{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1670472818051,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "yu0OV4sf1nk8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472819084,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "svhuDSYP1nk-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import collections\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "from IPython.core.display import HTML\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import tqdm\n",
    "from itertools import groupby\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472822205,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "vGhXf6lC1nk_",
    "outputId": "478747bb-6f8c-481d-ebb4-82b506528c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.11.0\n",
      "keras version 2.11.0\n",
      "Eager Execution Enabled: True\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of replicas: 1\n",
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Enable/Disable Eager Execution\n",
    "# Reference: https://www.tensorflow.org/guide/eager\n",
    "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
    "# without building graphs\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "print(\"keras version\", tf.keras.__version__)\n",
    "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
    "\n",
    "# Get the number of replicas \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "devices = tf.config.experimental.get_visible_devices()\n",
    "print(\"Devices:\", devices)\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
    "\n",
    "# Better performance with the tf.data API\n",
    "# Reference: https://www.tensorflow.org/guide/data_performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtMgghJO1nlA"
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "executionInfo": {
     "elapsed": 7156,
     "status": "ok",
     "timestamp": 1670461970917,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "eSg0NnAgXpRg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !unzip \"./all_data/sep_1/data.zip\" -d \"./temp_data/sep_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472827844,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "tbOPJ2jS1nlB"
   },
   "outputs": [],
   "source": [
    "# Getting the folder names \n",
    "folder_names_1 = glob.glob(\"./temp_data/sep_1/data/*\")\n",
    "folder_names_2 = glob.glob(\"./temp_data/sep_0.7/data/*\")\n",
    "# folder_names = folder_names_1 + folder_names_2\n",
    "folder_names = folder_names_1\n",
    "# folder_names = folder_names_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670472829094,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "JkZ1ScX01nlB"
   },
   "outputs": [],
   "source": [
    "# Getting the data names\n",
    "data_names = []\n",
    "for i in folder_names:\n",
    "    data_names.append(glob.glob(i+\"/*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng5z05Q61nlC"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "executionInfo": {
     "elapsed": 14851,
     "status": "ok",
     "timestamp": 1670472843943,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "06RUU7IU1nlD"
   },
   "outputs": [],
   "source": [
    "# Datasets to skip \n",
    "skip = []\n",
    "\n",
    "# Labels of the datasets\n",
    "labels = []\n",
    "\n",
    "# Data list \n",
    "data = []\n",
    "\n",
    "\n",
    "# Getting the labels and data for each dataset\n",
    "for i in range(len(data_names)):\n",
    "    if i in skip:\n",
    "        continue\n",
    "    \n",
    "    for j in range(len(data_names[i])):\n",
    "        labels.append([data_names[i][j][data_names[i][j].find(\".csv\")-1]])\n",
    "        \n",
    "        # Cleaning data\n",
    "        df = pd.read_csv(data_names[i][j],skiprows = 1)\n",
    "        df.drop(columns=df.columns[-1], axis=1,  inplace=True)\n",
    "        \n",
    "        data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472843943,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "OhMZiWrx1nlD"
   },
   "outputs": [],
   "source": [
    "# Changing the labels from int to string\n",
    "labels = [int(i)-1 for i in np.reshape(labels,(-1,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets for sep_1\n",
    "target = np.array([[-0.314,1.661,0.45],[0,1.661,0.45],[0.314,1.661,0.45],[-0.314,1.347,0.45],[0,1.347,0.45],[0.314,1.347,0.45],[-0.314,1.033,0.45],[0,1.033,0.45],[0.314,1.033,0.45]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3aWbcBR1nlD"
   },
   "source": [
    "## Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "executionInfo": {
     "elapsed": 57502,
     "status": "ok",
     "timestamp": 1670472901442,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "6sJpWHrX1nlE"
   },
   "outputs": [],
   "source": [
    "# Adding the centroid of all the fingers to the data\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for idx_1 in range(len(data)):\n",
    "\n",
    "    \n",
    "    # Grouped columns for centroid\n",
    "    grouped_columns_x = data[idx_1].columns[3::3] \n",
    "    grouped_columns_y = data[idx_1].columns[4::3]\n",
    "    grouped_columns_z = data[idx_1].columns[5::3]\n",
    "    \n",
    "    # Getting the centroid of the finger points\n",
    "    cent_x = np.mean(data[idx_1][grouped_columns_x],axis = 1)\n",
    "    cent_y = np.mean(data[idx_1][grouped_columns_y],axis = 1)\n",
    "    cent_z = np.mean(data[idx_1][grouped_columns_z],axis = 1)\n",
    "    \n",
    "    new_data.append(pd.concat([data[idx_1],cent_x,cent_y,cent_z],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgaA_2SY0MDc"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472901442,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "MUjsQWtJsKIn"
   },
   "outputs": [],
   "source": [
    "# Pulling only the centroid data \n",
    "cent_data = [i.iloc[:,-3:] for i in new_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1670472902684,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "cq550A880PAk",
    "outputId": "8c0ba4d0-9ee8-4885-fe2b-e9f624183928"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = np.array([len(i) for i in cent_data])\n",
    "plt.hist(lengths)\n",
    "plt.xlabel(\"Trajectory length\")\n",
    "plt.ylabel(\"Number of trajectories\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.61878727634195"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the mean trajectory lengths\n",
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "ymWVIli90Uu8"
   },
   "outputs": [],
   "source": [
    "# Removing trajectories with <=5 length\n",
    "idx = np.where(lengths <= 13.)[0]\n",
    "[labels.pop(j-i) for i,j in enumerate(idx)]\n",
    "[cent_data.pop(j-i) for i,j in enumerate(idx)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "9X0N0OYxcyyJ",
    "outputId": "e7d207da-0b10-4219-ad7d-a7ab34848596"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see if it worked \n",
    "lengths = np.array([len(i) for i in cent_data])\n",
    "np.where(lengths <= 13.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For target point prediction\n",
    "data_3d = []\n",
    "target_3d = []\n",
    "for i in cent_data:\n",
    "    data_3d.append(i.iloc[:-10,:])\n",
    "    temp = []\n",
    "    for j in range(len(i.iloc[:-10,:])):\n",
    "        temp.append(i.iloc[j+1:j+11,:])\n",
    "    target_3d.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "hfPRW0S7UN4b"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(cent_data, labels, test_size=0.2, random_state = 7)\n",
    "# x_train_, x_test_, y_train_, y_test_ = train_test_split(data_3d, target_3d, test_size=0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902687,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "kKLJbGtv1nlE"
   },
   "outputs": [],
   "source": [
    "# Getting the data in the required format for the model\n",
    "# Creating labels for RNN's output \n",
    "y_train = [[dt]*200 for idx,dt in enumerate(y_train)]\n",
    "y_test = [[dt]*200 for idx,dt in enumerate(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "evCXyI6-1nlE"
   },
   "outputs": [],
   "source": [
    "# Sequence length is based on data analysis\n",
    "# x_train = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_train_, padding='post', dtype='float', maxlen=200, value = -10.))\n",
    "x_train = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_train, padding='post', dtype='float', maxlen=200, value = 0))\n",
    "# y_train = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(y_train_, padding='post', dtype='float', maxlen=200))\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "# x_test = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_test_, padding='post', dtype='float', maxlen=200, value = -10.))\n",
    "x_test = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_test, padding='post', dtype='float', maxlen=200, value = 0))\n",
    "# y_test = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(y_test_, padding='post', dtype='float', maxlen=200))\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "ryFy62Mk1nlF"
   },
   "outputs": [],
   "source": [
    "# One hot encoding the data for training - not required for label_3d\n",
    "y_train = tf.one_hot(y_train, 9, on_value = 1.0, off_value = 0.0)\n",
    "y_test = tf.one_hot(y_test, 9, on_value = 1.0, off_value = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJc39yrs1nlE"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the DTW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dtw(ip_data,op_data):\n",
    "    data_dict_x = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    data_dict_y = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    data_dict_z = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "\n",
    "    time = np.arange(len(ip_data))\n",
    "    for i,j in zip(ip_data,op_data):\n",
    "\n",
    "        time = np.arange(len(i))\n",
    "        \n",
    "        data_dict_x[j].append(np.polyfit(time,i[0],3))\n",
    "        data_dict_y[j].append(np.polyfit(time,i[1],3))\n",
    "        data_dict_z[j].append(np.polyfit(time,i[2],3))\n",
    "\n",
    "    # getting the mean and trend\n",
    "    trend_dict_x = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    trend_dict_y = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    trend_dict_z = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    time = np.arange(70)\n",
    "    for i in range(9):\n",
    "        trend_dict_x[i] = np.poly1d(np.mean(data_dict_x[i],axis = 0))(time)\n",
    "        trend_dict_y[i] = np.poly1d(np.mean(data_dict_y[i],axis = 0))(time)\n",
    "        trend_dict_z[i] = np.poly1d(np.mean(data_dict_z[i],axis = 0))(time)\n",
    "\n",
    "  \n",
    "    dict_q = []\n",
    "    for i in range(9):\n",
    "        dict_q.append(np.array([trend_dict_x[i],trend_dict_y[i],trend_dict_z[i]]))\n",
    "    return dict_q\n",
    "\n",
    "\n",
    "def model_dtw_pred(ip_data,dic):\n",
    "\n",
    "    \n",
    "    predi = []\n",
    "#     for k in range(0,len(ip_data)):\n",
    "    d = []\n",
    "    for i in range(0,9):\n",
    "        distance, path = fastdtw(dic[i].T, ip_data, dist=euclidean)\n",
    "        d.append(distance)\n",
    "\n",
    "    predi.append(d.index(min(d)))\n",
    "    \n",
    "    return predi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_q = model_dtw(x_train,y_train)\n",
    "with open(\"./models/sep_1/data_driven\", 'wb') as handle:\n",
    "    pickle.dump(dict_q, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# Load data (deserialize)\n",
    "with open('./models/sep_1/data_driven', 'rb') as handle:\n",
    "    dic = pickle.load(handle)\n",
    "predi = model_dtw_pred(x_test[0],dict_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902689,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "LJC8EL0egiGL"
   },
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h = LSTM(ip_reformed)\n",
    "\n",
    "dense = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense(h)\n",
    "\n",
    "model_LSTM = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_LSTM.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM model - labels_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "masking = tf.keras.layers.Masking(mask_value=-10.)\n",
    "masked_op = masking(seq_input)\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(masked_op)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h = LSTM(ip_reformed)\n",
    "\n",
    "dense = tf.keras.layers.Dense(30, activation='linear')\n",
    "dense_out = dense(h)\n",
    "\n",
    "reshaping = tf.keras.layers.Reshape((200,10, 3))\n",
    "output = reshaping(dense_out)\n",
    "\n",
    "model_LSTM_3d = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_LSTM_3d.compile(loss='mse', metrics = ['mae'],optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM+RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472905553,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "qsyhNfUNdb9D"
   },
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "RNN = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN(ip_reformed)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h_2 = LSTM(h_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense(h_2)\n",
    "\n",
    "model_RNN_LSTM = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN_LSTM.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM+RNN model - labels_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "masking = tf.keras.layers.Masking(mask_value=-10.)\n",
    "masked_op = masking(seq_input)\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(masked_op)\n",
    "\n",
    "RNN = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN(ip_reformed)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h_2 = LSTM(h_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(30, activation='linear')\n",
    "dense_out = dense(h_2)\n",
    "\n",
    "reshaping = tf.keras.layers.Reshape((200,10, 3))\n",
    "output = reshaping(dense_out)\n",
    "\n",
    "model_RNN_LSTM_3d = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN_LSTM_3d.compile(loss='mse', metrics = ['mae'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472905553,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "29kaMRnt1nlF",
    "outputId": "96eed065-c571-49cd-fffa-6e4ef9d4d358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 200, 3)]          0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 200, 3)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200, 15)           60        \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 200, 15)           465       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 15)           1860      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200, 30)           480       \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 200, 10, 3)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,865\n",
      "Trainable params: 2,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RNN_LSTM_3d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1593,
     "status": "ok",
     "timestamp": 1670472927009,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "7B3g6dUGOOoU"
   },
   "outputs": [],
   "source": [
    "# callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_accuracy',\n",
    "#     patience=100,\n",
    "#     restore_best_weights = True\n",
    "# )\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=100,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdnYYPv_1nlF",
    "outputId": "a1bb33a5-8b8c-446d-9016-a14cbc846054",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:35:11.906640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2022-12-13 16:35:14.020076: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14a091c54b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-13 16:35:14.020095: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2022-12-13 16:35:14.103729: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-13 16:35:14.610576: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 34s 149ms/step - loss: 0.0109 - mae: 0.0405 - val_loss: 0.0021 - val_mae: 0.0182\n",
      "Epoch 2/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 0.0014 - mae: 0.0148 - val_loss: 9.0127e-04 - val_mae: 0.0121\n",
      "Epoch 3/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.3876e-04 - mae: 0.0100 - val_loss: 7.9560e-04 - val_mae: 0.0119\n",
      "Epoch 4/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.3815e-04 - mae: 0.0091 - val_loss: 5.1718e-04 - val_mae: 0.0089\n",
      "Epoch 5/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 3.3984e-04 - mae: 0.0071 - val_loss: 2.5057e-04 - val_mae: 0.0058\n",
      "Epoch 6/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 2.4240e-04 - mae: 0.0058 - val_loss: 3.7125e-04 - val_mae: 0.0076\n",
      "Epoch 7/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 2.4036e-04 - mae: 0.0057 - val_loss: 2.9518e-04 - val_mae: 0.0066\n",
      "Epoch 8/1000\n",
      "116/116 [==============================] - 16s 138ms/step - loss: 2.2973e-04 - mae: 0.0056 - val_loss: 2.1140e-04 - val_mae: 0.0050\n",
      "Epoch 9/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 2.1275e-04 - mae: 0.0054 - val_loss: 2.5746e-04 - val_mae: 0.0058\n",
      "Epoch 10/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 2.2137e-04 - mae: 0.0055 - val_loss: 2.6234e-04 - val_mae: 0.0061\n",
      "Epoch 11/1000\n",
      "116/116 [==============================] - 15s 132ms/step - loss: 2.2524e-04 - mae: 0.0057 - val_loss: 2.2886e-04 - val_mae: 0.0054\n",
      "Epoch 12/1000\n",
      "116/116 [==============================] - 16s 135ms/step - loss: 2.1259e-04 - mae: 0.0054 - val_loss: 2.3523e-04 - val_mae: 0.0056\n",
      "Epoch 13/1000\n",
      "116/116 [==============================] - 16s 137ms/step - loss: 2.1863e-04 - mae: 0.0056 - val_loss: 2.3231e-04 - val_mae: 0.0058\n",
      "Epoch 14/1000\n",
      "116/116 [==============================] - 16s 138ms/step - loss: 2.0749e-04 - mae: 0.0055 - val_loss: 2.3547e-04 - val_mae: 0.0058\n",
      "Epoch 15/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 1.9315e-04 - mae: 0.0052 - val_loss: 2.3251e-04 - val_mae: 0.0059\n",
      "Epoch 16/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 2.2158e-04 - mae: 0.0058 - val_loss: 3.2447e-04 - val_mae: 0.0082\n",
      "Epoch 17/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 2.0510e-04 - mae: 0.0054 - val_loss: 1.9539e-04 - val_mae: 0.0050\n",
      "Epoch 18/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.8087e-04 - mae: 0.0050 - val_loss: 1.8611e-04 - val_mae: 0.0050\n",
      "Epoch 19/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 2.0454e-04 - mae: 0.0055 - val_loss: 2.4169e-04 - val_mae: 0.0065\n",
      "Epoch 20/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 2.3520e-04 - mae: 0.0061 - val_loss: 2.1508e-04 - val_mae: 0.0055\n",
      "Epoch 21/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.9685e-04 - mae: 0.0055 - val_loss: 1.8574e-04 - val_mae: 0.0049\n",
      "Epoch 22/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 1.8268e-04 - mae: 0.0052 - val_loss: 1.9306e-04 - val_mae: 0.0053\n",
      "Epoch 23/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.7663e-04 - mae: 0.0050 - val_loss: 1.7536e-04 - val_mae: 0.0047\n",
      "Epoch 24/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 1.6423e-04 - mae: 0.0048 - val_loss: 1.7106e-04 - val_mae: 0.0048\n",
      "Epoch 25/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.6532e-04 - mae: 0.0048 - val_loss: 1.6487e-04 - val_mae: 0.0045\n",
      "Epoch 26/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.6102e-04 - mae: 0.0048 - val_loss: 1.7933e-04 - val_mae: 0.0051\n",
      "Epoch 27/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.8027e-04 - mae: 0.0052 - val_loss: 1.6522e-04 - val_mae: 0.0045\n",
      "Epoch 28/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.5161e-04 - mae: 0.0046 - val_loss: 1.6904e-04 - val_mae: 0.0047\n",
      "Epoch 29/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.6381e-04 - mae: 0.0050 - val_loss: 1.8683e-04 - val_mae: 0.0055\n",
      "Epoch 30/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.6783e-04 - mae: 0.0051 - val_loss: 1.8895e-04 - val_mae: 0.0051\n",
      "Epoch 31/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.6812e-04 - mae: 0.0051 - val_loss: 1.7076e-04 - val_mae: 0.0053\n",
      "Epoch 32/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 1.5477e-04 - mae: 0.0049 - val_loss: 1.7758e-04 - val_mae: 0.0057\n",
      "Epoch 33/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.5530e-04 - mae: 0.0051 - val_loss: 2.5091e-04 - val_mae: 0.0071\n",
      "Epoch 34/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 1.5556e-04 - mae: 0.0050 - val_loss: 2.0296e-04 - val_mae: 0.0066\n",
      "Epoch 35/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 1.3013e-04 - mae: 0.0044 - val_loss: 1.6148e-04 - val_mae: 0.0045\n",
      "Epoch 36/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 1.4532e-04 - mae: 0.0048 - val_loss: 1.2773e-04 - val_mae: 0.0040\n",
      "Epoch 37/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.3465e-04 - mae: 0.0046 - val_loss: 1.8769e-04 - val_mae: 0.0056\n",
      "Epoch 38/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.2977e-04 - mae: 0.0045 - val_loss: 1.6856e-04 - val_mae: 0.0054\n",
      "Epoch 39/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.2616e-04 - mae: 0.0043 - val_loss: 1.2191e-04 - val_mae: 0.0038\n",
      "Epoch 40/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 1.3013e-04 - mae: 0.0044 - val_loss: 2.1867e-04 - val_mae: 0.0070\n",
      "Epoch 41/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.3100e-04 - mae: 0.0045 - val_loss: 1.2874e-04 - val_mae: 0.0044\n",
      "Epoch 42/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.2824e-04 - mae: 0.0045 - val_loss: 1.2069e-04 - val_mae: 0.0041\n",
      "Epoch 43/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.1294e-04 - mae: 0.0041 - val_loss: 1.3843e-04 - val_mae: 0.0047\n",
      "Epoch 44/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 1.1907e-04 - mae: 0.0042 - val_loss: 2.0052e-04 - val_mae: 0.0055\n",
      "Epoch 45/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 1.2231e-04 - mae: 0.0044 - val_loss: 1.4533e-04 - val_mae: 0.0050\n",
      "Epoch 46/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.0901e-04 - mae: 0.0041 - val_loss: 1.1566e-04 - val_mae: 0.0040\n",
      "Epoch 47/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.0791e-04 - mae: 0.0040 - val_loss: 1.1435e-04 - val_mae: 0.0038\n",
      "Epoch 48/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.0649e-04 - mae: 0.0040 - val_loss: 1.4358e-04 - val_mae: 0.0046\n",
      "Epoch 49/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 1.1126e-04 - mae: 0.0041 - val_loss: 1.0613e-04 - val_mae: 0.0037\n",
      "Epoch 50/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 9.1794e-05 - mae: 0.0037 - val_loss: 1.1627e-04 - val_mae: 0.0043\n",
      "Epoch 51/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.0369e-05 - mae: 0.0036 - val_loss: 1.2046e-04 - val_mae: 0.0043\n",
      "Epoch 52/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.4732e-05 - mae: 0.0038 - val_loss: 1.0782e-04 - val_mae: 0.0041\n",
      "Epoch 53/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 9.1811e-05 - mae: 0.0038 - val_loss: 1.0530e-04 - val_mae: 0.0038\n",
      "Epoch 54/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.0454e-05 - mae: 0.0037 - val_loss: 1.1607e-04 - val_mae: 0.0043\n",
      "Epoch 55/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 9.4180e-05 - mae: 0.0037 - val_loss: 1.0110e-04 - val_mae: 0.0038\n",
      "Epoch 56/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 8.0517e-05 - mae: 0.0034 - val_loss: 9.8325e-05 - val_mae: 0.0035\n",
      "Epoch 57/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 8.6761e-05 - mae: 0.0036 - val_loss: 8.9184e-05 - val_mae: 0.0036\n",
      "Epoch 58/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 7.7914e-05 - mae: 0.0033 - val_loss: 8.6915e-05 - val_mae: 0.0036\n",
      "Epoch 59/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 8.9431e-05 - mae: 0.0038 - val_loss: 9.0322e-05 - val_mae: 0.0037\n",
      "Epoch 60/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.0297e-05 - mae: 0.0037 - val_loss: 8.9438e-05 - val_mae: 0.0036\n",
      "Epoch 61/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.3034e-05 - mae: 0.0038 - val_loss: 1.1009e-04 - val_mae: 0.0043\n",
      "Epoch 62/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 7.2515e-05 - mae: 0.0032 - val_loss: 8.0797e-05 - val_mae: 0.0031\n",
      "Epoch 63/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 7.5458e-05 - mae: 0.0033 - val_loss: 8.6755e-05 - val_mae: 0.0034\n",
      "Epoch 64/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 7.5651e-05 - mae: 0.0033 - val_loss: 7.8274e-05 - val_mae: 0.0032\n",
      "Epoch 65/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 7.1675e-05 - mae: 0.0032 - val_loss: 8.5493e-05 - val_mae: 0.0034\n",
      "Epoch 66/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 7.5099e-05 - mae: 0.0033 - val_loss: 1.0427e-04 - val_mae: 0.0044\n",
      "Epoch 67/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 8.4721e-05 - mae: 0.0038 - val_loss: 7.5888e-05 - val_mae: 0.0032\n",
      "Epoch 68/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.7472e-05 - mae: 0.0030 - val_loss: 8.4022e-05 - val_mae: 0.0035\n",
      "Epoch 69/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.4877e-05 - mae: 0.0030 - val_loss: 8.3727e-05 - val_mae: 0.0033\n",
      "Epoch 70/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 7.4439e-05 - mae: 0.0034 - val_loss: 8.0386e-05 - val_mae: 0.0034\n",
      "Epoch 71/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 7.3756e-05 - mae: 0.0033 - val_loss: 9.2154e-05 - val_mae: 0.0040\n",
      "Epoch 72/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 7.1240e-05 - mae: 0.0033 - val_loss: 8.2839e-05 - val_mae: 0.0035\n",
      "Epoch 73/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 7.2526e-05 - mae: 0.0033 - val_loss: 7.8068e-05 - val_mae: 0.0034\n",
      "Epoch 74/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 7.6906e-05 - mae: 0.0035 - val_loss: 8.6142e-05 - val_mae: 0.0034\n",
      "Epoch 75/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 6.6470e-05 - mae: 0.0031 - val_loss: 8.4138e-05 - val_mae: 0.0035\n",
      "Epoch 76/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.3981e-05 - mae: 0.0030 - val_loss: 7.4597e-05 - val_mae: 0.0033\n",
      "Epoch 77/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.5187e-05 - mae: 0.0031 - val_loss: 6.9407e-05 - val_mae: 0.0031\n",
      "Epoch 78/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 6.6682e-05 - mae: 0.0031 - val_loss: 7.7087e-05 - val_mae: 0.0031\n",
      "Epoch 79/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.5263e-05 - mae: 0.0031 - val_loss: 8.2621e-05 - val_mae: 0.0037\n",
      "Epoch 80/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.9184e-05 - mae: 0.0028 - val_loss: 7.8754e-05 - val_mae: 0.0035\n",
      "Epoch 81/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.1700e-05 - mae: 0.0030 - val_loss: 8.1309e-05 - val_mae: 0.0036\n",
      "Epoch 82/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 6.7724e-05 - mae: 0.0032 - val_loss: 8.0564e-05 - val_mae: 0.0034\n",
      "Epoch 83/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.2991e-05 - mae: 0.0030 - val_loss: 7.9642e-05 - val_mae: 0.0040\n",
      "Epoch 84/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 6.0646e-05 - mae: 0.0030 - val_loss: 9.9392e-05 - val_mae: 0.0041\n",
      "Epoch 85/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.0760e-05 - mae: 0.0029 - val_loss: 7.1592e-05 - val_mae: 0.0030\n",
      "Epoch 86/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.5965e-05 - mae: 0.0032 - val_loss: 7.4124e-05 - val_mae: 0.0029\n",
      "Epoch 87/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.1680e-05 - mae: 0.0030 - val_loss: 7.4816e-05 - val_mae: 0.0033\n",
      "Epoch 88/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.0405e-05 - mae: 0.0030 - val_loss: 7.3106e-05 - val_mae: 0.0030\n",
      "Epoch 89/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 5.9257e-05 - mae: 0.0029 - val_loss: 6.2100e-05 - val_mae: 0.0026\n",
      "Epoch 90/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 6.0077e-05 - mae: 0.0030 - val_loss: 6.7376e-05 - val_mae: 0.0028\n",
      "Epoch 91/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.0411e-05 - mae: 0.0030 - val_loss: 6.6792e-05 - val_mae: 0.0030\n",
      "Epoch 92/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.8697e-05 - mae: 0.0029 - val_loss: 7.1107e-05 - val_mae: 0.0031\n",
      "Epoch 93/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.1454e-05 - mae: 0.0031 - val_loss: 7.0483e-05 - val_mae: 0.0033\n",
      "Epoch 94/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.8629e-05 - mae: 0.0029 - val_loss: 6.7643e-05 - val_mae: 0.0031\n",
      "Epoch 95/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 6.0778e-05 - mae: 0.0030 - val_loss: 8.2647e-05 - val_mae: 0.0036\n",
      "Epoch 96/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.8483e-05 - mae: 0.0030 - val_loss: 6.8450e-05 - val_mae: 0.0029\n",
      "Epoch 97/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.8544e-05 - mae: 0.0030 - val_loss: 6.3602e-05 - val_mae: 0.0028\n",
      "Epoch 98/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.0529e-05 - mae: 0.0029 - val_loss: 6.2841e-05 - val_mae: 0.0027\n",
      "Epoch 99/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 6.0189e-05 - mae: 0.0031 - val_loss: 7.5825e-05 - val_mae: 0.0033\n",
      "Epoch 100/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.5962e-05 - mae: 0.0029 - val_loss: 7.5002e-05 - val_mae: 0.0032\n",
      "Epoch 101/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.9426e-05 - mae: 0.0030 - val_loss: 9.5606e-05 - val_mae: 0.0038\n",
      "Epoch 102/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.1980e-05 - mae: 0.0026 - val_loss: 6.1063e-05 - val_mae: 0.0026\n",
      "Epoch 103/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 6.0263e-05 - mae: 0.0030 - val_loss: 6.4070e-05 - val_mae: 0.0028\n",
      "Epoch 104/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.7479e-05 - mae: 0.0029 - val_loss: 8.4327e-05 - val_mae: 0.0036\n",
      "Epoch 105/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.6060e-05 - mae: 0.0029 - val_loss: 6.5855e-05 - val_mae: 0.0031\n",
      "Epoch 106/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 5.1738e-05 - mae: 0.0027 - val_loss: 5.8581e-05 - val_mae: 0.0027\n",
      "Epoch 107/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.4935e-05 - mae: 0.0029 - val_loss: 7.1839e-05 - val_mae: 0.0033\n",
      "Epoch 108/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.9250e-05 - mae: 0.0030 - val_loss: 5.9636e-05 - val_mae: 0.0026\n",
      "Epoch 109/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.9998e-05 - mae: 0.0026 - val_loss: 6.9199e-05 - val_mae: 0.0031\n",
      "Epoch 110/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.3236e-05 - mae: 0.0028 - val_loss: 5.9437e-05 - val_mae: 0.0025\n",
      "Epoch 111/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.7911e-05 - mae: 0.0030 - val_loss: 7.8435e-05 - val_mae: 0.0034\n",
      "Epoch 112/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.9607e-05 - mae: 0.0026 - val_loss: 6.6859e-05 - val_mae: 0.0034\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 16s 142ms/step - loss: 5.7049e-05 - mae: 0.0030 - val_loss: 7.0060e-05 - val_mae: 0.0032\n",
      "Epoch 114/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 5.1417e-05 - mae: 0.0027 - val_loss: 7.0800e-05 - val_mae: 0.0033\n",
      "Epoch 115/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 6.0992e-05 - mae: 0.0030 - val_loss: 1.4356e-04 - val_mae: 0.0051\n",
      "Epoch 116/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.4520e-05 - mae: 0.0032 - val_loss: 6.5206e-05 - val_mae: 0.0031\n",
      "Epoch 117/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.9702e-05 - mae: 0.0026 - val_loss: 6.1064e-05 - val_mae: 0.0027\n",
      "Epoch 118/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.2330e-05 - mae: 0.0028 - val_loss: 6.4438e-05 - val_mae: 0.0031\n",
      "Epoch 119/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.1707e-05 - mae: 0.0027 - val_loss: 5.6812e-05 - val_mae: 0.0028\n",
      "Epoch 120/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.9381e-05 - mae: 0.0031 - val_loss: 8.6419e-05 - val_mae: 0.0039\n",
      "Epoch 121/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.3433e-05 - mae: 0.0028 - val_loss: 7.2319e-05 - val_mae: 0.0034\n",
      "Epoch 122/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.3199e-05 - mae: 0.0028 - val_loss: 7.3382e-05 - val_mae: 0.0034\n",
      "Epoch 123/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.2251e-05 - mae: 0.0027 - val_loss: 6.1858e-05 - val_mae: 0.0027\n",
      "Epoch 124/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.1323e-05 - mae: 0.0027 - val_loss: 1.2841e-04 - val_mae: 0.0051\n",
      "Epoch 125/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 7.4479e-05 - mae: 0.0036 - val_loss: 7.7339e-05 - val_mae: 0.0035\n",
      "Epoch 126/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.0419e-05 - mae: 0.0026 - val_loss: 6.9191e-05 - val_mae: 0.0034\n",
      "Epoch 127/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.7373e-05 - mae: 0.0025 - val_loss: 5.8092e-05 - val_mae: 0.0026\n",
      "Epoch 128/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.7065e-05 - mae: 0.0025 - val_loss: 5.5284e-05 - val_mae: 0.0025\n",
      "Epoch 129/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.9722e-05 - mae: 0.0027 - val_loss: 5.8031e-05 - val_mae: 0.0025\n",
      "Epoch 130/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.9445e-05 - mae: 0.0026 - val_loss: 5.4547e-05 - val_mae: 0.0024\n",
      "Epoch 131/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.6717e-05 - mae: 0.0025 - val_loss: 5.9883e-05 - val_mae: 0.0027\n",
      "Epoch 132/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.8257e-05 - mae: 0.0026 - val_loss: 6.5699e-05 - val_mae: 0.0031\n",
      "Epoch 133/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.8600e-05 - mae: 0.0026 - val_loss: 7.0707e-05 - val_mae: 0.0032\n",
      "Epoch 134/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.0303e-05 - mae: 0.0027 - val_loss: 6.5965e-05 - val_mae: 0.0033\n",
      "Epoch 135/1000\n",
      "116/116 [==============================] - 16s 138ms/step - loss: 5.5459e-05 - mae: 0.0029 - val_loss: 7.2868e-05 - val_mae: 0.0035\n",
      "Epoch 136/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.3368e-05 - mae: 0.0029 - val_loss: 6.7793e-05 - val_mae: 0.0034\n",
      "Epoch 137/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.0207e-05 - mae: 0.0027 - val_loss: 7.0868e-05 - val_mae: 0.0033\n",
      "Epoch 138/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.4600e-05 - mae: 0.0029 - val_loss: 5.9740e-05 - val_mae: 0.0028\n",
      "Epoch 139/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.1002e-05 - mae: 0.0028 - val_loss: 7.5197e-05 - val_mae: 0.0035\n",
      "Epoch 140/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.9308e-05 - mae: 0.0027 - val_loss: 5.8505e-05 - val_mae: 0.0028\n",
      "Epoch 141/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.7863e-05 - mae: 0.0026 - val_loss: 5.9674e-05 - val_mae: 0.0026\n",
      "Epoch 142/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.7541e-05 - mae: 0.0026 - val_loss: 5.6215e-05 - val_mae: 0.0024\n",
      "Epoch 143/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.0217e-05 - mae: 0.0027 - val_loss: 5.9753e-05 - val_mae: 0.0029\n",
      "Epoch 144/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 3.8101e-04 - mae: 0.0072 - val_loss: 3.0268e-04 - val_mae: 0.0078\n",
      "Epoch 145/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.9157e-04 - mae: 0.0058 - val_loss: 1.8662e-04 - val_mae: 0.0051\n",
      "Epoch 146/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 1.4656e-04 - mae: 0.0049 - val_loss: 1.5354e-04 - val_mae: 0.0047\n",
      "Epoch 147/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 1.1785e-04 - mae: 0.0044 - val_loss: 1.1718e-04 - val_mae: 0.0042\n",
      "Epoch 148/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 8.9971e-05 - mae: 0.0037 - val_loss: 1.0322e-04 - val_mae: 0.0042\n",
      "Epoch 149/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 8.0611e-05 - mae: 0.0035 - val_loss: 1.0813e-04 - val_mae: 0.0041\n",
      "Epoch 150/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 8.0304e-05 - mae: 0.0036 - val_loss: 9.2830e-05 - val_mae: 0.0038\n",
      "Epoch 151/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 7.2473e-05 - mae: 0.0033 - val_loss: 8.3242e-05 - val_mae: 0.0031\n",
      "Epoch 152/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.6995e-05 - mae: 0.0030 - val_loss: 7.6303e-05 - val_mae: 0.0031\n",
      "Epoch 153/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.7343e-05 - mae: 0.0031 - val_loss: 7.6836e-05 - val_mae: 0.0030\n",
      "Epoch 154/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 6.5958e-05 - mae: 0.0030 - val_loss: 8.6145e-05 - val_mae: 0.0037\n",
      "Epoch 155/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.5210e-05 - mae: 0.0030 - val_loss: 7.4963e-05 - val_mae: 0.0031\n",
      "Epoch 156/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.4464e-05 - mae: 0.0030 - val_loss: 7.5039e-05 - val_mae: 0.0033\n",
      "Epoch 157/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.5965e-05 - mae: 0.0031 - val_loss: 7.0846e-05 - val_mae: 0.0029\n",
      "Epoch 158/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 6.4126e-05 - mae: 0.0031 - val_loss: 9.5813e-05 - val_mae: 0.0038\n",
      "Epoch 159/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.6930e-05 - mae: 0.0032 - val_loss: 8.6672e-05 - val_mae: 0.0038\n",
      "Epoch 160/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 6.3028e-05 - mae: 0.0030 - val_loss: 7.7258e-05 - val_mae: 0.0032\n",
      "Epoch 161/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 6.2369e-05 - mae: 0.0031 - val_loss: 1.1914e-04 - val_mae: 0.0051\n",
      "Epoch 162/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 6.6798e-05 - mae: 0.0033 - val_loss: 7.3566e-05 - val_mae: 0.0031\n",
      "Epoch 163/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.8966e-05 - mae: 0.0029 - val_loss: 8.0460e-05 - val_mae: 0.0036\n",
      "Epoch 164/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 6.0611e-05 - mae: 0.0030 - val_loss: 6.8069e-05 - val_mae: 0.0029\n",
      "Epoch 165/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.7751e-05 - mae: 0.0028 - val_loss: 6.7860e-05 - val_mae: 0.0028\n",
      "Epoch 166/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.4485e-05 - mae: 0.0033 - val_loss: 7.0992e-05 - val_mae: 0.0034\n",
      "Epoch 167/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.5252e-05 - mae: 0.0032 - val_loss: 1.0251e-04 - val_mae: 0.0051\n",
      "Epoch 168/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 6.4975e-05 - mae: 0.0032 - val_loss: 6.9394e-05 - val_mae: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.8084e-05 - mae: 0.0030 - val_loss: 6.5414e-05 - val_mae: 0.0029\n",
      "Epoch 170/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.3914e-05 - mae: 0.0027 - val_loss: 7.1059e-05 - val_mae: 0.0030\n",
      "Epoch 171/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.0457e-05 - mae: 0.0031 - val_loss: 6.1493e-05 - val_mae: 0.0026\n",
      "Epoch 172/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.7303e-05 - mae: 0.0029 - val_loss: 6.6400e-05 - val_mae: 0.0030\n",
      "Epoch 173/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.6105e-05 - mae: 0.0029 - val_loss: 8.6536e-05 - val_mae: 0.0038\n",
      "Epoch 174/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.1712e-05 - mae: 0.0032 - val_loss: 6.6812e-05 - val_mae: 0.0030\n",
      "Epoch 175/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.6297e-05 - mae: 0.0030 - val_loss: 7.0278e-05 - val_mae: 0.0030\n",
      "Epoch 176/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.3183e-05 - mae: 0.0027 - val_loss: 6.1144e-05 - val_mae: 0.0025\n",
      "Epoch 177/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.5632e-05 - mae: 0.0028 - val_loss: 6.3003e-05 - val_mae: 0.0027\n",
      "Epoch 178/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.8739e-05 - mae: 0.0031 - val_loss: 6.9809e-05 - val_mae: 0.0033\n",
      "Epoch 179/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 5.4533e-05 - mae: 0.0029 - val_loss: 6.1467e-05 - val_mae: 0.0028\n",
      "Epoch 180/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.3731e-05 - mae: 0.0029 - val_loss: 6.1724e-05 - val_mae: 0.0029\n",
      "Epoch 181/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.0569e-05 - mae: 0.0027 - val_loss: 6.1623e-05 - val_mae: 0.0031\n",
      "Epoch 182/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.5517e-05 - mae: 0.0029 - val_loss: 6.2585e-05 - val_mae: 0.0029\n",
      "Epoch 183/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.6398e-05 - mae: 0.0030 - val_loss: 5.6990e-05 - val_mae: 0.0025\n",
      "Epoch 184/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.8951e-05 - mae: 0.0026 - val_loss: 6.0412e-05 - val_mae: 0.0028\n",
      "Epoch 185/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.0377e-05 - mae: 0.0027 - val_loss: 7.9214e-05 - val_mae: 0.0039\n",
      "Epoch 186/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.4526e-05 - mae: 0.0029 - val_loss: 6.9457e-05 - val_mae: 0.0035\n",
      "Epoch 187/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 5.1262e-05 - mae: 0.0027 - val_loss: 6.0020e-05 - val_mae: 0.0028\n",
      "Epoch 188/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.4338e-05 - mae: 0.0030 - val_loss: 5.8997e-05 - val_mae: 0.0026\n",
      "Epoch 189/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 7.3239e-05 - mae: 0.0036 - val_loss: 1.0778e-04 - val_mae: 0.0050\n",
      "Epoch 190/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.7582e-05 - mae: 0.0030 - val_loss: 6.0681e-05 - val_mae: 0.0029\n",
      "Epoch 191/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.0917e-05 - mae: 0.0028 - val_loss: 5.7424e-05 - val_mae: 0.0025\n",
      "Epoch 192/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.9189e-05 - mae: 0.0026 - val_loss: 6.4233e-05 - val_mae: 0.0030\n",
      "Epoch 193/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.1719e-05 - mae: 0.0028 - val_loss: 1.1264e-04 - val_mae: 0.0047\n",
      "Epoch 194/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 5.6303e-05 - mae: 0.0030 - val_loss: 5.8591e-05 - val_mae: 0.0026\n",
      "Epoch 195/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.5255e-05 - mae: 0.0029 - val_loss: 5.9445e-05 - val_mae: 0.0025\n",
      "Epoch 196/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.8549e-05 - mae: 0.0026 - val_loss: 5.7503e-05 - val_mae: 0.0025\n",
      "Epoch 197/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.2658e-05 - mae: 0.0029 - val_loss: 6.8137e-05 - val_mae: 0.0033\n",
      "Epoch 198/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.8169e-05 - mae: 0.0026 - val_loss: 6.0710e-05 - val_mae: 0.0031\n",
      "Epoch 199/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.2920e-05 - mae: 0.0029 - val_loss: 9.9699e-05 - val_mae: 0.0047\n",
      "Epoch 200/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.4043e-05 - mae: 0.0030 - val_loss: 6.8122e-05 - val_mae: 0.0033\n",
      "Epoch 201/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.2696e-05 - mae: 0.0029 - val_loss: 6.1443e-05 - val_mae: 0.0031\n",
      "Epoch 202/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.9603e-05 - mae: 0.0031 - val_loss: 6.1093e-05 - val_mae: 0.0027\n",
      "Epoch 203/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.9667e-05 - mae: 0.0027 - val_loss: 6.0888e-05 - val_mae: 0.0030\n",
      "Epoch 204/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.7346e-05 - mae: 0.0030 - val_loss: 6.4559e-05 - val_mae: 0.0033\n",
      "Epoch 205/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.2308e-05 - mae: 0.0029 - val_loss: 6.9429e-05 - val_mae: 0.0034\n",
      "Epoch 206/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.2128e-05 - mae: 0.0028 - val_loss: 5.7767e-05 - val_mae: 0.0028\n",
      "Epoch 207/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.1578e-05 - mae: 0.0028 - val_loss: 6.8328e-05 - val_mae: 0.0034\n",
      "Epoch 208/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.1967e-05 - mae: 0.0028 - val_loss: 5.6604e-05 - val_mae: 0.0027\n",
      "Epoch 209/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.9992e-05 - mae: 0.0028 - val_loss: 5.9032e-05 - val_mae: 0.0027\n",
      "Epoch 210/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.0858e-05 - mae: 0.0028 - val_loss: 5.6729e-05 - val_mae: 0.0028\n",
      "Epoch 211/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.6976e-05 - mae: 0.0026 - val_loss: 7.7636e-05 - val_mae: 0.0037\n",
      "Epoch 212/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.3971e-05 - mae: 0.0029 - val_loss: 5.7308e-05 - val_mae: 0.0029\n",
      "Epoch 213/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.7984e-05 - mae: 0.0026 - val_loss: 7.3754e-05 - val_mae: 0.0033\n",
      "Epoch 214/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.8885e-05 - mae: 0.0026 - val_loss: 5.9536e-05 - val_mae: 0.0028\n",
      "Epoch 215/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.4145e-05 - mae: 0.0029 - val_loss: 6.7055e-05 - val_mae: 0.0032\n",
      "Epoch 216/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 5.0940e-05 - mae: 0.0028 - val_loss: 6.7092e-05 - val_mae: 0.0032\n",
      "Epoch 217/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.0807e-05 - mae: 0.0028 - val_loss: 6.4997e-05 - val_mae: 0.0035\n",
      "Epoch 218/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.9276e-05 - mae: 0.0027 - val_loss: 5.6482e-05 - val_mae: 0.0026\n",
      "Epoch 219/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.5732e-05 - mae: 0.0025 - val_loss: 6.0058e-05 - val_mae: 0.0028\n",
      "Epoch 220/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.7756e-05 - mae: 0.0026 - val_loss: 5.8106e-05 - val_mae: 0.0027\n",
      "Epoch 221/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.3454e-05 - mae: 0.0029 - val_loss: 6.2834e-05 - val_mae: 0.0031\n",
      "Epoch 222/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.1811e-05 - mae: 0.0029 - val_loss: 5.8181e-05 - val_mae: 0.0028\n",
      "Epoch 223/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.7350e-05 - mae: 0.0029 - val_loss: 5.1174e-05 - val_mae: 0.0022\n",
      "Epoch 224/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.2385e-05 - mae: 0.0028 - val_loss: 5.1400e-05 - val_mae: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.0023e-05 - mae: 0.0027 - val_loss: 5.3405e-05 - val_mae: 0.0022\n",
      "Epoch 226/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.6332e-05 - mae: 0.0025 - val_loss: 6.4839e-05 - val_mae: 0.0030\n",
      "Epoch 227/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.8126e-05 - mae: 0.0030 - val_loss: 5.7315e-05 - val_mae: 0.0027\n",
      "Epoch 228/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.7968e-05 - mae: 0.0026 - val_loss: 6.4354e-05 - val_mae: 0.0031\n",
      "Epoch 229/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.8291e-05 - mae: 0.0027 - val_loss: 5.5527e-05 - val_mae: 0.0027\n",
      "Epoch 230/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.6498e-05 - mae: 0.0026 - val_loss: 5.5868e-05 - val_mae: 0.0026\n",
      "Epoch 231/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.8781e-05 - mae: 0.0027 - val_loss: 5.6542e-05 - val_mae: 0.0027\n",
      "Epoch 232/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.3277e-05 - mae: 0.0029 - val_loss: 6.5426e-05 - val_mae: 0.0031\n",
      "Epoch 233/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.0420e-05 - mae: 0.0028 - val_loss: 7.0656e-05 - val_mae: 0.0032\n",
      "Epoch 234/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.3327e-05 - mae: 0.0029 - val_loss: 8.4492e-05 - val_mae: 0.0039\n",
      "Epoch 235/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.1793e-05 - mae: 0.0028 - val_loss: 6.3084e-05 - val_mae: 0.0031\n",
      "Epoch 236/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5626e-05 - mae: 0.0025 - val_loss: 6.1277e-05 - val_mae: 0.0029\n",
      "Epoch 237/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.8951e-05 - mae: 0.0027 - val_loss: 6.2721e-05 - val_mae: 0.0035\n",
      "Epoch 238/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.9548e-05 - mae: 0.0027 - val_loss: 8.1340e-05 - val_mae: 0.0037\n",
      "Epoch 239/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.9676e-05 - mae: 0.0027 - val_loss: 5.8275e-05 - val_mae: 0.0030\n",
      "Epoch 240/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.5536e-05 - mae: 0.0025 - val_loss: 6.3051e-05 - val_mae: 0.0031\n",
      "Epoch 241/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.8082e-05 - mae: 0.0026 - val_loss: 5.9891e-05 - val_mae: 0.0028\n",
      "Epoch 242/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.7972e-05 - mae: 0.0031 - val_loss: 6.4363e-05 - val_mae: 0.0030\n",
      "Epoch 243/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.0003e-05 - mae: 0.0028 - val_loss: 5.6740e-05 - val_mae: 0.0028\n",
      "Epoch 244/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5176e-05 - mae: 0.0025 - val_loss: 5.4399e-05 - val_mae: 0.0025\n",
      "Epoch 245/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.8801e-05 - mae: 0.0026 - val_loss: 8.4310e-05 - val_mae: 0.0041\n",
      "Epoch 246/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 5.4919e-05 - mae: 0.0029 - val_loss: 6.3334e-05 - val_mae: 0.0032\n",
      "Epoch 247/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.8976e-05 - mae: 0.0027 - val_loss: 6.0461e-05 - val_mae: 0.0032\n",
      "Epoch 248/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.5576e-05 - mae: 0.0025 - val_loss: 7.2264e-05 - val_mae: 0.0033\n",
      "Epoch 249/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 5.1910e-05 - mae: 0.0029 - val_loss: 6.8018e-05 - val_mae: 0.0030\n",
      "Epoch 250/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.8756e-05 - mae: 0.0026 - val_loss: 5.6745e-05 - val_mae: 0.0026\n",
      "Epoch 251/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5355e-05 - mae: 0.0025 - val_loss: 5.8104e-05 - val_mae: 0.0029\n",
      "Epoch 252/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.6229e-05 - mae: 0.0025 - val_loss: 5.9266e-05 - val_mae: 0.0029\n",
      "Epoch 253/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 5.2161e-05 - mae: 0.0028 - val_loss: 6.7536e-05 - val_mae: 0.0032\n",
      "Epoch 254/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5514e-05 - mae: 0.0025 - val_loss: 5.3890e-05 - val_mae: 0.0025\n",
      "Epoch 255/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.3430e-05 - mae: 0.0029 - val_loss: 5.7910e-05 - val_mae: 0.0026\n",
      "Epoch 256/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.6312e-05 - mae: 0.0026 - val_loss: 5.5119e-05 - val_mae: 0.0027\n",
      "Epoch 257/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.9702e-05 - mae: 0.0028 - val_loss: 5.6051e-05 - val_mae: 0.0028\n",
      "Epoch 258/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.8328e-05 - mae: 0.0027 - val_loss: 4.9094e-05 - val_mae: 0.0021\n",
      "Epoch 259/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5429e-05 - mae: 0.0025 - val_loss: 5.1673e-05 - val_mae: 0.0023\n",
      "Epoch 260/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.9453e-05 - mae: 0.0027 - val_loss: 6.4938e-05 - val_mae: 0.0034\n",
      "Epoch 261/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.9849e-05 - mae: 0.0027 - val_loss: 5.2073e-05 - val_mae: 0.0024\n",
      "Epoch 262/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.6319e-05 - mae: 0.0025 - val_loss: 5.4689e-05 - val_mae: 0.0029\n",
      "Epoch 263/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4483e-05 - mae: 0.0024 - val_loss: 5.2797e-05 - val_mae: 0.0025\n",
      "Epoch 264/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.6121e-05 - mae: 0.0026 - val_loss: 5.4369e-05 - val_mae: 0.0027\n",
      "Epoch 265/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.5841e-05 - mae: 0.0026 - val_loss: 5.2174e-05 - val_mae: 0.0024\n",
      "Epoch 266/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.6689e-05 - mae: 0.0026 - val_loss: 5.2991e-05 - val_mae: 0.0026\n",
      "Epoch 267/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.5056e-05 - mae: 0.0025 - val_loss: 5.3792e-05 - val_mae: 0.0025\n",
      "Epoch 268/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.8002e-05 - mae: 0.0027 - val_loss: 5.8548e-05 - val_mae: 0.0029\n",
      "Epoch 269/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.1909e-05 - mae: 0.0028 - val_loss: 5.9694e-05 - val_mae: 0.0027\n",
      "Epoch 270/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.5106e-05 - mae: 0.0025 - val_loss: 5.4139e-05 - val_mae: 0.0027\n",
      "Epoch 271/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.2802e-05 - mae: 0.0023 - val_loss: 5.6650e-05 - val_mae: 0.0028\n",
      "Epoch 272/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.9851e-05 - mae: 0.0027 - val_loss: 7.3328e-05 - val_mae: 0.0038\n",
      "Epoch 273/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5906e-05 - mae: 0.0026 - val_loss: 5.5208e-05 - val_mae: 0.0027\n",
      "Epoch 274/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.4705e-05 - mae: 0.0025 - val_loss: 5.1308e-05 - val_mae: 0.0025\n",
      "Epoch 275/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.3050e-05 - mae: 0.0024 - val_loss: 5.2562e-05 - val_mae: 0.0025\n",
      "Epoch 276/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4985e-05 - mae: 0.0025 - val_loss: 5.2027e-05 - val_mae: 0.0024\n",
      "Epoch 277/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.7318e-05 - mae: 0.0026 - val_loss: 6.7441e-05 - val_mae: 0.0036\n",
      "Epoch 278/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.6642e-05 - mae: 0.0026 - val_loss: 5.8551e-05 - val_mae: 0.0028\n",
      "Epoch 279/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5529e-05 - mae: 0.0025 - val_loss: 6.0273e-05 - val_mae: 0.0028\n",
      "Epoch 280/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.3787e-05 - mae: 0.0030 - val_loss: 5.3670e-05 - val_mae: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2367e-05 - mae: 0.0023 - val_loss: 5.2948e-05 - val_mae: 0.0027\n",
      "Epoch 282/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.2936e-05 - mae: 0.0024 - val_loss: 6.8119e-05 - val_mae: 0.0034\n",
      "Epoch 283/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.6307e-05 - mae: 0.0026 - val_loss: 6.8442e-05 - val_mae: 0.0033\n",
      "Epoch 284/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.4131e-05 - mae: 0.0025 - val_loss: 5.3847e-05 - val_mae: 0.0025\n",
      "Epoch 285/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.7642e-05 - mae: 0.0027 - val_loss: 6.6877e-05 - val_mae: 0.0032\n",
      "Epoch 286/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.5975e-05 - mae: 0.0026 - val_loss: 5.2608e-05 - val_mae: 0.0024\n",
      "Epoch 287/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.4287e-05 - mae: 0.0024 - val_loss: 5.1128e-05 - val_mae: 0.0024\n",
      "Epoch 288/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.2943e-05 - mae: 0.0024 - val_loss: 5.1037e-05 - val_mae: 0.0023\n",
      "Epoch 289/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.5859e-05 - mae: 0.0026 - val_loss: 6.6040e-05 - val_mae: 0.0029\n",
      "Epoch 290/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.6667e-05 - mae: 0.0026 - val_loss: 5.2003e-05 - val_mae: 0.0024\n",
      "Epoch 291/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.8068e-05 - mae: 0.0027 - val_loss: 4.9703e-05 - val_mae: 0.0023\n",
      "Epoch 292/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.2859e-05 - mae: 0.0024 - val_loss: 5.0276e-05 - val_mae: 0.0023\n",
      "Epoch 293/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.2119e-05 - mae: 0.0023 - val_loss: 5.3557e-05 - val_mae: 0.0026\n",
      "Epoch 294/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5411e-05 - mae: 0.0026 - val_loss: 5.3222e-05 - val_mae: 0.0025\n",
      "Epoch 295/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.9277e-05 - mae: 0.0026 - val_loss: 5.6764e-05 - val_mae: 0.0027\n",
      "Epoch 296/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.5172e-05 - mae: 0.0025 - val_loss: 5.1063e-05 - val_mae: 0.0024\n",
      "Epoch 297/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.5222e-05 - mae: 0.0025 - val_loss: 5.6528e-05 - val_mae: 0.0027\n",
      "Epoch 298/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.1659e-05 - mae: 0.0030 - val_loss: 6.1591e-05 - val_mae: 0.0034\n",
      "Epoch 299/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.6017e-05 - mae: 0.0026 - val_loss: 5.5453e-05 - val_mae: 0.0026\n",
      "Epoch 300/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5940e-05 - mae: 0.0025 - val_loss: 5.3702e-05 - val_mae: 0.0027\n",
      "Epoch 301/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.4109e-05 - mae: 0.0025 - val_loss: 5.1036e-05 - val_mae: 0.0024\n",
      "Epoch 302/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.7221e-05 - mae: 0.0027 - val_loss: 7.1337e-05 - val_mae: 0.0038\n",
      "Epoch 303/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.5124e-05 - mae: 0.0025 - val_loss: 5.2820e-05 - val_mae: 0.0023\n",
      "Epoch 304/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.3594e-05 - mae: 0.0024 - val_loss: 5.7202e-05 - val_mae: 0.0027\n",
      "Epoch 305/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.4968e-05 - mae: 0.0025 - val_loss: 6.3628e-05 - val_mae: 0.0031\n",
      "Epoch 306/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.7043e-05 - mae: 0.0026 - val_loss: 6.5693e-05 - val_mae: 0.0036\n",
      "Epoch 307/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.5580e-05 - mae: 0.0026 - val_loss: 7.2775e-05 - val_mae: 0.0034\n",
      "Epoch 308/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.8966e-05 - mae: 0.0027 - val_loss: 4.8934e-05 - val_mae: 0.0021\n",
      "Epoch 309/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.3414e-05 - mae: 0.0024 - val_loss: 5.2226e-05 - val_mae: 0.0026\n",
      "Epoch 310/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4220e-05 - mae: 0.0025 - val_loss: 5.2259e-05 - val_mae: 0.0024\n",
      "Epoch 311/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.4215e-05 - mae: 0.0025 - val_loss: 6.0776e-05 - val_mae: 0.0031\n",
      "Epoch 312/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.4271e-05 - mae: 0.0025 - val_loss: 5.5540e-05 - val_mae: 0.0029\n",
      "Epoch 313/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2448e-05 - mae: 0.0024 - val_loss: 5.4300e-05 - val_mae: 0.0024\n",
      "Epoch 314/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.3970e-05 - mae: 0.0025 - val_loss: 4.7616e-05 - val_mae: 0.0023\n",
      "Epoch 315/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.2284e-05 - mae: 0.0024 - val_loss: 6.4322e-05 - val_mae: 0.0030\n",
      "Epoch 316/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.6045e-05 - mae: 0.0026 - val_loss: 5.0227e-05 - val_mae: 0.0023\n",
      "Epoch 317/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.4114e-05 - mae: 0.0025 - val_loss: 6.1319e-05 - val_mae: 0.0033\n",
      "Epoch 318/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.4525e-05 - mae: 0.0026 - val_loss: 6.2862e-05 - val_mae: 0.0033\n",
      "Epoch 319/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.3838e-05 - mae: 0.0025 - val_loss: 5.6144e-05 - val_mae: 0.0028\n",
      "Epoch 320/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.2977e-05 - mae: 0.0024 - val_loss: 6.8502e-05 - val_mae: 0.0035\n",
      "Epoch 321/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.6847e-05 - mae: 0.0026 - val_loss: 5.2361e-05 - val_mae: 0.0025\n",
      "Epoch 322/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.3875e-05 - mae: 0.0024 - val_loss: 5.6385e-05 - val_mae: 0.0027\n",
      "Epoch 323/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.8002e-05 - mae: 0.0028 - val_loss: 5.3806e-05 - val_mae: 0.0026\n",
      "Epoch 324/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.4899e-05 - mae: 0.0025 - val_loss: 5.0682e-05 - val_mae: 0.0024\n",
      "Epoch 325/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.3738e-05 - mae: 0.0024 - val_loss: 6.6552e-05 - val_mae: 0.0034\n",
      "Epoch 326/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5471e-05 - mae: 0.0025 - val_loss: 4.8057e-05 - val_mae: 0.0022\n",
      "Epoch 327/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.9064e-05 - mae: 0.0028 - val_loss: 5.2201e-05 - val_mae: 0.0024\n",
      "Epoch 328/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.3812e-05 - mae: 0.0024 - val_loss: 5.4535e-05 - val_mae: 0.0026\n",
      "Epoch 329/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.4797e-05 - mae: 0.0025 - val_loss: 5.2403e-05 - val_mae: 0.0027\n",
      "Epoch 330/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.3461e-05 - mae: 0.0024 - val_loss: 5.4648e-05 - val_mae: 0.0027\n",
      "Epoch 331/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.4008e-05 - mae: 0.0025 - val_loss: 5.3278e-05 - val_mae: 0.0026\n",
      "Epoch 332/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2934e-05 - mae: 0.0025 - val_loss: 7.3185e-05 - val_mae: 0.0040\n",
      "Epoch 333/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2335e-05 - mae: 0.0024 - val_loss: 5.2561e-05 - val_mae: 0.0025\n",
      "Epoch 334/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.4407e-05 - mae: 0.0026 - val_loss: 5.0274e-05 - val_mae: 0.0026\n",
      "Epoch 335/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.0789e-05 - mae: 0.0023 - val_loss: 4.9752e-05 - val_mae: 0.0023\n",
      "Epoch 336/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.1710e-05 - mae: 0.0024 - val_loss: 5.9224e-05 - val_mae: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.3794e-05 - mae: 0.0025 - val_loss: 4.8674e-05 - val_mae: 0.0023\n",
      "Epoch 338/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.1735e-05 - mae: 0.0024 - val_loss: 5.8282e-05 - val_mae: 0.0030\n",
      "Epoch 339/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.1614e-05 - mae: 0.0024 - val_loss: 4.9245e-05 - val_mae: 0.0023\n",
      "Epoch 340/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 3.9317e-05 - mae: 0.0022 - val_loss: 4.6532e-05 - val_mae: 0.0022\n",
      "Epoch 341/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.2143e-05 - mae: 0.0024 - val_loss: 5.0435e-05 - val_mae: 0.0026\n",
      "Epoch 342/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2211e-05 - mae: 0.0024 - val_loss: 5.2228e-05 - val_mae: 0.0024\n",
      "Epoch 343/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.3060e-05 - mae: 0.0025 - val_loss: 5.1086e-05 - val_mae: 0.0026\n",
      "Epoch 344/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.3293e-05 - mae: 0.0025 - val_loss: 4.8459e-05 - val_mae: 0.0024\n",
      "Epoch 345/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4173e-05 - mae: 0.0026 - val_loss: 6.5095e-05 - val_mae: 0.0033\n",
      "Epoch 346/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5334e-05 - mae: 0.0027 - val_loss: 6.6330e-05 - val_mae: 0.0035\n",
      "Epoch 347/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 4.5200e-05 - mae: 0.0026 - val_loss: 4.8225e-05 - val_mae: 0.0023\n",
      "Epoch 348/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.1985e-05 - mae: 0.0024 - val_loss: 4.8228e-05 - val_mae: 0.0023\n",
      "Epoch 349/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.0164e-05 - mae: 0.0023 - val_loss: 4.8835e-05 - val_mae: 0.0024\n",
      "Epoch 350/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2064e-05 - mae: 0.0024 - val_loss: 5.0977e-05 - val_mae: 0.0027\n",
      "Epoch 351/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.2216e-05 - mae: 0.0024 - val_loss: 5.0123e-05 - val_mae: 0.0024\n",
      "Epoch 352/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.7564e-05 - mae: 0.0027 - val_loss: 6.4020e-05 - val_mae: 0.0036\n",
      "Epoch 353/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4337e-05 - mae: 0.0026 - val_loss: 4.7903e-05 - val_mae: 0.0023\n",
      "Epoch 354/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.0478e-05 - mae: 0.0023 - val_loss: 5.2032e-05 - val_mae: 0.0027\n",
      "Epoch 355/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.1351e-05 - mae: 0.0024 - val_loss: 5.0839e-05 - val_mae: 0.0024\n",
      "Epoch 356/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.6027e-05 - mae: 0.0026 - val_loss: 5.2442e-05 - val_mae: 0.0026\n",
      "Epoch 357/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.3171e-05 - mae: 0.0025 - val_loss: 5.8487e-05 - val_mae: 0.0034\n",
      "Epoch 358/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 3.9944e-05 - mae: 0.0023 - val_loss: 4.9493e-05 - val_mae: 0.0023\n"
     ]
    }
   ],
   "source": [
    "history = model_RNN_LSTM_3d.fit(x_train,y_train, epochs=1000, batch_size=16, validation_split=0.2,callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670470311929,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "4kEwHgcTThyk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_RNN_LSTM_3d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_RNN_LSTM_3d\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/sep_1/lstm.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_RNN_LSTM_3d' is not defined"
     ]
    }
   ],
   "source": [
    "# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5\")\n",
    "# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5\")\n",
    "model_RNN_LSTM_3d.save(\"./models/traj_point/lstm_rnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1549,
     "status": "ok",
     "timestamp": 1670464132234,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "_lI1n5rWk7DF",
    "outputId": "11fbc446-b78b-4739-c7b0-cdfd12b12134"
   },
   "outputs": [],
   "source": [
    "# classification models\n",
    "# model_load = load_model('/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5')\n",
    "# model_load = load_model('/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5')\n",
    "model_load = load_model('./models/sep_0.7/lstm_rnn.h5')\n",
    "\n",
    "\n",
    "# 3d models\n",
    "# model_load = load_model('./models/traj_point/lstm_rnn.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 200, 3)]          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200, 15)           60        \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 200, 15)           465       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 15)           1860      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200, 9)            144       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,529\n",
      "Trainable params: 2,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_load.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 18ms/step - loss: 0.2631 - accuracy: 0.9007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26308029890060425, 0.900730311870575]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2674 - accuracy: 0.8985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.267398864030838, 0.898490846157074]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the lengths of x_test\n",
    "# lengths = np.array([len(i) for i in x_test_])\n",
    "# Removing trajectories with <=12 length\n",
    "# idx = np.where(lengths <= 12)[0]\n",
    "# [y_test_.pop(j-i) for i,j in enumerate(idx)]\n",
    "# [x_test_.pop(j-i) for i,j in enumerate(idx)];\n",
    "# Checking\n",
    "# np.where(lengths <= 12)[0]\n",
    "\n",
    "# dict_l = defaultdict(list)\n",
    "\n",
    "# for i in tqdm.tqdm(range(max(lengths)-9)):\n",
    "#     idx = np.where(lengths >= i+12)[0]\n",
    "#     x_ = [x_test_[l].values.tolist()[:i+2] for l in idx]\n",
    "#     y_ = [y_test_[l].values.tolist()[i+2:i+12] for l in idx]\n",
    "#     if len(idx) == 1:\n",
    "#             break\n",
    "#     for k in range(10):\n",
    "\n",
    "#         temp = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_, padding='post', dtype='float', maxlen=200, value = -10))\n",
    "\n",
    "#         preds = model_load.predict(temp, verbose = 0)\n",
    "#         preds = preds[:,-1,:]\n",
    "#         [x_[j].append(list(preds[j])) for j in range(len(idx))]\n",
    "#     print(np.array(x_[j])[i+2:] - np.array(y_[j]))\n",
    "#     print(np.array(x_[j]))\n",
    "#     print(np.array(y_[j]))\n",
    "#     helo\n",
    "#     [dict_l[i+2].append(np.mean(np.linalg.norm(),axis =0)) for j in range(len(x_))]\n",
    "# [np.mean(dict_l[i]) for i in dict_l.keys()]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
