{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1670472818051,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "yu0OV4sf1nk8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472819084,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "svhuDSYP1nk-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import collections\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "from IPython.core.display import HTML\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472822205,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "vGhXf6lC1nk_",
    "outputId": "478747bb-6f8c-481d-ebb4-82b506528c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.11.0\n",
      "keras version 2.11.0\n",
      "Eager Execution Enabled: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 11:55:00.101821: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-12 11:55:00.718504: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 30972 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:af:00.0, compute capability: 7.0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of replicas: 1\n",
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Enable/Disable Eager Execution\n",
    "# Reference: https://www.tensorflow.org/guide/eager\n",
    "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
    "# without building graphs\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "print(\"keras version\", tf.keras.__version__)\n",
    "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
    "\n",
    "# Get the number of replicas \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "devices = tf.config.experimental.get_visible_devices()\n",
    "print(\"Devices:\", devices)\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
    "\n",
    "# Better performance with the tf.data API\n",
    "# Reference: https://www.tensorflow.org/guide/data_performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtMgghJO1nlA"
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "executionInfo": {
     "elapsed": 7156,
     "status": "ok",
     "timestamp": 1670461970917,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "eSg0NnAgXpRg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !unzip \"./all_data/sep_0.7/data.zip\" -d \"./temp_data/sep_0.7/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472827844,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "tbOPJ2jS1nlB"
   },
   "outputs": [],
   "source": [
    "# Getting the folder names \n",
    "folder_names = glob.glob(\"./temp_data/sep_0.7/data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670472829094,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "JkZ1ScX01nlB"
   },
   "outputs": [],
   "source": [
    "# Getting the data names\n",
    "data_names = []\n",
    "for i in folder_names:\n",
    "    data_names.append(glob.glob(i+\"/*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng5z05Q61nlC"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "executionInfo": {
     "elapsed": 14851,
     "status": "ok",
     "timestamp": 1670472843943,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "06RUU7IU1nlD"
   },
   "outputs": [],
   "source": [
    "# Datasets to skip \n",
    "skip = []\n",
    "\n",
    "# Labels of the datasets\n",
    "labels = []\n",
    "\n",
    "# Data list \n",
    "data = []\n",
    "\n",
    "\n",
    "# Getting the labels and data for each dataset\n",
    "for i in range(len(data_names)):\n",
    "    if i in skip:\n",
    "        continue\n",
    "    \n",
    "    for j in range(len(data_names[i])):\n",
    "        labels.append([data_names[i][j][data_names[i][j].find(\".csv\")-1]])\n",
    "        \n",
    "        # Cleaning data\n",
    "        df = pd.read_csv(data_names[i][j],skiprows = 1)\n",
    "        df.drop(columns=df.columns[-1], axis=1,  inplace=True)\n",
    "        \n",
    "        data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472843943,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "OhMZiWrx1nlD"
   },
   "outputs": [],
   "source": [
    "# Changing the labels from int to string\n",
    "labels = [int(i)-1 for i in np.reshape(labels,(-1,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets for sep_1\n",
    "target = np.array([[-0.314,1.661,0.45],[0,1.661,0.45],[0.314,1.661,0.45],[-0.314,1.347,0.45],[0,1.347,0.45],[0.314,1.347,0.45],[-0.314,1.033,0.45],[0,1.033,0.45],[0.314,1.033,0.45]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels_3d = [target[i] for i in labels]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3aWbcBR1nlD"
   },
   "source": [
    "## Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "executionInfo": {
     "elapsed": 57502,
     "status": "ok",
     "timestamp": 1670472901442,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "6sJpWHrX1nlE"
   },
   "outputs": [],
   "source": [
    "# Adding the centroid of all the fingers to the data\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for idx_1 in range(len(data)):\n",
    "\n",
    "    \n",
    "    # Grouped columns for centroid\n",
    "    grouped_columns_x = data[idx_1].columns[3::3] \n",
    "    grouped_columns_y = data[idx_1].columns[4::3]\n",
    "    grouped_columns_z = data[idx_1].columns[5::3]\n",
    "    \n",
    "    # Getting the centroid of the finger points\n",
    "    cent_x = np.mean(data[idx_1][grouped_columns_x],axis = 1)\n",
    "    cent_y = np.mean(data[idx_1][grouped_columns_y],axis = 1)\n",
    "    cent_z = np.mean(data[idx_1][grouped_columns_z],axis = 1)\n",
    "    \n",
    "    new_data.append(pd.concat([data[idx_1],cent_x,cent_y,cent_z],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgaA_2SY0MDc"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472901442,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "MUjsQWtJsKIn"
   },
   "outputs": [],
   "source": [
    "# Pulling only the centroid data \n",
    "cent_data = [i.iloc[:,-3:] for i in new_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1670472902684,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "cq550A880PAk",
    "outputId": "8c0ba4d0-9ee8-4885-fe2b-e9f624183928"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = np.array([len(i) for i in cent_data])\n",
    "plt.hist(lengths)\n",
    "plt.xlabel(\"Trajectory length\")\n",
    "plt.ylabel(\"Number of trajectories\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "ymWVIli90Uu8"
   },
   "outputs": [],
   "source": [
    "# Removing trajectories with <=5 length\n",
    "idx = np.where(lengths <= 5.)[0]\n",
    "[labels.pop(j-i) for i,j in enumerate(idx)]\n",
    "[labels_3d.pop(j-i) for i,j in enumerate(idx)]\n",
    "[cent_data.pop(j-i) for i,j in enumerate(idx)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "9X0N0OYxcyyJ",
    "outputId": "e7d207da-0b10-4219-ad7d-a7ab34848596"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see if it worked \n",
    "lengths = np.array([len(i) for i in cent_data])\n",
    "np.where(lengths <= 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "hfPRW0S7UN4b"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(cent_data, labels, test_size=0.2)\n",
    "# x_train, x_test, y_train, y_test = train_test_split(cent_data, labels_3d, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_dZtq9NzYnZ"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902686,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "LiOpfkOpaYuO"
   },
   "outputs": [],
   "source": [
    "x_train_aug = []\n",
    "for idx,i in enumerate(x_train):\n",
    "    ch = np.random.choice([0,1],p = [0.3,0.7])\n",
    "\n",
    "    flag = 0 \n",
    "\n",
    "    if ch == 0: # Perform data augmentation\n",
    "\n",
    "        trim = len(i)//2\n",
    "\n",
    "        if trim >= 5: # Trim if the lengths are greater than 5\n",
    "\n",
    "            aug = i.head(trim)\n",
    "\n",
    "        else: # If lengths are not greater than 1, don't trim\n",
    "\n",
    "            aug = i\n",
    "    else:\n",
    "        aug = i\n",
    "\n",
    "\n",
    "    x_train_aug.append(aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902687,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "4OWcaGqDBPvm",
    "outputId": "560f265e-c919-47cb-e3f7-41284420d962"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(709, 709)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the lengths after and before augmentation\n",
    "len(x_train_aug), len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902687,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "kKLJbGtv1nlE"
   },
   "outputs": [],
   "source": [
    "# Getting the data in the required format for the model\n",
    "# Creating labels for RNN's output \n",
    "y_train = [[dt]*200 for idx,dt in enumerate(y_train)]\n",
    "y_test = [[dt]*200 for idx,dt in enumerate(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "evCXyI6-1nlE"
   },
   "outputs": [],
   "source": [
    "# Sequence length is based on data analysis\n",
    "x_train = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_train, padding='post', dtype='float', maxlen=200))\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "x_test = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_test, padding='post', dtype='float', maxlen=200))\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "ryFy62Mk1nlF"
   },
   "outputs": [],
   "source": [
    "# One hot encoding the data for training - not required for label_3d\n",
    "y_train = tf.one_hot(y_train, 9, on_value = 1.0, off_value = 0.0)\n",
    "y_test = tf.one_hot(y_test, 9, on_value = 1.0, off_value = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJc39yrs1nlE"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "y12mcLmQ1nlF"
   },
   "outputs": [],
   "source": [
    "hidden_size= 10\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "RNN_1 = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN_1(ip_reformed)\n",
    "\n",
    "RNN_2 = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_2 = RNN_2(h_1)\n",
    "\n",
    "\n",
    "dense_2 = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense_2(h_2)\n",
    "\n",
    "model_RNN = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the RNN model - labels_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size= 10\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "RNN_1 = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN_1(ip_reformed)\n",
    "\n",
    "RNN_2 = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_2 = RNN_2(h_1)\n",
    "\n",
    "\n",
    "dense_2 = tf.keras.layers.Dense(3, activation='linear')\n",
    "output = dense_2(h_2)\n",
    "\n",
    "model_RNN_3d = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN_3d.compile(loss='mse', metrics = ['mse'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902689,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "LJC8EL0egiGL"
   },
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h = LSTM(ip_reformed)\n",
    "\n",
    "dense = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense(h)\n",
    "\n",
    "model_LSTM = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_LSTM.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM model - labels_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h = LSTM(ip_reformed)\n",
    "\n",
    "dense = tf.keras.layers.Dense(3, activation='linear')\n",
    "output = dense(h)\n",
    "\n",
    "model_LSTM_3d = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_LSTM_3d.compile(loss='mse', metrics = ['mse'],optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM+RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472905553,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "qsyhNfUNdb9D"
   },
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "RNN = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN(ip_reformed)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h_2 = LSTM(h_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense(h_2)\n",
    "\n",
    "model_RNN_LSTM = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN_LSTM.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM+RNN model - labels_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "RNN = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN(ip_reformed)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h_2 = LSTM(h_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(3, activation='linear')\n",
    "output = dense(h_2)\n",
    "\n",
    "model_RNN_LSTM_3d = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN_LSTM_3d.compile(loss='mse', metrics = ['mse'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472905553,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "29kaMRnt1nlF",
    "outputId": "96eed065-c571-49cd-fffa-6e4ef9d4d358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 200, 3)]          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200, 15)           60        \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 15)           1860      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200, 9)            144       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,064\n",
      "Trainable params: 2,064\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_LSTM.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "executionInfo": {
     "elapsed": 1593,
     "status": "ok",
     "timestamp": 1670472927009,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "7B3g6dUGOOoU"
   },
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=100,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdnYYPv_1nlF",
    "outputId": "a1bb33a5-8b8c-446d-9016-a14cbc846054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-12 12:27:36.962874: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x563779732870 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-12 12:27:36.962896: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-SXM2-32GB, Compute Capability 7.0\n",
      "2022-12-12 12:27:36.967191: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-12 12:27:37.081779: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 6s 97ms/step - loss: 2.2071 - accuracy: 0.1029 - val_loss: 2.2136 - val_accuracy: 0.1036\n",
      "Epoch 2/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 2.1965 - accuracy: 0.1277 - val_loss: 2.1989 - val_accuracy: 0.1338\n",
      "Epoch 3/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 2.1904 - accuracy: 0.1319 - val_loss: 2.2066 - val_accuracy: 0.1260\n",
      "Epoch 4/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 2.1845 - accuracy: 0.1312 - val_loss: 2.1825 - val_accuracy: 0.1268\n",
      "Epoch 5/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.9095 - accuracy: 0.1756 - val_loss: 1.6946 - val_accuracy: 0.2362\n",
      "Epoch 6/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.7227 - accuracy: 0.2195 - val_loss: 1.7187 - val_accuracy: 0.2272\n",
      "Epoch 7/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.6847 - accuracy: 0.2081 - val_loss: 1.7014 - val_accuracy: 0.2273\n",
      "Epoch 8/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.6898 - accuracy: 0.2173 - val_loss: 1.6488 - val_accuracy: 0.1892\n",
      "Epoch 9/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 1.5873 - accuracy: 0.2585 - val_loss: 1.3868 - val_accuracy: 0.2437\n",
      "Epoch 10/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3980 - accuracy: 0.2814 - val_loss: 1.3498 - val_accuracy: 0.2673\n",
      "Epoch 11/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3472 - accuracy: 0.3174 - val_loss: 1.3135 - val_accuracy: 0.3020\n",
      "Epoch 12/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3058 - accuracy: 0.3034 - val_loss: 1.2822 - val_accuracy: 0.2727\n",
      "Epoch 13/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.5219 - accuracy: 0.2829 - val_loss: 1.6616 - val_accuracy: 0.2732\n",
      "Epoch 14/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.8107 - accuracy: 0.2329 - val_loss: 1.7296 - val_accuracy: 0.1550\n",
      "Epoch 15/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.5675 - accuracy: 0.2872 - val_loss: 1.3900 - val_accuracy: 0.3387\n",
      "Epoch 16/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3647 - accuracy: 0.2848 - val_loss: 1.3405 - val_accuracy: 0.2914\n",
      "Epoch 17/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3354 - accuracy: 0.3287 - val_loss: 1.3431 - val_accuracy: 0.2848\n",
      "Epoch 18/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3788 - accuracy: 0.2930 - val_loss: 1.3499 - val_accuracy: 0.2601\n",
      "Epoch 19/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3348 - accuracy: 0.3379 - val_loss: 1.3377 - val_accuracy: 0.2954\n",
      "Epoch 20/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3065 - accuracy: 0.3312 - val_loss: 1.3185 - val_accuracy: 0.2869\n",
      "Epoch 21/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3164 - accuracy: 0.3576 - val_loss: 1.2909 - val_accuracy: 0.3313\n",
      "Epoch 22/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3024 - accuracy: 0.3547 - val_loss: 1.3065 - val_accuracy: 0.2972\n",
      "Epoch 23/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3247 - accuracy: 0.3661 - val_loss: 1.2756 - val_accuracy: 0.4009\n",
      "Epoch 24/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.2670 - accuracy: 0.3999 - val_loss: 1.3006 - val_accuracy: 0.3226\n",
      "Epoch 25/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.8403 - accuracy: 0.2561 - val_loss: 1.6925 - val_accuracy: 0.2118\n",
      "Epoch 26/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 1.5425 - accuracy: 0.3314 - val_loss: 1.4012 - val_accuracy: 0.3228\n",
      "Epoch 27/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.3116 - accuracy: 0.4230 - val_loss: 1.2724 - val_accuracy: 0.3882\n",
      "Epoch 28/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 1.1894 - accuracy: 0.4527 - val_loss: 1.1810 - val_accuracy: 0.4525\n",
      "Epoch 29/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.2233 - accuracy: 0.4650 - val_loss: 1.2322 - val_accuracy: 0.4605\n",
      "Epoch 30/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.2610 - accuracy: 0.4059 - val_loss: 1.1925 - val_accuracy: 0.4611\n",
      "Epoch 31/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.1322 - accuracy: 0.4903 - val_loss: 1.1022 - val_accuracy: 0.5155\n",
      "Epoch 32/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.1084 - accuracy: 0.4821 - val_loss: 1.1855 - val_accuracy: 0.3962\n",
      "Epoch 33/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.0759 - accuracy: 0.5095 - val_loss: 1.0699 - val_accuracy: 0.4890\n",
      "Epoch 34/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.1192 - accuracy: 0.4897 - val_loss: 1.1870 - val_accuracy: 0.3895\n",
      "Epoch 35/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.0751 - accuracy: 0.5140 - val_loss: 1.0435 - val_accuracy: 0.5152\n",
      "Epoch 36/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 1.0159 - accuracy: 0.5371 - val_loss: 0.9940 - val_accuracy: 0.5816\n",
      "Epoch 37/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.9922 - accuracy: 0.5596 - val_loss: 1.1617 - val_accuracy: 0.4281\n",
      "Epoch 38/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 1.0008 - accuracy: 0.5760 - val_loss: 1.0015 - val_accuracy: 0.5194\n",
      "Epoch 39/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.9225 - accuracy: 0.6020 - val_loss: 0.9173 - val_accuracy: 0.6085\n",
      "Epoch 40/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.9189 - accuracy: 0.6013 - val_loss: 1.8117 - val_accuracy: 0.3293\n",
      "Epoch 41/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.5411 - accuracy: 0.3998 - val_loss: 1.1951 - val_accuracy: 0.4462\n",
      "Epoch 42/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 1.1663 - accuracy: 0.4273 - val_loss: 1.0768 - val_accuracy: 0.5255\n",
      "Epoch 43/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.9933 - accuracy: 0.5656 - val_loss: 1.0106 - val_accuracy: 0.5388\n",
      "Epoch 44/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.9128 - accuracy: 0.6041 - val_loss: 0.9197 - val_accuracy: 0.6117\n",
      "Epoch 45/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.8629 - accuracy: 0.6507 - val_loss: 0.8247 - val_accuracy: 0.6350\n",
      "Epoch 46/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.8161 - accuracy: 0.6567 - val_loss: 0.8152 - val_accuracy: 0.6497\n",
      "Epoch 47/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.8909 - accuracy: 0.6104 - val_loss: 0.8274 - val_accuracy: 0.6438\n",
      "Epoch 48/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.7961 - accuracy: 0.6661 - val_loss: 0.7947 - val_accuracy: 0.6518\n",
      "Epoch 49/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.8016 - accuracy: 0.6532 - val_loss: 0.8543 - val_accuracy: 0.5733\n",
      "Epoch 50/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.8502 - accuracy: 0.6287 - val_loss: 0.8126 - val_accuracy: 0.6448\n",
      "Epoch 51/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.8182 - accuracy: 0.6404 - val_loss: 0.7709 - val_accuracy: 0.6661\n",
      "Epoch 52/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.7892 - accuracy: 0.6612 - val_loss: 0.7581 - val_accuracy: 0.6482\n",
      "Epoch 53/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.7555 - accuracy: 0.6668 - val_loss: 0.7561 - val_accuracy: 0.6518\n",
      "Epoch 54/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.7848 - accuracy: 0.6474 - val_loss: 0.7609 - val_accuracy: 0.6881\n",
      "Epoch 55/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.7590 - accuracy: 0.6648 - val_loss: 0.7144 - val_accuracy: 0.7112\n",
      "Epoch 56/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.7104 - accuracy: 0.7289 - val_loss: 0.7292 - val_accuracy: 0.7303\n",
      "Epoch 57/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.6732 - accuracy: 0.7423 - val_loss: 0.6607 - val_accuracy: 0.7467\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6463 - accuracy: 0.7463 - val_loss: 0.6196 - val_accuracy: 0.7849\n",
      "Epoch 59/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.7380 - accuracy: 0.6950 - val_loss: 0.6351 - val_accuracy: 0.7863\n",
      "Epoch 60/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.7154 - accuracy: 0.7119 - val_loss: 0.6130 - val_accuracy: 0.8173\n",
      "Epoch 61/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.6395 - accuracy: 0.7650 - val_loss: 0.5885 - val_accuracy: 0.7882\n",
      "Epoch 62/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6329 - accuracy: 0.7576 - val_loss: 0.5827 - val_accuracy: 0.8049\n",
      "Epoch 63/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.6319 - accuracy: 0.7431 - val_loss: 0.5844 - val_accuracy: 0.7816\n",
      "Epoch 64/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5950 - accuracy: 0.7666 - val_loss: 0.5497 - val_accuracy: 0.8049\n",
      "Epoch 65/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6259 - accuracy: 0.7687 - val_loss: 0.8194 - val_accuracy: 0.6432\n",
      "Epoch 66/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6344 - accuracy: 0.7665 - val_loss: 0.5105 - val_accuracy: 0.8346\n",
      "Epoch 67/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5429 - accuracy: 0.8120 - val_loss: 0.5809 - val_accuracy: 0.7521\n",
      "Epoch 68/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.8020 - accuracy: 0.6980 - val_loss: 0.6567 - val_accuracy: 0.7255\n",
      "Epoch 69/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5920 - accuracy: 0.7950 - val_loss: 0.5245 - val_accuracy: 0.8121\n",
      "Epoch 70/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5104 - accuracy: 0.8284 - val_loss: 0.4935 - val_accuracy: 0.8476\n",
      "Epoch 71/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5565 - accuracy: 0.8020 - val_loss: 0.6032 - val_accuracy: 0.7376\n",
      "Epoch 72/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.5658 - accuracy: 0.7743 - val_loss: 0.4823 - val_accuracy: 0.8546\n",
      "Epoch 73/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5123 - accuracy: 0.8215 - val_loss: 0.4570 - val_accuracy: 0.8602\n",
      "Epoch 74/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.4809 - accuracy: 0.8278 - val_loss: 0.4467 - val_accuracy: 0.8465\n",
      "Epoch 75/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4912 - accuracy: 0.8182 - val_loss: 0.4259 - val_accuracy: 0.8687\n",
      "Epoch 76/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4318 - accuracy: 0.8591 - val_loss: 0.4041 - val_accuracy: 0.8696\n",
      "Epoch 77/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4221 - accuracy: 0.8594 - val_loss: 0.4048 - val_accuracy: 0.8690\n",
      "Epoch 78/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4484 - accuracy: 0.8421 - val_loss: 0.4820 - val_accuracy: 0.8289\n",
      "Epoch 79/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4446 - accuracy: 0.8479 - val_loss: 0.3928 - val_accuracy: 0.8701\n",
      "Epoch 80/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4968 - accuracy: 0.8236 - val_loss: 0.5208 - val_accuracy: 0.8056\n",
      "Epoch 81/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.7258 - accuracy: 0.7569 - val_loss: 0.4658 - val_accuracy: 0.8595\n",
      "Epoch 82/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4946 - accuracy: 0.8316 - val_loss: 0.4459 - val_accuracy: 0.8516\n",
      "Epoch 83/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.4642 - accuracy: 0.8418 - val_loss: 0.6186 - val_accuracy: 0.7529\n",
      "Epoch 84/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5266 - accuracy: 0.8080 - val_loss: 0.4862 - val_accuracy: 0.8068\n",
      "Epoch 85/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4770 - accuracy: 0.8278 - val_loss: 0.5076 - val_accuracy: 0.8055\n",
      "Epoch 86/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5789 - accuracy: 0.7785 - val_loss: 0.7890 - val_accuracy: 0.6970\n",
      "Epoch 87/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 1.0120 - accuracy: 0.6694 - val_loss: 0.7937 - val_accuracy: 0.6365\n",
      "Epoch 88/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6935 - accuracy: 0.7085 - val_loss: 0.5999 - val_accuracy: 0.7677\n",
      "Epoch 89/1000\n",
      "36/36 [==============================] - 3s 85ms/step - loss: 0.4828 - accuracy: 0.8416 - val_loss: 0.4365 - val_accuracy: 0.8497\n",
      "Epoch 90/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4191 - accuracy: 0.8611 - val_loss: 0.3938 - val_accuracy: 0.8713\n",
      "Epoch 91/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.5946 - accuracy: 0.8078 - val_loss: 0.4888 - val_accuracy: 0.8357\n",
      "Epoch 92/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4532 - accuracy: 0.8427 - val_loss: 0.4011 - val_accuracy: 0.8613\n",
      "Epoch 93/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4211 - accuracy: 0.8523 - val_loss: 0.3768 - val_accuracy: 0.8712\n",
      "Epoch 94/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4096 - accuracy: 0.8530 - val_loss: 0.5343 - val_accuracy: 0.7896\n",
      "Epoch 95/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4796 - accuracy: 0.8235 - val_loss: 1.0618 - val_accuracy: 0.6769\n",
      "Epoch 96/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6352 - accuracy: 0.7540 - val_loss: 0.4642 - val_accuracy: 0.8502\n",
      "Epoch 97/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4548 - accuracy: 0.8504 - val_loss: 0.4406 - val_accuracy: 0.8436\n",
      "Epoch 98/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3989 - accuracy: 0.8639 - val_loss: 0.3768 - val_accuracy: 0.8729\n",
      "Epoch 99/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3767 - accuracy: 0.8712 - val_loss: 0.3677 - val_accuracy: 0.8739\n",
      "Epoch 100/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3693 - accuracy: 0.8721 - val_loss: 0.3797 - val_accuracy: 0.8622\n",
      "Epoch 101/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3677 - accuracy: 0.8720 - val_loss: 0.3616 - val_accuracy: 0.8758\n",
      "Epoch 102/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3646 - accuracy: 0.8714 - val_loss: 0.3572 - val_accuracy: 0.8741\n",
      "Epoch 103/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3868 - accuracy: 0.8600 - val_loss: 0.3890 - val_accuracy: 0.8621\n",
      "Epoch 104/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4946 - accuracy: 0.8223 - val_loss: 0.3914 - val_accuracy: 0.8556\n",
      "Epoch 105/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6563 - accuracy: 0.7713 - val_loss: 0.5065 - val_accuracy: 0.8228\n",
      "Epoch 106/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4511 - accuracy: 0.8472 - val_loss: 0.3911 - val_accuracy: 0.8745\n",
      "Epoch 107/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3809 - accuracy: 0.8742 - val_loss: 0.3616 - val_accuracy: 0.8755\n",
      "Epoch 108/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3624 - accuracy: 0.8741 - val_loss: 0.3544 - val_accuracy: 0.8758\n",
      "Epoch 109/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3578 - accuracy: 0.8743 - val_loss: 0.3507 - val_accuracy: 0.8761\n",
      "Epoch 110/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3543 - accuracy: 0.8759 - val_loss: 0.3493 - val_accuracy: 0.8769\n",
      "Epoch 111/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3522 - accuracy: 0.8745 - val_loss: 0.3452 - val_accuracy: 0.8765\n",
      "Epoch 112/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3483 - accuracy: 0.8771 - val_loss: 0.3438 - val_accuracy: 0.8772\n",
      "Epoch 113/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3479 - accuracy: 0.8771 - val_loss: 0.3424 - val_accuracy: 0.8756\n",
      "Epoch 114/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3446 - accuracy: 0.8766 - val_loss: 0.3404 - val_accuracy: 0.8771\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3426 - accuracy: 0.8773 - val_loss: 0.3367 - val_accuracy: 0.8782\n",
      "Epoch 116/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3400 - accuracy: 0.8777 - val_loss: 0.3348 - val_accuracy: 0.8806\n",
      "Epoch 117/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3386 - accuracy: 0.8789 - val_loss: 0.3344 - val_accuracy: 0.8798\n",
      "Epoch 118/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3367 - accuracy: 0.8792 - val_loss: 0.3304 - val_accuracy: 0.8819\n",
      "Epoch 119/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3650 - accuracy: 0.8672 - val_loss: 0.3490 - val_accuracy: 0.8803\n",
      "Epoch 120/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4302 - accuracy: 0.8469 - val_loss: 0.3458 - val_accuracy: 0.8797\n",
      "Epoch 121/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4943 - accuracy: 0.8203 - val_loss: 0.3808 - val_accuracy: 0.8701\n",
      "Epoch 122/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6556 - accuracy: 0.7746 - val_loss: 0.5156 - val_accuracy: 0.8078\n",
      "Epoch 123/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4161 - accuracy: 0.8595 - val_loss: 0.3634 - val_accuracy: 0.8800\n",
      "Epoch 124/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3571 - accuracy: 0.8782 - val_loss: 0.3431 - val_accuracy: 0.8817\n",
      "Epoch 125/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3476 - accuracy: 0.8786 - val_loss: 0.3357 - val_accuracy: 0.8846\n",
      "Epoch 126/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3412 - accuracy: 0.8788 - val_loss: 0.3335 - val_accuracy: 0.8809\n",
      "Epoch 127/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3351 - accuracy: 0.8802 - val_loss: 0.3271 - val_accuracy: 0.8841\n",
      "Epoch 128/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3840 - accuracy: 0.8575 - val_loss: 0.4346 - val_accuracy: 0.8337\n",
      "Epoch 129/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3566 - accuracy: 0.8770 - val_loss: 0.3269 - val_accuracy: 0.8872\n",
      "Epoch 130/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3655 - accuracy: 0.8659 - val_loss: 0.3287 - val_accuracy: 0.8820\n",
      "Epoch 131/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4095 - accuracy: 0.8493 - val_loss: 0.3835 - val_accuracy: 0.8508\n",
      "Epoch 132/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4701 - accuracy: 0.8320 - val_loss: 0.4387 - val_accuracy: 0.8328\n",
      "Epoch 133/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4175 - accuracy: 0.8430 - val_loss: 0.5740 - val_accuracy: 0.7749\n",
      "Epoch 134/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3993 - accuracy: 0.8518 - val_loss: 0.4550 - val_accuracy: 0.8396\n",
      "Epoch 135/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3601 - accuracy: 0.8675 - val_loss: 0.3275 - val_accuracy: 0.8804\n",
      "Epoch 136/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3476 - accuracy: 0.8727 - val_loss: 0.3306 - val_accuracy: 0.8806\n",
      "Epoch 137/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3570 - accuracy: 0.8679 - val_loss: 0.3369 - val_accuracy: 0.8735\n",
      "Epoch 138/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3385 - accuracy: 0.8769 - val_loss: 0.3212 - val_accuracy: 0.8855\n",
      "Epoch 139/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3292 - accuracy: 0.8806 - val_loss: 0.3235 - val_accuracy: 0.8804\n",
      "Epoch 140/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3257 - accuracy: 0.8813 - val_loss: 0.3179 - val_accuracy: 0.8838\n",
      "Epoch 141/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3232 - accuracy: 0.8820 - val_loss: 0.3159 - val_accuracy: 0.8835\n",
      "Epoch 142/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3229 - accuracy: 0.8809 - val_loss: 0.3181 - val_accuracy: 0.8803\n",
      "Epoch 143/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3208 - accuracy: 0.8811 - val_loss: 0.3146 - val_accuracy: 0.8823\n",
      "Epoch 144/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3188 - accuracy: 0.8825 - val_loss: 0.3087 - val_accuracy: 0.8865\n",
      "Epoch 145/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3174 - accuracy: 0.8835 - val_loss: 0.3099 - val_accuracy: 0.8862\n",
      "Epoch 146/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3155 - accuracy: 0.8833 - val_loss: 0.3123 - val_accuracy: 0.8838\n",
      "Epoch 147/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3165 - accuracy: 0.8831 - val_loss: 0.3157 - val_accuracy: 0.8830\n",
      "Epoch 148/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3140 - accuracy: 0.8823 - val_loss: 0.3118 - val_accuracy: 0.8825\n",
      "Epoch 149/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3151 - accuracy: 0.8851 - val_loss: 0.3084 - val_accuracy: 0.8843\n",
      "Epoch 150/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3139 - accuracy: 0.8838 - val_loss: 0.3054 - val_accuracy: 0.8877\n",
      "Epoch 151/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3112 - accuracy: 0.8859 - val_loss: 0.3103 - val_accuracy: 0.8839\n",
      "Epoch 152/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3126 - accuracy: 0.8849 - val_loss: 0.3060 - val_accuracy: 0.8848\n",
      "Epoch 153/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3098 - accuracy: 0.8856 - val_loss: 0.3231 - val_accuracy: 0.8724\n",
      "Epoch 154/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3110 - accuracy: 0.8846 - val_loss: 0.3051 - val_accuracy: 0.8856\n",
      "Epoch 155/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3068 - accuracy: 0.8867 - val_loss: 0.3017 - val_accuracy: 0.8879\n",
      "Epoch 156/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3064 - accuracy: 0.8867 - val_loss: 0.3087 - val_accuracy: 0.8840\n",
      "Epoch 157/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3060 - accuracy: 0.8869 - val_loss: 0.3105 - val_accuracy: 0.8812\n",
      "Epoch 158/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3052 - accuracy: 0.8866 - val_loss: 0.3166 - val_accuracy: 0.8814\n",
      "Epoch 159/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3062 - accuracy: 0.8855 - val_loss: 0.3031 - val_accuracy: 0.8869\n",
      "Epoch 160/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3052 - accuracy: 0.8855 - val_loss: 0.2981 - val_accuracy: 0.8883\n",
      "Epoch 161/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3042 - accuracy: 0.8870 - val_loss: 0.3074 - val_accuracy: 0.8847\n",
      "Epoch 162/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3052 - accuracy: 0.8871 - val_loss: 0.3023 - val_accuracy: 0.8856\n",
      "Epoch 163/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3035 - accuracy: 0.8879 - val_loss: 0.3040 - val_accuracy: 0.8831\n",
      "Epoch 164/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3042 - accuracy: 0.8875 - val_loss: 0.2989 - val_accuracy: 0.8887\n",
      "Epoch 165/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3016 - accuracy: 0.8884 - val_loss: 0.2981 - val_accuracy: 0.8883\n",
      "Epoch 166/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3005 - accuracy: 0.8873 - val_loss: 0.3007 - val_accuracy: 0.8869\n",
      "Epoch 167/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3017 - accuracy: 0.8882 - val_loss: 0.3143 - val_accuracy: 0.8795\n",
      "Epoch 168/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3066 - accuracy: 0.8857 - val_loss: 0.3052 - val_accuracy: 0.8819\n",
      "Epoch 169/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3020 - accuracy: 0.8870 - val_loss: 0.3027 - val_accuracy: 0.8866\n",
      "Epoch 170/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2986 - accuracy: 0.8880 - val_loss: 0.2945 - val_accuracy: 0.8908\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3011 - accuracy: 0.8876 - val_loss: 0.2970 - val_accuracy: 0.8858\n",
      "Epoch 172/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2993 - accuracy: 0.8876 - val_loss: 0.2987 - val_accuracy: 0.8876\n",
      "Epoch 173/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2984 - accuracy: 0.8875 - val_loss: 0.2978 - val_accuracy: 0.8872\n",
      "Epoch 174/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2974 - accuracy: 0.8884 - val_loss: 0.2933 - val_accuracy: 0.8877\n",
      "Epoch 175/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2980 - accuracy: 0.8876 - val_loss: 0.2975 - val_accuracy: 0.8874\n",
      "Epoch 176/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3002 - accuracy: 0.8864 - val_loss: 0.3028 - val_accuracy: 0.8826\n",
      "Epoch 177/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2977 - accuracy: 0.8875 - val_loss: 0.2947 - val_accuracy: 0.8887\n",
      "Epoch 178/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2998 - accuracy: 0.8874 - val_loss: 0.2968 - val_accuracy: 0.8878\n",
      "Epoch 179/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2963 - accuracy: 0.8877 - val_loss: 0.2897 - val_accuracy: 0.8910\n",
      "Epoch 180/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2955 - accuracy: 0.8892 - val_loss: 0.2926 - val_accuracy: 0.8869\n",
      "Epoch 181/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2955 - accuracy: 0.8881 - val_loss: 0.2999 - val_accuracy: 0.8838\n",
      "Epoch 182/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2948 - accuracy: 0.8892 - val_loss: 0.3007 - val_accuracy: 0.8884\n",
      "Epoch 183/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3109 - accuracy: 0.8845 - val_loss: 1.0452 - val_accuracy: 0.7441\n",
      "Epoch 184/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 1.3835 - accuracy: 0.5668 - val_loss: 0.8412 - val_accuracy: 0.6571\n",
      "Epoch 185/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3992 - accuracy: 0.8528 - val_loss: 0.5063 - val_accuracy: 0.8217\n",
      "Epoch 193/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4682 - accuracy: 0.8326 - val_loss: 0.4172 - val_accuracy: 0.8419\n",
      "Epoch 194/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3726 - accuracy: 0.8694 - val_loss: 0.3368 - val_accuracy: 0.8762\n",
      "Epoch 195/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3553 - accuracy: 0.8712 - val_loss: 0.3727 - val_accuracy: 0.8624\n",
      "Epoch 196/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3794 - accuracy: 0.8622 - val_loss: 0.6098 - val_accuracy: 0.7645\n",
      "Epoch 197/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4795 - accuracy: 0.8218 - val_loss: 0.5926 - val_accuracy: 0.7773\n",
      "Epoch 198/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4833 - accuracy: 0.8093 - val_loss: 0.4106 - val_accuracy: 0.8373\n",
      "Epoch 199/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3568 - accuracy: 0.8675 - val_loss: 0.3292 - val_accuracy: 0.8802\n",
      "Epoch 200/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3313 - accuracy: 0.8797 - val_loss: 0.3296 - val_accuracy: 0.8803\n",
      "Epoch 201/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3242 - accuracy: 0.8804 - val_loss: 0.3198 - val_accuracy: 0.8826\n",
      "Epoch 202/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3209 - accuracy: 0.8810 - val_loss: 0.3131 - val_accuracy: 0.8851\n",
      "Epoch 203/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3162 - accuracy: 0.8829 - val_loss: 0.3109 - val_accuracy: 0.8855\n",
      "Epoch 204/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3157 - accuracy: 0.8821 - val_loss: 0.3061 - val_accuracy: 0.8838\n",
      "Epoch 205/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3125 - accuracy: 0.8838 - val_loss: 0.3080 - val_accuracy: 0.8837\n",
      "Epoch 206/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3099 - accuracy: 0.8852 - val_loss: 0.3057 - val_accuracy: 0.8833\n",
      "Epoch 207/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3119 - accuracy: 0.8824 - val_loss: 0.3014 - val_accuracy: 0.8860\n",
      "Epoch 208/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3081 - accuracy: 0.8857 - val_loss: 0.2993 - val_accuracy: 0.8876\n",
      "Epoch 209/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3072 - accuracy: 0.8849 - val_loss: 0.3025 - val_accuracy: 0.8830\n",
      "Epoch 210/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3067 - accuracy: 0.8859 - val_loss: 0.2967 - val_accuracy: 0.8873\n",
      "Epoch 211/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3050 - accuracy: 0.8856 - val_loss: 0.2965 - val_accuracy: 0.8899\n",
      "Epoch 212/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3026 - accuracy: 0.8880 - val_loss: 0.2942 - val_accuracy: 0.8876\n",
      "Epoch 213/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3014 - accuracy: 0.8875 - val_loss: 0.2955 - val_accuracy: 0.8857\n",
      "Epoch 214/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3017 - accuracy: 0.8877 - val_loss: 0.2915 - val_accuracy: 0.8876\n",
      "Epoch 215/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3009 - accuracy: 0.8876 - val_loss: 0.3028 - val_accuracy: 0.8825\n",
      "Epoch 216/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3009 - accuracy: 0.8887 - val_loss: 0.2952 - val_accuracy: 0.8870\n",
      "Epoch 217/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3009 - accuracy: 0.8876 - val_loss: 0.2886 - val_accuracy: 0.8909\n",
      "Epoch 218/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2975 - accuracy: 0.8887 - val_loss: 0.2919 - val_accuracy: 0.8891\n",
      "Epoch 219/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2980 - accuracy: 0.8895 - val_loss: 0.2913 - val_accuracy: 0.8892\n",
      "Epoch 220/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2983 - accuracy: 0.8876 - val_loss: 0.2926 - val_accuracy: 0.8891\n",
      "Epoch 221/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2961 - accuracy: 0.8896 - val_loss: 0.2897 - val_accuracy: 0.8895\n",
      "Epoch 222/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2929 - accuracy: 0.8905 - val_loss: 0.2870 - val_accuracy: 0.8896\n",
      "Epoch 223/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2946 - accuracy: 0.8895 - val_loss: 0.2916 - val_accuracy: 0.8882\n",
      "Epoch 224/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2929 - accuracy: 0.8913 - val_loss: 0.2864 - val_accuracy: 0.8884\n",
      "Epoch 225/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2921 - accuracy: 0.8896 - val_loss: 0.2932 - val_accuracy: 0.8849\n",
      "Epoch 226/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3257 - accuracy: 0.8785 - val_loss: 0.3690 - val_accuracy: 0.8639\n",
      "Epoch 227/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4749 - accuracy: 0.8399 - val_loss: 0.3564 - val_accuracy: 0.8640\n",
      "Epoch 228/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5565 - accuracy: 0.8095 - val_loss: 0.3723 - val_accuracy: 0.8597\n",
      "Epoch 229/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3759 - accuracy: 0.8596 - val_loss: 0.3223 - val_accuracy: 0.8796\n",
      "Epoch 230/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3385 - accuracy: 0.8748 - val_loss: 0.2987 - val_accuracy: 0.8886\n",
      "Epoch 231/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4027 - accuracy: 0.8609 - val_loss: 0.3316 - val_accuracy: 0.8786\n",
      "Epoch 232/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3095 - accuracy: 0.8860 - val_loss: 0.3020 - val_accuracy: 0.8876\n",
      "Epoch 233/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2996 - accuracy: 0.8886 - val_loss: 0.2928 - val_accuracy: 0.8893\n",
      "Epoch 234/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2966 - accuracy: 0.8899 - val_loss: 0.2886 - val_accuracy: 0.8887\n",
      "Epoch 235/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2961 - accuracy: 0.8889 - val_loss: 0.2890 - val_accuracy: 0.8898\n",
      "Epoch 236/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2934 - accuracy: 0.8896 - val_loss: 0.2872 - val_accuracy: 0.8901\n",
      "Epoch 237/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2925 - accuracy: 0.8907 - val_loss: 0.2893 - val_accuracy: 0.8879\n",
      "Epoch 238/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2906 - accuracy: 0.8916 - val_loss: 0.2875 - val_accuracy: 0.8905\n",
      "Epoch 239/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2915 - accuracy: 0.8898 - val_loss: 0.2826 - val_accuracy: 0.8929\n",
      "Epoch 240/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2895 - accuracy: 0.8911 - val_loss: 0.2857 - val_accuracy: 0.8904\n",
      "Epoch 241/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2899 - accuracy: 0.8908 - val_loss: 0.2831 - val_accuracy: 0.8916\n",
      "Epoch 242/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2897 - accuracy: 0.8908 - val_loss: 0.2922 - val_accuracy: 0.8879\n",
      "Epoch 243/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2904 - accuracy: 0.8897 - val_loss: 0.2848 - val_accuracy: 0.8919\n",
      "Epoch 244/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2873 - accuracy: 0.8913 - val_loss: 0.2874 - val_accuracy: 0.8899\n",
      "Epoch 245/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2866 - accuracy: 0.8921 - val_loss: 0.2826 - val_accuracy: 0.8923\n",
      "Epoch 246/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2852 - accuracy: 0.8934 - val_loss: 0.2854 - val_accuracy: 0.8900\n",
      "Epoch 247/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2853 - accuracy: 0.8920 - val_loss: 0.2827 - val_accuracy: 0.8913\n",
      "Epoch 248/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2842 - accuracy: 0.8927 - val_loss: 0.2793 - val_accuracy: 0.8946\n",
      "Epoch 249/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2833 - accuracy: 0.8929 - val_loss: 0.2821 - val_accuracy: 0.8924\n",
      "Epoch 250/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2831 - accuracy: 0.8934 - val_loss: 0.2861 - val_accuracy: 0.8922\n",
      "Epoch 251/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2809 - accuracy: 0.8935 - val_loss: 0.2811 - val_accuracy: 0.8926\n",
      "Epoch 252/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2852 - accuracy: 0.8917 - val_loss: 0.2814 - val_accuracy: 0.8932\n",
      "Epoch 253/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2843 - accuracy: 0.8938 - val_loss: 0.2873 - val_accuracy: 0.8907\n",
      "Epoch 254/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2816 - accuracy: 0.8943 - val_loss: 0.2803 - val_accuracy: 0.8937\n",
      "Epoch 255/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2813 - accuracy: 0.8940 - val_loss: 0.2812 - val_accuracy: 0.8931\n",
      "Epoch 256/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4548 - accuracy: 0.8416 - val_loss: 0.3220 - val_accuracy: 0.8859\n",
      "Epoch 257/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3141 - accuracy: 0.8857 - val_loss: 0.2969 - val_accuracy: 0.8865\n",
      "Epoch 258/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3211 - accuracy: 0.8843 - val_loss: 0.3671 - val_accuracy: 0.8717\n",
      "Epoch 259/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5223 - accuracy: 0.8336 - val_loss: 0.6995 - val_accuracy: 0.7376\n",
      "Epoch 260/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.6120 - accuracy: 0.8110 - val_loss: 0.3801 - val_accuracy: 0.8610\n",
      "Epoch 261/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4724 - accuracy: 0.8349 - val_loss: 0.5031 - val_accuracy: 0.8289\n",
      "Epoch 262/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4021 - accuracy: 0.8530 - val_loss: 0.5018 - val_accuracy: 0.7977\n",
      "Epoch 263/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5175 - accuracy: 0.8167 - val_loss: 0.4190 - val_accuracy: 0.8404\n",
      "Epoch 264/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.6502 - accuracy: 0.8191 - val_loss: 0.3731 - val_accuracy: 0.8740\n",
      "Epoch 265/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3326 - accuracy: 0.8801 - val_loss: 0.3054 - val_accuracy: 0.8875\n",
      "Epoch 266/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3098 - accuracy: 0.8863 - val_loss: 0.3011 - val_accuracy: 0.8862\n",
      "Epoch 267/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3014 - accuracy: 0.8875 - val_loss: 0.2922 - val_accuracy: 0.8887\n",
      "Epoch 268/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2972 - accuracy: 0.8888 - val_loss: 0.2875 - val_accuracy: 0.8917\n",
      "Epoch 269/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2931 - accuracy: 0.8913 - val_loss: 0.2878 - val_accuracy: 0.8911\n",
      "Epoch 270/1000\n",
      "36/36 [==============================] - 3s 88ms/step - loss: 0.2910 - accuracy: 0.8907 - val_loss: 0.2855 - val_accuracy: 0.8907\n",
      "Epoch 271/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2893 - accuracy: 0.8908 - val_loss: 0.2898 - val_accuracy: 0.8900\n",
      "Epoch 272/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2883 - accuracy: 0.8915 - val_loss: 0.2841 - val_accuracy: 0.8914\n",
      "Epoch 273/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2858 - accuracy: 0.8924 - val_loss: 0.2828 - val_accuracy: 0.8925\n",
      "Epoch 274/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2857 - accuracy: 0.8929 - val_loss: 0.2811 - val_accuracy: 0.8937\n",
      "Epoch 275/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2840 - accuracy: 0.8932 - val_loss: 0.2837 - val_accuracy: 0.8917\n",
      "Epoch 276/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2845 - accuracy: 0.8923 - val_loss: 0.2867 - val_accuracy: 0.8907\n",
      "Epoch 277/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2833 - accuracy: 0.8934 - val_loss: 0.2841 - val_accuracy: 0.8918\n",
      "Epoch 278/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2814 - accuracy: 0.8937 - val_loss: 0.2792 - val_accuracy: 0.8939\n",
      "Epoch 279/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2808 - accuracy: 0.8938 - val_loss: 0.2788 - val_accuracy: 0.8941\n",
      "Epoch 280/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2802 - accuracy: 0.8953 - val_loss: 0.2802 - val_accuracy: 0.8945\n",
      "Epoch 281/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2801 - accuracy: 0.8945 - val_loss: 0.2787 - val_accuracy: 0.8940\n",
      "Epoch 282/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2810 - accuracy: 0.8939 - val_loss: 0.2765 - val_accuracy: 0.8956\n",
      "Epoch 283/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2777 - accuracy: 0.8953 - val_loss: 0.2804 - val_accuracy: 0.8925\n",
      "Epoch 284/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2774 - accuracy: 0.8953 - val_loss: 0.2797 - val_accuracy: 0.8934\n",
      "Epoch 285/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2779 - accuracy: 0.8952 - val_loss: 0.2791 - val_accuracy: 0.8946\n",
      "Epoch 286/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2766 - accuracy: 0.8946 - val_loss: 0.2799 - val_accuracy: 0.8938\n",
      "Epoch 287/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2761 - accuracy: 0.8955 - val_loss: 0.2778 - val_accuracy: 0.8949\n",
      "Epoch 288/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2754 - accuracy: 0.8960 - val_loss: 0.2778 - val_accuracy: 0.8957\n",
      "Epoch 289/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2749 - accuracy: 0.8971 - val_loss: 0.2800 - val_accuracy: 0.8911\n",
      "Epoch 290/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2771 - accuracy: 0.8954 - val_loss: 0.2741 - val_accuracy: 0.8972\n",
      "Epoch 291/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2751 - accuracy: 0.8951 - val_loss: 0.2757 - val_accuracy: 0.8969\n",
      "Epoch 292/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2736 - accuracy: 0.8958 - val_loss: 0.2785 - val_accuracy: 0.8946\n",
      "Epoch 293/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2749 - accuracy: 0.8969 - val_loss: 0.2759 - val_accuracy: 0.8947\n",
      "Epoch 294/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2746 - accuracy: 0.8958 - val_loss: 0.3037 - val_accuracy: 0.8920\n",
      "Epoch 295/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2724 - accuracy: 0.8964 - val_loss: 0.2851 - val_accuracy: 0.8929\n",
      "Epoch 296/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2728 - accuracy: 0.8970 - val_loss: 0.2738 - val_accuracy: 0.8973\n",
      "Epoch 297/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2722 - accuracy: 0.8962 - val_loss: 0.3149 - val_accuracy: 0.8913\n",
      "Epoch 298/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2737 - accuracy: 0.8958 - val_loss: 0.3127 - val_accuracy: 0.8856\n",
      "Epoch 299/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2724 - accuracy: 0.8959 - val_loss: 0.2907 - val_accuracy: 0.8921\n",
      "Epoch 300/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2698 - accuracy: 0.8976 - val_loss: 0.3187 - val_accuracy: 0.8809\n",
      "Epoch 301/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2699 - accuracy: 0.8965 - val_loss: 0.3031 - val_accuracy: 0.8930\n",
      "Epoch 302/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2702 - accuracy: 0.8976 - val_loss: 0.3025 - val_accuracy: 0.8945\n",
      "Epoch 303/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2688 - accuracy: 0.8977 - val_loss: 0.3025 - val_accuracy: 0.8901\n",
      "Epoch 304/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2694 - accuracy: 0.8969 - val_loss: 0.3114 - val_accuracy: 0.8868\n",
      "Epoch 305/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2713 - accuracy: 0.8975 - val_loss: 0.3131 - val_accuracy: 0.8889\n",
      "Epoch 306/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3380 - accuracy: 0.8769 - val_loss: 0.3869 - val_accuracy: 0.8617\n",
      "Epoch 307/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.7926 - accuracy: 0.7726 - val_loss: 0.6229 - val_accuracy: 0.7419\n",
      "Epoch 308/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6380 - accuracy: 0.7837 - val_loss: 0.3868 - val_accuracy: 0.8454\n",
      "Epoch 309/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3849 - accuracy: 0.8626 - val_loss: 0.3130 - val_accuracy: 0.8887\n",
      "Epoch 310/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3390 - accuracy: 0.8752 - val_loss: 0.4714 - val_accuracy: 0.8195\n",
      "Epoch 311/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3376 - accuracy: 0.8726 - val_loss: 0.2969 - val_accuracy: 0.8882\n",
      "Epoch 312/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2907 - accuracy: 0.8913 - val_loss: 0.2787 - val_accuracy: 0.8952\n",
      "Epoch 313/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2865 - accuracy: 0.8927 - val_loss: 0.2739 - val_accuracy: 0.8940\n",
      "Epoch 314/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2825 - accuracy: 0.8932 - val_loss: 0.2716 - val_accuracy: 0.8960\n",
      "Epoch 315/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2807 - accuracy: 0.8945 - val_loss: 0.2721 - val_accuracy: 0.8954\n",
      "Epoch 316/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2774 - accuracy: 0.8952 - val_loss: 0.2749 - val_accuracy: 0.8952\n",
      "Epoch 317/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2772 - accuracy: 0.8958 - val_loss: 0.2687 - val_accuracy: 0.8971\n",
      "Epoch 318/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2769 - accuracy: 0.8954 - val_loss: 0.2709 - val_accuracy: 0.8967\n",
      "Epoch 319/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2749 - accuracy: 0.8967 - val_loss: 0.2718 - val_accuracy: 0.8959\n",
      "Epoch 320/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2743 - accuracy: 0.8971 - val_loss: 0.2801 - val_accuracy: 0.8933\n",
      "Epoch 321/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2745 - accuracy: 0.8963 - val_loss: 0.2661 - val_accuracy: 0.8980\n",
      "Epoch 322/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2719 - accuracy: 0.8965 - val_loss: 0.2688 - val_accuracy: 0.8970\n",
      "Epoch 323/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2721 - accuracy: 0.8974 - val_loss: 0.2715 - val_accuracy: 0.8965\n",
      "Epoch 324/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2715 - accuracy: 0.8971 - val_loss: 0.2735 - val_accuracy: 0.8954\n",
      "Epoch 325/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2707 - accuracy: 0.8980 - val_loss: 0.2693 - val_accuracy: 0.8965\n",
      "Epoch 326/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2689 - accuracy: 0.8979 - val_loss: 0.2686 - val_accuracy: 0.8974\n",
      "Epoch 327/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2688 - accuracy: 0.8982 - val_loss: 0.2652 - val_accuracy: 0.8990\n",
      "Epoch 328/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2695 - accuracy: 0.8973 - val_loss: 0.2682 - val_accuracy: 0.8968\n",
      "Epoch 329/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2686 - accuracy: 0.8976 - val_loss: 0.2672 - val_accuracy: 0.8973\n",
      "Epoch 330/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2684 - accuracy: 0.8993 - val_loss: 0.2672 - val_accuracy: 0.8997\n",
      "Epoch 331/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2688 - accuracy: 0.8973 - val_loss: 0.2652 - val_accuracy: 0.8985\n",
      "Epoch 332/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2670 - accuracy: 0.8986 - val_loss: 0.2661 - val_accuracy: 0.8973\n",
      "Epoch 333/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2692 - accuracy: 0.8972 - val_loss: 0.2671 - val_accuracy: 0.9001\n",
      "Epoch 334/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2668 - accuracy: 0.8991 - val_loss: 0.2680 - val_accuracy: 0.8986\n",
      "Epoch 335/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2669 - accuracy: 0.8994 - val_loss: 0.2686 - val_accuracy: 0.8958\n",
      "Epoch 336/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2667 - accuracy: 0.8984 - val_loss: 0.2688 - val_accuracy: 0.8979\n",
      "Epoch 337/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2670 - accuracy: 0.8982 - val_loss: 0.2704 - val_accuracy: 0.8975\n",
      "Epoch 338/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2649 - accuracy: 0.8989 - val_loss: 0.2651 - val_accuracy: 0.9007\n",
      "Epoch 339/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2679 - accuracy: 0.8973 - val_loss: 0.2670 - val_accuracy: 0.9010\n",
      "Epoch 340/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2642 - accuracy: 0.8993 - val_loss: 0.2738 - val_accuracy: 0.8968\n",
      "Epoch 341/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2639 - accuracy: 0.9000 - val_loss: 0.2652 - val_accuracy: 0.8978\n",
      "Epoch 342/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2638 - accuracy: 0.9001 - val_loss: 0.2651 - val_accuracy: 0.8976\n",
      "Epoch 343/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2635 - accuracy: 0.8993 - val_loss: 0.2639 - val_accuracy: 0.8992\n",
      "Epoch 344/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.7359 - accuracy: 0.8098 - val_loss: 0.7640 - val_accuracy: 0.6997\n",
      "Epoch 345/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 1.1740 - accuracy: 0.6350 - val_loss: 0.6554 - val_accuracy: 0.7245\n",
      "Epoch 346/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 86ms/step - loss: 0.6096 - accuracy: 0.7715 - val_loss: 0.4396 - val_accuracy: 0.8476\n",
      "Epoch 347/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5124 - accuracy: 0.8131 - val_loss: 0.4177 - val_accuracy: 0.8422\n",
      "Epoch 348/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.7716 - accuracy: 0.7306 - val_loss: 0.7695 - val_accuracy: 0.7301\n",
      "Epoch 349/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5619 - accuracy: 0.7537 - val_loss: 0.5146 - val_accuracy: 0.7423\n",
      "Epoch 350/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4803 - accuracy: 0.8328 - val_loss: 0.4698 - val_accuracy: 0.8657\n",
      "Epoch 351/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.5050 - accuracy: 0.8354 - val_loss: 0.4203 - val_accuracy: 0.8669\n",
      "Epoch 352/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3996 - accuracy: 0.8616 - val_loss: 0.3717 - val_accuracy: 0.8636\n",
      "Epoch 353/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3713 - accuracy: 0.8628 - val_loss: 0.3747 - val_accuracy: 0.8643\n",
      "Epoch 354/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3938 - accuracy: 0.8614 - val_loss: 0.3623 - val_accuracy: 0.8664\n",
      "Epoch 355/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3729 - accuracy: 0.8680 - val_loss: 0.3515 - val_accuracy: 0.8734\n",
      "Epoch 356/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3573 - accuracy: 0.8717 - val_loss: 0.3427 - val_accuracy: 0.8749\n",
      "Epoch 357/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3477 - accuracy: 0.8734 - val_loss: 0.3374 - val_accuracy: 0.8758\n",
      "Epoch 358/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3506 - accuracy: 0.8714 - val_loss: 0.3329 - val_accuracy: 0.8758\n",
      "Epoch 359/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3363 - accuracy: 0.8757 - val_loss: 0.3265 - val_accuracy: 0.8787\n",
      "Epoch 360/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3317 - accuracy: 0.8764 - val_loss: 0.3264 - val_accuracy: 0.8781\n",
      "Epoch 361/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3360 - accuracy: 0.8744 - val_loss: 0.3231 - val_accuracy: 0.8788\n",
      "Epoch 362/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3267 - accuracy: 0.8798 - val_loss: 0.3216 - val_accuracy: 0.8794\n",
      "Epoch 363/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3204 - accuracy: 0.8814 - val_loss: 0.3176 - val_accuracy: 0.8805\n",
      "Epoch 364/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3170 - accuracy: 0.8828 - val_loss: 0.3158 - val_accuracy: 0.8835\n",
      "Epoch 365/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3141 - accuracy: 0.8839 - val_loss: 0.3151 - val_accuracy: 0.8819\n",
      "Epoch 366/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3295 - accuracy: 0.8792 - val_loss: 0.3285 - val_accuracy: 0.8775\n",
      "Epoch 367/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3364 - accuracy: 0.8731 - val_loss: 0.3578 - val_accuracy: 0.8520\n",
      "Epoch 368/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3697 - accuracy: 0.8654 - val_loss: 0.3163 - val_accuracy: 0.8845\n",
      "Epoch 369/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3292 - accuracy: 0.8752 - val_loss: 0.3116 - val_accuracy: 0.8825\n",
      "Epoch 370/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.4395 - accuracy: 0.8440 - val_loss: 0.3682 - val_accuracy: 0.8624\n",
      "Epoch 371/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3538 - accuracy: 0.8715 - val_loss: 0.3101 - val_accuracy: 0.8864\n",
      "Epoch 372/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3062 - accuracy: 0.8865 - val_loss: 0.3010 - val_accuracy: 0.8869\n",
      "Epoch 373/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3004 - accuracy: 0.8883 - val_loss: 0.3011 - val_accuracy: 0.8868\n",
      "Epoch 374/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2963 - accuracy: 0.8887 - val_loss: 0.2976 - val_accuracy: 0.8874\n",
      "Epoch 375/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2938 - accuracy: 0.8900 - val_loss: 0.2942 - val_accuracy: 0.8894\n",
      "Epoch 376/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2923 - accuracy: 0.8899 - val_loss: 0.2922 - val_accuracy: 0.8907\n",
      "Epoch 377/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2907 - accuracy: 0.8897 - val_loss: 0.2885 - val_accuracy: 0.8909\n",
      "Epoch 378/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2884 - accuracy: 0.8912 - val_loss: 0.2908 - val_accuracy: 0.8906\n",
      "Epoch 379/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2844 - accuracy: 0.8930 - val_loss: 0.2881 - val_accuracy: 0.8911\n",
      "Epoch 380/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2844 - accuracy: 0.8921 - val_loss: 0.2876 - val_accuracy: 0.8908\n",
      "Epoch 381/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2823 - accuracy: 0.8926 - val_loss: 0.2846 - val_accuracy: 0.8937\n",
      "Epoch 382/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2813 - accuracy: 0.8933 - val_loss: 0.2819 - val_accuracy: 0.8942\n",
      "Epoch 383/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2824 - accuracy: 0.8937 - val_loss: 0.2789 - val_accuracy: 0.8949\n",
      "Epoch 384/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2789 - accuracy: 0.8941 - val_loss: 0.2776 - val_accuracy: 0.8953\n",
      "Epoch 385/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2761 - accuracy: 0.8956 - val_loss: 0.2810 - val_accuracy: 0.8961\n",
      "Epoch 386/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2767 - accuracy: 0.8955 - val_loss: 0.2764 - val_accuracy: 0.8964\n",
      "Epoch 387/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2756 - accuracy: 0.8957 - val_loss: 0.2808 - val_accuracy: 0.8936\n",
      "Epoch 388/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2747 - accuracy: 0.8964 - val_loss: 0.2752 - val_accuracy: 0.8961\n",
      "Epoch 389/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2759 - accuracy: 0.8946 - val_loss: 0.2854 - val_accuracy: 0.8928\n",
      "Epoch 390/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2725 - accuracy: 0.8972 - val_loss: 0.2743 - val_accuracy: 0.8965\n",
      "Epoch 391/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2725 - accuracy: 0.8969 - val_loss: 0.2765 - val_accuracy: 0.8973\n",
      "Epoch 392/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2720 - accuracy: 0.8967 - val_loss: 0.2758 - val_accuracy: 0.8952\n",
      "Epoch 393/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2718 - accuracy: 0.8972 - val_loss: 0.2744 - val_accuracy: 0.8966\n",
      "Epoch 394/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3510 - accuracy: 0.8772 - val_loss: 0.3213 - val_accuracy: 0.8814\n",
      "Epoch 395/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4249 - accuracy: 0.8276 - val_loss: 0.3151 - val_accuracy: 0.8844\n",
      "Epoch 396/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3166 - accuracy: 0.8854 - val_loss: 0.2771 - val_accuracy: 0.8962\n",
      "Epoch 397/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2791 - accuracy: 0.8955 - val_loss: 0.2739 - val_accuracy: 0.8940\n",
      "Epoch 398/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2784 - accuracy: 0.8949 - val_loss: 0.2764 - val_accuracy: 0.8947\n",
      "Epoch 399/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2756 - accuracy: 0.8959 - val_loss: 0.2710 - val_accuracy: 0.8987\n",
      "Epoch 400/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2729 - accuracy: 0.8978 - val_loss: 0.2756 - val_accuracy: 0.8952\n",
      "Epoch 401/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2722 - accuracy: 0.8970 - val_loss: 0.2719 - val_accuracy: 0.8972\n",
      "Epoch 402/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2699 - accuracy: 0.8973 - val_loss: 0.2723 - val_accuracy: 0.8998\n",
      "Epoch 403/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2714 - accuracy: 0.8968 - val_loss: 0.2722 - val_accuracy: 0.8968\n",
      "Epoch 404/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2693 - accuracy: 0.8981 - val_loss: 0.2715 - val_accuracy: 0.8974\n",
      "Epoch 405/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2708 - accuracy: 0.8970 - val_loss: 0.2756 - val_accuracy: 0.8954\n",
      "Epoch 406/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2675 - accuracy: 0.8984 - val_loss: 0.2755 - val_accuracy: 0.8948\n",
      "Epoch 407/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2676 - accuracy: 0.8986 - val_loss: 0.2786 - val_accuracy: 0.8889\n",
      "Epoch 408/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2672 - accuracy: 0.8981 - val_loss: 0.2695 - val_accuracy: 0.8991\n",
      "Epoch 409/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4006 - accuracy: 0.8725 - val_loss: 1.1135 - val_accuracy: 0.7612\n",
      "Epoch 410/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.8546 - accuracy: 0.7079 - val_loss: 0.6799 - val_accuracy: 0.7267\n",
      "Epoch 411/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.4314 - accuracy: 0.8438 - val_loss: 0.3648 - val_accuracy: 0.8602\n",
      "Epoch 412/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3522 - accuracy: 0.8711 - val_loss: 0.3554 - val_accuracy: 0.8627\n",
      "Epoch 413/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.3275 - accuracy: 0.8793 - val_loss: 0.3253 - val_accuracy: 0.8782\n",
      "Epoch 414/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3121 - accuracy: 0.8842 - val_loss: 0.3143 - val_accuracy: 0.8838\n",
      "Epoch 415/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3036 - accuracy: 0.8873 - val_loss: 0.3079 - val_accuracy: 0.8880\n",
      "Epoch 416/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3051 - accuracy: 0.8858 - val_loss: 0.3306 - val_accuracy: 0.8804\n",
      "Epoch 417/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3569 - accuracy: 0.8662 - val_loss: 0.3530 - val_accuracy: 0.8694\n",
      "Epoch 418/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.3357 - accuracy: 0.8767 - val_loss: 0.3111 - val_accuracy: 0.8862\n",
      "Epoch 419/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2982 - accuracy: 0.8896 - val_loss: 0.2988 - val_accuracy: 0.8900\n",
      "Epoch 420/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2896 - accuracy: 0.8931 - val_loss: 0.2963 - val_accuracy: 0.8923\n",
      "Epoch 421/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2851 - accuracy: 0.8942 - val_loss: 0.2900 - val_accuracy: 0.8942\n",
      "Epoch 422/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2819 - accuracy: 0.8947 - val_loss: 0.2854 - val_accuracy: 0.8969\n",
      "Epoch 423/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2794 - accuracy: 0.8949 - val_loss: 0.2857 - val_accuracy: 0.8957\n",
      "Epoch 424/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2763 - accuracy: 0.8955 - val_loss: 0.2848 - val_accuracy: 0.8985\n",
      "Epoch 425/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2768 - accuracy: 0.8962 - val_loss: 0.2923 - val_accuracy: 0.8919\n",
      "Epoch 426/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2720 - accuracy: 0.8978 - val_loss: 0.2868 - val_accuracy: 0.8914\n",
      "Epoch 427/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2712 - accuracy: 0.8973 - val_loss: 0.2784 - val_accuracy: 0.8957\n",
      "Epoch 428/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2699 - accuracy: 0.8969 - val_loss: 0.2802 - val_accuracy: 0.8954\n",
      "Epoch 429/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2677 - accuracy: 0.8992 - val_loss: 0.2765 - val_accuracy: 0.8977\n",
      "Epoch 430/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2676 - accuracy: 0.8983 - val_loss: 0.2761 - val_accuracy: 0.8931\n",
      "Epoch 431/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2655 - accuracy: 0.8992 - val_loss: 0.2739 - val_accuracy: 0.8998\n",
      "Epoch 432/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2648 - accuracy: 0.8997 - val_loss: 0.2717 - val_accuracy: 0.9005\n",
      "Epoch 433/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2642 - accuracy: 0.8999 - val_loss: 0.2740 - val_accuracy: 0.8998\n",
      "Epoch 434/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2638 - accuracy: 0.8999 - val_loss: 0.2746 - val_accuracy: 0.8992\n",
      "Epoch 435/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2622 - accuracy: 0.9012 - val_loss: 0.2784 - val_accuracy: 0.8975\n",
      "Epoch 436/1000\n",
      "36/36 [==============================] - 3s 86ms/step - loss: 0.2622 - accuracy: 0.9009 - val_loss: 0.2742 - val_accuracy: 0.8993\n",
      "Epoch 437/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2614 - accuracy: 0.9009 - val_loss: 0.2759 - val_accuracy: 0.8987\n",
      "Epoch 438/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2614 - accuracy: 0.9004 - val_loss: 0.2721 - val_accuracy: 0.9000\n",
      "Epoch 439/1000\n",
      "36/36 [==============================] - 3s 87ms/step - loss: 0.2592 - accuracy: 0.9010 - val_loss: 0.2692 - val_accuracy: 0.9006\n"
     ]
    }
   ],
   "source": [
    "history = model_RNN_LSTM.fit(x_train,y_train, epochs=1000, batch_size=16, validation_split=0.2,callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conf = []\n",
    "# for i in predictions:\n",
    "#     softmax = []\n",
    "#     for j in i:\n",
    "#         dist = np.linalg.norm(target-j,axis =1)\n",
    "#         softmax.append(np.exp(dist)/np.sum(np.exp(dist)))\n",
    "#     conf.append(softmax)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670470311929,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "4kEwHgcTThyk"
   },
   "outputs": [],
   "source": [
    "# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5\")\n",
    "# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5\")\n",
    "model_RNN_LSTM.save(\"./models/sep_0.7/lstm_rnn.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1549,
     "status": "ok",
     "timestamp": 1670464132234,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "_lI1n5rWk7DF",
    "outputId": "11fbc446-b78b-4739-c7b0-cdfd12b12134"
   },
   "outputs": [],
   "source": [
    "# Testing the saved model\n",
    "# classification models\n",
    "# model_load = load_model('/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5')\n",
    "# model_load = load_model('/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5')\n",
    "# model_load = load_model('./models/lstm_rnn.h5')\n",
    "model_load = load_model('./models/sep_0.7/lstm_rnn.h5')\n",
    "\n",
    "\n",
    "# 3d models\n",
    "# model_load = load_model('./models/sep_1/lstm_3d.h5')\n",
    "# model_load = load_model('./models/sep_1/lstm_rnn_3d.h5', compile=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 4ms/step - loss: 0.4029 - accuracy: 0.8769\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.40291428565979004, 0.8769382238388062]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Model evaluation for classification\n",
    "# model_load.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=Adam(1e-2))\n",
    "# Evaluating classification models\n",
    "model_load.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-11 18:28:11.923356: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:630] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2022-12-11 18:28:18.451829: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8233830845771144\n"
     ]
    }
   ],
   "source": [
    "# Model evaluation for 3d \n",
    "# model_load.compile(loss='mse', metrics = ['mse'])\n",
    "predictions = model_load.predict(x_test)\n",
    "preds = [[np.argmin(np.linalg.norm(target-j,axis =1)) for j in i] for i in predictions]\n",
    "label_y_test = [[np.argmin(np.linalg.norm(target-j,axis =1)) for j in i] for i in y_test.numpy()]\n",
    "correct = 0\n",
    "for i,j in zip(preds,label_y_test):\n",
    "    for k,l in zip(i,j):\n",
    "        correct+=np.sum((k==l)*1)\n",
    "print(\"Accuracy:\", correct/np.prod(np.shape(preds)) )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_layer (InputLayer)     [(None, 200, 3)]          0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 200, 15)           60        \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 200, 15)           465       \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 200, 15)           1860      \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 200, 3)            48        \n",
      "=================================================================\n",
      "Total params: 2,433\n",
      "Trainable params: 2,433\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_load.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
