{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1670472818051,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "yu0OV4sf1nk8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472819084,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "svhuDSYP1nk-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import collections\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "from IPython.core.display import HTML\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.python.keras.models import load_model\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472822205,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "vGhXf6lC1nk_",
    "outputId": "478747bb-6f8c-481d-ebb4-82b506528c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.4.1\n",
      "keras version 2.4.0\n",
      "Eager Execution Enabled: True\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of replicas: 1\n",
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-10 14:43:53.911294: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-12-10 14:43:53.912399: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcuda.so.1\n",
      "2022-12-10 14:43:53.977561: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-12-10 14:43:53.977593: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-12-10 14:43:54.620282: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-12-10 14:43:54.620406: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-12-10 14:43:54.794630: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-12-10 14:43:55.121465: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-12-10 14:43:55.561832: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-12-10 14:43:55.702624: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-12-10 14:43:56.446026: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-12-10 14:43:56.446864: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-12-10 14:43:56.447866: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 AVX512F FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-12-10 14:43:56.448205: I tensorflow/compiler/jit/xla_gpu_device.cc:99] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-12-10 14:43:56.448640: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1720] Found device 0 with properties: \n",
      "pciBusID: 0000:1e:00.0 name: Tesla V100-SXM2-16GB computeCapability: 7.0\n",
      "coreClock: 1.53GHz coreCount: 80 deviceMemorySize: 15.78GiB deviceMemoryBandwidth: 836.37GiB/s\n",
      "2022-12-10 14:43:56.448680: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-12-10 14:43:56.448703: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublas.so.10\n",
      "2022-12-10 14:43:56.448711: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcublasLt.so.10\n",
      "2022-12-10 14:43:56.448720: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcufft.so.10\n",
      "2022-12-10 14:43:56.448729: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcurand.so.10\n",
      "2022-12-10 14:43:56.448737: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusolver.so.10\n",
      "2022-12-10 14:43:56.448746: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcusparse.so.10\n",
      "2022-12-10 14:43:56.448755: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudnn.so.7\n",
      "2022-12-10 14:43:56.449258: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1862] Adding visible gpu devices: 0\n",
      "2022-12-10 14:43:56.449287: I tensorflow/stream_executor/platform/default/dso_loader.cc:49] Successfully opened dynamic library libcudart.so.10.1\n",
      "2022-12-10 14:43:59.491964: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1261] Device interconnect StreamExecutor with strength 1 edge matrix:\n",
      "2022-12-10 14:43:59.491984: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1267]      0 \n",
      "2022-12-10 14:43:59.491988: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1280] 0:   N \n",
      "2022-12-10 14:43:59.493070: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1406] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14763 MB memory) -> physical GPU (device: 0, name: Tesla V100-SXM2-16GB, pci bus id: 0000:1e:00.0, compute capability: 7.0)\n"
     ]
    }
   ],
   "source": [
    "# Enable/Disable Eager Execution\n",
    "# Reference: https://www.tensorflow.org/guide/eager\n",
    "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
    "# without building graphs\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "print(\"keras version\", tf.keras.__version__)\n",
    "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
    "\n",
    "# Get the number of replicas \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "devices = tf.config.experimental.get_visible_devices()\n",
    "print(\"Devices:\", devices)\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
    "\n",
    "# Better performance with the tf.data API\n",
    "# Reference: https://www.tensorflow.org/guide/data_performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtMgghJO1nlA"
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "executionInfo": {
     "elapsed": 7156,
     "status": "ok",
     "timestamp": 1670461970917,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "eSg0NnAgXpRg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !unzip \"./all_data/sep_1/data.zip\" -d \"./temp_data/sep_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472827844,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "tbOPJ2jS1nlB"
   },
   "outputs": [],
   "source": [
    "# Getting the folder names \n",
    "folder_names = glob.glob(\"./temp_data/sep_1/data/*\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670472829094,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "JkZ1ScX01nlB"
   },
   "outputs": [],
   "source": [
    "# Getting the data names\n",
    "data_names = []\n",
    "for i in folder_names:\n",
    "    data_names.append(glob.glob(i+\"/*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng5z05Q61nlC"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "executionInfo": {
     "elapsed": 14851,
     "status": "ok",
     "timestamp": 1670472843943,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "06RUU7IU1nlD"
   },
   "outputs": [],
   "source": [
    "# Datasets to skip \n",
    "skip = []\n",
    "\n",
    "# Labels of the datasets\n",
    "labels = []\n",
    "\n",
    "# Data list \n",
    "data = []\n",
    "\n",
    "\n",
    "# Getting the labels and data for each dataset\n",
    "for i in range(len(data_names)):\n",
    "    if i in skip:\n",
    "        continue\n",
    "    \n",
    "    for j in range(len(data_names[i])):\n",
    "        labels.append([data_names[i][j][data_names[i][j].find(\".csv\")-1]])\n",
    "        \n",
    "        # Cleaning data\n",
    "        df = pd.read_csv(data_names[i][j],skiprows = 1)\n",
    "        df.drop(columns=df.columns[-1], axis=1,  inplace=True)\n",
    "        \n",
    "        data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472843943,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "OhMZiWrx1nlD"
   },
   "outputs": [],
   "source": [
    "# Changing the labels from int to string\n",
    "labels = [int(i)-1 for i in np.reshape(labels,(-1,))]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3aWbcBR1nlD"
   },
   "source": [
    "## Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "executionInfo": {
     "elapsed": 57502,
     "status": "ok",
     "timestamp": 1670472901442,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "6sJpWHrX1nlE"
   },
   "outputs": [],
   "source": [
    "# Adding the centroid of all the fingers to the data\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for idx_1 in range(len(data)):\n",
    "\n",
    "    \n",
    "    # Grouped columns for centroid\n",
    "    grouped_columns_x = data[idx_1].columns[3::3] \n",
    "    grouped_columns_y = data[idx_1].columns[4::3]\n",
    "    grouped_columns_z = data[idx_1].columns[5::3]\n",
    "    \n",
    "    # Getting the centroid of the finger points\n",
    "    cent_x = np.mean(data[idx_1][grouped_columns_x],axis = 1)\n",
    "    cent_y = np.mean(data[idx_1][grouped_columns_y],axis = 1)\n",
    "    cent_z = np.mean(data[idx_1][grouped_columns_z],axis = 1)\n",
    "    \n",
    "    new_data.append(pd.concat([data[idx_1],cent_x,cent_y,cent_z],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgaA_2SY0MDc"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472901442,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "MUjsQWtJsKIn"
   },
   "outputs": [],
   "source": [
    "# Pulling only the centroid data \n",
    "cent_data = [i.iloc[:,-3:] for i in new_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1670472902684,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "cq550A880PAk",
    "outputId": "8c0ba4d0-9ee8-4885-fe2b-e9f624183928"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0, 0.5, 'Number of trajectories')"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYUAAAEGCAYAAACKB4k+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAbPklEQVR4nO3dfbQX1X3v8fdHUJMaBZFTFkW4oKG6um4bpKcGq7WmRONDBKPRq20qelkhvbFG23RVjElMatpoUvXqSq+GqAmkRoMkClFjQgnoygMqIMHngAYKhKcYBaJRg37vH7PPOJyc8ztzDsxvzsPntdas3549T98z/vx9mT0zeysiMDMzA9in7gDMzKz3cFIwM7Ock4KZmeWcFMzMLOekYGZmucF1B7Anhg8fHmPHjq07DDOzPmX58uW/jIiWjpb16aQwduxYli1bVncYZmZ9iqR1nS1z85GZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnl+vQbzdZ3jJ15Xy3HXXv1abUc16yv8pWCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxylSUFSUdIWlmYdki6VNIwSQslrU6fB6f1JelGSWskrZI0sarYzMysY5UlhYh4NiImRMQE4E+BV4C7gZnAoogYDyxK8wCnAOPTNAO4qarYzMysY81qPpoMPBcR64CpwOxUPxs4I5WnAnMisxQYKmlkk+IzMzOalxTOBe5I5RERsSmVNwMjUnkUsL6wzYZUtxtJMyQtk7Rs27ZtVcVrZjYgVZ4UJO0HTAHuar8sIgKI7uwvImZFRGtEtLa0tOylKM3MDJpzpXAKsCIitqT5LW3NQulza6rfCIwubHdoqjMzsyZpRlI4j7eajgAWANNSeRowv1B/fnoKaRKwvdDMZGZmTVBpL6mSDgBOBD5SqL4amCtpOrAOOCfV3w+cCqwhe1LpwipjMzOz31VpUoiIl4FD2tW9QPY0Uvt1A7ioynjMzKwxv9FsZmY5JwUzM8s5KZiZWc5JwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZrtKkIGmopHmSnpH0tKRjJA2TtFDS6vR5cFpXkm6UtEbSKkkTq4zNzMx+V9VXCjcAD0TEkcC7gKeBmcCiiBgPLErzAKcA49M0A7ip4tjMzKydwVXtWNIQ4HjgAoCIeB14XdJU4IS02mxgCXAZMBWYExEBLE1XGSMjYlNVMVr/N3bmfbUcd+3Vp9VyXLM9VeWVwjhgG/BVSY9JukXSAcCIwg/9ZmBEKo8C1he235DqdiNphqRlkpZt27atwvDNzAaeKpPCYGAicFNEHAW8zFtNRQCkq4Lozk4jYlZEtEZEa0tLy14L1szMqk0KG4ANEfFwmp9HliS2SBoJkD63puUbgdGF7Q9NdWZm1iSVJYWI2Aysl3REqpoMPAUsAKalumnA/FReAJyfnkKaBGz3/QQzs+aq7EZzcjFwu6T9gOeBC8kS0VxJ04F1wDlp3fuBU4E1wCtpXTMza6JuJYX0TsHoiFhVZv2IWAm0drBocgfrBnBRd+IxM7O9q8vmI0lLJB0kaRiwAviKpOuqD83MzJqtzD2FIRGxAziT7D2CdwPvrTYsMzOrQ5mkMDg9JXQOcG/F8ZiZWY3KJIV/Ab4HPBcRj0o6DFhdbVhmZlaHLm80R8RdwF2F+eeBs6oMyszM6lHmRvMfSlok6Yk0/yeSPll9aGZm1mxlmo++AlwO/BYgPY56bpVBmZlZPcokhd+LiEfa1e2qIhgzM6tXmaTwS0mHkzquk/RBwN1PmJn1Q2XeaL4ImAUcKWkj8HPgQ5VGZWZmtSjz9NHzwHvTWAj7RMTO6sMyM7M6dJoUJH0oIv5T0j+2qwcgItzVhZlZP9PoSuGA9HlgMwIxM7P6dZoUIuLLkgYBOyLi+ibGZGZmNWn49FFEvAGc16RYzMysZmWePvqRpC8B3yQbZxmAiFhRWVRmZlaLMklhQvr8l0JdAH+198MxM7M6lXkk9T3NCMTMzOpXpkO8IZKuk7QsTddKGtKM4MzMrLnKdHNxG7CTbJCdc4AdwFfL7FzSWkmPS1opaVmqGyZpoaTV6fPgVC9JN0paI2mVpIk9+5PMzKynyiSFwyPiyoh4Pk2fBQ7rxjHeExETIqI1zc8EFkXEeGBRmgc4BRifphnATd04hpmZ7QVlksJvJB3XNiPpWOA3e3DMqcDsVJ4NnFGonxOZpcDQNAyomZk1SZmnj/4OmFO4j/AiMK3k/gP4vqQAvhwRs4AREdHWy+pmYEQqjwLWF7bdkOp265FV0gyyKwnGjBlTMgwzMyujTFLYERHvknQQQETskDSu5P6Pi4iNkn4fWCjpmeLCiIiUMEpLiWUWQGtra7e2NTOzxso0H30LsmQQETtS3bwyO4+IjelzK3A3cDSwpa1ZKH1uTatvBEYXNj801ZmZWZN0mhQkHSnpLGCIpDML0wXA27rasaQDJB3YVgZOAp4AFvBW89M0YH4qLwDOT08hTQK2F5qZzMysCRo1Hx0BvB8YCpxeqN8JfLjEvkcAd6eutgcD34iIByQ9CsyVNB1YR/aYK8D9wKnAGuAV4MJu/B1mZrYXNOoldT4wX9IxEfGT7u44Dc7zrg7qXwAmd1AfZKO8mZlZTcrcU/g7SUPbZiQdLOm2CmMyM7OalEkKfxIRL7XNRMSLwFHVhWRmZnUpkxT2aeuKArJuKij3KKuZmfUxZX7crwV+IumuNH828K/VhWRmZnUp03X2nNSZXdv4CWdGxFPVhmVmZnUo03wEMAx4OSK+BGzrxhvNZmbWh5QZT+FK4DLg8lS1L/CfVQZlZmb1KHOl8AFgCml85oj4BXBglUGZmVk9yiSF19OLZQF5lxVmZtYPlUkKcyV9mWx8gw8D/wV8pdqwzMysDmWePvp3SSeSDcN5BPDpiFhYeWRmZtZ0pV5CS0nAicDMrJ9r1HX2D9PnTkk7Oph+LumjzQvVzMyq1qiX1OPSZ4dPGkk6BPgx8P+qCc3MzJqtdB9GaUjNfHCdiPhvSSdUEZSZmdWjzMtrUyStBn4OPAisBb4L4JHRzMz6lzKPpF4FTAJ+FhHjyAbIWVppVGZmVosySeG3abS0fSTtExGLgdaK4zIzsxqUuafwkqR3AA8Bt0vaSurywszM+pcyVwpTgVeAfwAeAJ4DTi97AEmDJD0m6d40P07Sw5LWSPqmpP1S/f5pfk1aPra7f4yZme2ZhklB0iDg3oh4MyJ2RcTsiLgxNSeVdQnwdGH+GuD6iHgn8CIwPdVPB15M9den9czMrIkaJoWIeAN4U9KQnuxc0qHAacAtaV5kg/XMS6vMBs5I5alpnrR8clrfzMyapMw9hV8Dj0taSOFeQkR8rMS2/xf4Z97qavsQ4KWI2JXmNwCjUnkUsD7te5ek7Wn9XxZ3KGkGMANgzJgxJUIwM7OyyiSFb6epKLraSNL7ga0RsXxvvuQWEbOAWQCtra1dxmFmZuWVSQpDI+KGYoWkS0psdywwRdKpZG9CHwTcQNYF9+B0tXAosDGtvxEYDWyQNBgYAnTn3oWZme2hMk8fTeug7oKuNoqIyyPi0IgYC5wL/CAi/gZYDHywsO/5qbygcKwPpvV9JWBm1kSdXilIOg/4a2CcpAWFRQcCv9qDY14G3Cnpc8BjwK2p/lbg65LWpP2fuwfHMDOzHmjUfPRjYBMwHLi2UL8TWNWdg0TEEmBJKj8PHN3BOq8CZ3dnv2Zmtnc16jp7HbAOOKZ54ZiZWZ3K3FMwM7MBwknBzMxyjYbjXJQ+3d2EmdkA0ehG80hJf072rsGdwG5dTkTEikojMzOzpmuUFD4NfIrsBbPr2i0Lsj6MzMysH2n09NE8YJ6kT0XEVU2MyczMatJlNxcRcZWkKcDxqWpJRNxbbVhmZlaHLp8+kvR5sjERnkrTJZL+rerAzMys+cp0iHcaMCEi3gSQNJuse4pPVBmYmZk1X9n3FIYWyj0acMfMzHq/MlcKnwcek7SY7LHU44GZlUZlZma1KHOj+Q5JS4A/S1WXRcTmSqMyM7NalLlSICI2kY13YGZm/Zj7PjIzs5yTgpmZ5RomBUmDJD3TrGDMzKxeDZNCRLwBPCtpTJPiMTOzGpW50Xww8KSkR4CX2yojYkplUZmZWS3KJIVP9WTHkt4GPATsn44zLyKulDQOuBM4BFgO/G1EvC5pf2AO8KfAC8D/ioi1PTm2mZn1TJc3miPiQWAtsG8qPwqUGUvhNeCvIuJdwATgZEmTgGuA6yPincCLwPS0/nTgxVR/fVrPzMyaqEyHeB8G5gFfTlWjgHu62i4yv06z+6apbRyGeal+NnBGKk9N86TlkyXtNrCPmZlVq8wjqRcBxwI7ACJiNfD7ZXaenl5aCWwFFgLPAS9FxK60ygayJEP6XJ+OsQvYTtbE1H6fMyQtk7Rs27ZtZcIwM7OSyiSF1yLi9bYZSYPJ/sXfpYh4IyImkI3edjRwZI+i3H2fsyKiNSJaW1pa9nR3ZmZWUCYpPCjpE8DbJZ0I3AV8pzsHiYiXgMXAMcDQlFggSxYbU3kjMBryxDOE7IazmZk1SZmkMBPYBjwOfAS4H/hkVxtJapE0NJXfDpwIPE2WHD6YVpsGzE/lBWmetPwHEVHqisTMzPaOMr2kvpkG1nmYrNno2ZI/1iOB2ZIGkSWfuRFxr6SngDslfY5ssJ5b0/q3Al+XtAb4FXBu9/8cMzPbE10mBUmnATeT3SQWME7SRyLiu422i4hVwFEd1D9Pdn+hff2rwNkl4zYzswqUeXntWuA9EbEGQNLhwH1Aw6RgZmZ9T5l7CjvbEkLyPLCzonjMzKxGnV4pSDozFZdJuh+YS3ZP4Wyyt5rNzKyfadR8dHqhvAX4y1TeBry9sojMzKw2nSaFiLiwmYGYmVn9yjx9NA64GBhbXN9dZ5uZ9T9lnj66h+wdgu8Ab1YbjpmZ1alMUng1Im6sPBIzM6tdmaRwg6Qrge+TjZEAQESUGVPBzMz6kDJJ4Y+BvyUbB6Gt+ahtXAQzM+tHyiSFs4HDit1nm5lZ/1TmjeYngKFVB2JmZvUrc6UwFHhG0qPsfk/Bj6SamfUzZZLClZVHYWZmvUKZ8RQebEYgZmZWvzJvNO/krTGZ9wP2BV6OiIOqDMz2vrEz76s7BDPr5cpcKRzYVpYkYCowqcqgzMysHmWePspF5h7gfRXFY2ZmNSrTfHRmYXYfoBV4tbKIzPqBOpvq1l59Wm3Htr6vzJXC6YXpfWSjrk3taiNJoyUtlvSUpCclXZLqh0laKGl1+jw41UvSjZLWSFolaWLP/ywzM+uJMvcUejquwi7g4xGxQtKBwHJJC4ELgEURcbWkmcBM4DLgFGB8mt4N3JQ+zcysSRoNx/npBttFRFzVaMcRsQnYlMo7JT0NjCK7yjghrTYbWEKWFKYCcyIigKWShkoamfZjZmZN0Kj56OUOJoDpZD/ipUkaCxwFPAyMKPzQbwZGpPIoYH1hsw2pzszMmqTRcJzXtpVT888lwIXAncC1nW3XnqR3AN8CLo2IHdlTrfkxQlJ0unHH+5sBzAAYM2ZMdzY1M7MuNLzRnG4Kfw5YRZZAJkbEZRGxtczOJe1LlhBuj4hvp+otkkam5SOBtn1tBEYXNj801e0mImZFRGtEtLa0tJQJw8zMSuo0KUj6IvAo2dNGfxwRn4mIF8vuOL3odivwdERcV1i0AJiWytOA+YX689NTSJOA7b6fYGbWXI2ePvo4Wa+onwSuKDT7iKzlp6tuLo4lG5zncUkrU90ngKuBuZKmA+uAc9Ky+4FTgTXAK2RNVWZm1kSN7il0623nDrb/IVkC6cjkDtYP4KI9OaaZme2ZPfrhNzOz/sVJwczMck4KZmaWc1IwM7Ock4KZmeWcFMzMLOekYGZmOScFMzPLOSmYmVnOScHMzHJOCmZmlnNSMDOznJOCmZnlnBTMzCznpGBmZjknBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs9zgqnYs6Tbg/cDWiPifqW4Y8E1gLLAWOCciXpQk4AbgVOAV4IKIWFFVbGb92diZ99Vy3LVXn1bLcW3vqvJK4WvAye3qZgKLImI8sCjNA5wCjE/TDOCmCuMyM7NOVJYUIuIh4FftqqcCs1N5NnBGoX5OZJYCQyWNrCo2MzPrWLPvKYyIiE2pvBkYkcqjgPWF9Takut8haYakZZKWbdu2rbpIzcwGoNpuNEdEANGD7WZFRGtEtLa0tFQQmZnZwNXspLClrVkofW5N9RuB0YX1Dk11ZmbWRM1OCguAaak8DZhfqD9fmUnA9kIzk5mZNUmVj6TeAZwADJe0AbgSuBqYK2k6sA44J61+P9njqGvIHkm9sKq4zMysc5UlhYg4r5NFkztYN4CLqorFzMzK8RvNZmaWc1IwM7Ock4KZmeWcFMzMLFfZjWYzG1jq6ogP3Bnf3uQrBTMzyzkpmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5ZwUzMws56RgZmY5JwUzM8s5KZiZWc7dXJhZn1dXFxv9sXsNJwUzsx7qj/09ufnIzMxyTgpmZpbrVUlB0smSnpW0RtLMuuMxMxtoes09BUmDgP8ATgQ2AI9KWhART1VxvDrbAs3MeqvedKVwNLAmIp6PiNeBO4GpNcdkZjag9JorBWAUsL4wvwF4d/uVJM0AZqTZX0t6tofHGw78sofb1qmvxg19N3bH3VyOuwRds0eb/4/OFvSmpFBKRMwCZu3pfiQti4jWvRBSU/XVuKHvxu64m8tx16s3NR9tBEYX5g9NdWZm1iS9KSk8CoyXNE7SfsC5wIKaYzIzG1B6TfNRROyS9PfA94BBwG0R8WSFh9zjJqia9NW4oe/G7riby3HXSBFRdwxmZtZL9KbmIzMzq5mTgpmZ5QZkUugr3WlIGi1psaSnJD0p6ZJU/xlJGyWtTNOpdcfanqS1kh5P8S1LdcMkLZS0On0eXHecRZKOKJzTlZJ2SLq0N55vSbdJ2irpiUJdh+dXmRvT932VpIm9LO4vSnomxXa3pKGpfqyk3xTO+811xZ3i6Sj2Tr8bki5P5/xZSe+rJ+oeiIgBNZHdxH4OOAzYD/gp8Ed1x9VJrCOBial8IPAz4I+AzwD/VHd8XcS+Fhjeru4LwMxUnglcU3ecXXxPNpO95NPrzjdwPDAReKKr8wucCnwXEDAJeLiXxX0SMDiVrynEPba4Xt1TJ7F3+N1I/5/+FNgfGJd+cwbV/TeUmQbilUKf6U4jIjZFxIpU3gk8Tfbmd181FZidyrOBM2qMpSuTgeciYl3dgXQkIh4CftWuurPzOxWYE5mlwFBJI5sT6e46ijsivh8Ru9LsUrJ3lHqdTs55Z6YCd0bEaxHxc2AN2W9PrzcQk0JH3Wn0+h9aSWOBo4CHU9Xfp8vt23pbM0wSwPclLU9dkwCMiIhNqbwZGFFPaKWcC9xRmO/t5xs6P7996Tv/v8muatqMk/SYpAcl/UVdQXWho+9GXzrnuxmISaHPkfQO4FvApRGxA7gJOByYAGwCrq0xvM4cFxETgVOAiyQdX1wY2TV2r3weOr08OQW4K1X1hfO9m958fjsj6QpgF3B7qtoEjImIo4B/BL4h6aC64utEn/tudGUgJoU+1Z2GpH3JEsLtEfFtgIjYEhFvRMSbwFfohZelEbExfW4F7iaLcUtbs0X63FpfhA2dAqyIiC3QN8530tn57fXfeUkXAO8H/iYlNFLTywupvJysXf4PawuyAw2+G73+nHdmICaFPtOdhiQBtwJPR8R1hfpie/AHgCfab1snSQdIOrCtTHYj8Qmy8zwtrTYNmF9PhF06j0LTUW8/3wWdnd8FwPnpKaRJwPZCM1PtJJ0M/DMwJSJeKdS3KBtnBUmHAeOB5+uJsmMNvhsLgHMl7S9pHFnsjzQ7vh6p+053HRPZ0xg/I/uXxxV1x9MgzuPImgBWASvTdCrwdeDxVL8AGFl3rO3iPozsyYufAk+2nWPgEGARsBr4L2BY3bF2EPsBwAvAkEJdrzvfZElrE/Bbsvbq6Z2dX7Knjv4jfd8fB1p7WdxryNrf277jN6d1z0rfn5XACuD0XnjOO/1uAFekc/4scErd35myk7u5MDOz3EBsPjIzs044KZiZWc5JwczMck4KZmaWc1IwM7Ock4L1KZIOKfRIubldD5X7dbFtq6Qbe3jcSyX9Xs+i7nLfSyTt1QHfJQ2V9NHC/AmS7t2bx7D+yUnB+pSIeCEiJkTEBOBm4Pq2+Yh4XVKnQ8xGxLKI+FgPD30p0K2k0PbiVU2GAh/tci2zdpwUrM+T9DVJN0t6GPiCpKMl/SR1pPZjSUek9fJ/Lae3rm+T9Ehab2qqHyTp3yU9kTo5u1jSx4A/ABZLWpzWO0/ZeBFPSLqmEMuvJV0r6afAFZLuKSw7UdLdXfwtJ6XYV0i6K/V71TY+xWdT/eOSjkz1LcrGTnhS0i2S1kkaDlwNHJ6uoL6Ydv8OSfOUjV1we3pj3mx3db8958lTTydSX/bA14B7Sf3VAwfxVv/87wW+lconAPem8r8BH0rloWRvuB8A/B9gXmH7treC15LGhyBLEP8NtACDgR8AZ6RlAZyTygKeAVrS/Dfo4K1cYAnQCgwHHgIOSPWXAZ8uHP/iVP4ocEsqfwm4PJVPTscfTruxCNLfvp2sD559gJ+QdVpY+39HT71r6vRS26yPuSsi3kjlIcBsSePJfiT37WD9k4Apkv4pzb8NGEOWRG6O1L9/RHTUf/6fAUsiYhuApNvJBmC5B3iDrANDIiIkfR34kKSvAscA5zf4GyaRDc7yo/SP+P3IfrzbfDt9LgfOTOXjyPrcISIekPRig/0/EhEbUswryRLHDxusbwOQk4L1Fy8XylcBiyPiA8rGoVjSwfoCzoqIZ3er3PMWlVcLyQngq8B3gFfJEteujjfLY1oYEed1svy19PkGPft/97VCuaf7sH7O9xSsPxrCW90UX9DJOt8DLm5rV5d0VKpfCHyk7Ya1pGGpfifZkKiQ9Xb5l5KGp5vJ5wEPdnSQiPgF8Avgk2QJopGlwLGS3pmOfYCkrrqK/hFwTlr/JKBtkJdivGalOSlYf/QF4POSHuN3/zXc1gPkVWTNSqskPZnmAW4hu1+wKt0s/utUPwt4QNLiyLqdngksJusJdnlENOoG/HZgfUQ83Sjo1Bx1AXCHpFVkTUdHdvG3fhY4Sdlg8meTjbi2M7JxCH6UboR/seEezArcS6oNGJLOIuuzf1qXK+/d434JeCwibq1g3/sDb0TELknHADdF9riuWY+4TdEGBElTgH8lGwO4mcddTna/4+MVHWIMMFfSPsDrwIcrOo4NEL5SMDOznO8pmJlZzknBzMxyTgpmZpZzUjAzs5yTgpmZ5f4/SsCJpLV5z5sAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = np.array([len(i) for i in cent_data])\n",
    "plt.hist(lengths)\n",
    "plt.xlabel(\"Trajectory length\")\n",
    "plt.ylabel(\"Number of trajectories\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "ymWVIli90Uu8"
   },
   "outputs": [],
   "source": [
    "# Removing trajectories with <=5 length\n",
    "idx = np.where(lengths <= 5.)[0]\n",
    "[labels.pop(j-i) for i,j in enumerate(idx)]\n",
    "[cent_data.pop(j-i) for i,j in enumerate(idx)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "9X0N0OYxcyyJ",
    "outputId": "e7d207da-0b10-4219-ad7d-a7ab34848596"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 176,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see if it worked \n",
    "lengths = np.array([len(i) for i in cent_data])\n",
    "np.where(lengths <= 5.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "hfPRW0S7UN4b"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(cent_data, labels, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9_dZtq9NzYnZ"
   },
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902686,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "LiOpfkOpaYuO"
   },
   "outputs": [],
   "source": [
    "x_train_aug = []\n",
    "for idx,i in enumerate(x_train):\n",
    "    ch = np.random.choice([0,1],p = [0.3,0.7])\n",
    "\n",
    "    flag = 0 \n",
    "\n",
    "    if ch == 0: # Perform data augmentation\n",
    "\n",
    "    trim = len(i)//2\n",
    "\n",
    "    if trim >= 5: # Trim if the lengths are greater than 5\n",
    "\n",
    "        aug = i.head(trim)\n",
    "\n",
    "    else: # If lengths are not greater than 1, don't trim\n",
    "\n",
    "        aug = i\n",
    "    else:\n",
    "    aug = i\n",
    "\n",
    "\n",
    "    x_train_aug.append(aug)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902687,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "4OWcaGqDBPvm",
    "outputId": "560f265e-c919-47cb-e3f7-41284420d962"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1605, 1605)"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Printing out the lengths after and before augmentation\n",
    "len(x_train_aug), len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJc39yrs1nlE"
   },
   "source": [
    "## Method 2 - RNN with embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902687,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "kKLJbGtv1nlE"
   },
   "outputs": [],
   "source": [
    "# Getting the data in the required format for the model\n",
    "# Creating labels for RNN's output \n",
    "y_train = [[dt]*200 for idx,dt in enumerate(y_train)]\n",
    "y_test = [[dt]*200 for idx,dt in enumerate(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "evCXyI6-1nlE"
   },
   "outputs": [],
   "source": [
    "# Sequence length is based on data analysis\n",
    "x_train = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_train, padding='post', dtype='float', maxlen=200))\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "x_test = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_test, padding='post', dtype='float', maxlen=200))\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "ryFy62Mk1nlF"
   },
   "outputs": [],
   "source": [
    "# One hot encoding the data for training\n",
    "y_train = tf.one_hot(y_train, 9, on_value = 1.0, off_value = 0.0)\n",
    "y_test = tf.one_hot(y_test, 9, on_value = 1.0, off_value = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "y12mcLmQ1nlF"
   },
   "outputs": [],
   "source": [
    "# Creating the RNN model\n",
    "\n",
    "hidden_size= 10\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "RNN_1 = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN_1(ip_reformed)\n",
    "\n",
    "RNN_2 = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_2 = RNN_2(h_1)\n",
    "\n",
    "\n",
    "dense_2 = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense_2(h_2)\n",
    "\n",
    "model_RNN = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=tf.keras.optimizers.Adam(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902689,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "LJC8EL0egiGL"
   },
   "outputs": [],
   "source": [
    "# Creating the LSTM model\n",
    "\n",
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h = LSTM(ip_reformed)\n",
    "\n",
    "dense = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense(h)\n",
    "\n",
    "model_LSTM = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_LSTM.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=tf.keras.optimizers.Adam(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472905553,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "qsyhNfUNdb9D"
   },
   "outputs": [],
   "source": [
    "# Creating the LSTM+RNN model\n",
    "\n",
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "LSTM_1 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h_1 = LSTM_1(ip_reformed)\n",
    "\n",
    "LSTM_2 = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h_2 = LSTM_2(h_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense(h_2)\n",
    "\n",
    "model_LSTM_2 = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_LSTM_2.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=tf.keras.optimizers.Adam(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472905553,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "29kaMRnt1nlF",
    "outputId": "96eed065-c571-49cd-fffa-6e4ef9d4d358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 200, 3)]          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200, 15)           60        \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 15)           1860      \n",
      "                                                                 \n",
      " lstm_1 (LSTM)               (None, 200, 15)           1860      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200, 9)            144       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,924\n",
      "Trainable params: 3,924\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model_LSTM.summary()\n",
    "model_LSTM_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "executionInfo": {
     "elapsed": 1593,
     "status": "ok",
     "timestamp": 1670472927009,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "7B3g6dUGOOoU"
   },
   "outputs": [],
   "source": [
    "callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_accuracy',\n",
    "    patience=100,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdnYYPv_1nlF",
    "outputId": "a1bb33a5-8b8c-446d-9016-a14cbc846054"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "81/81 [==============================] - 6s 31ms/step - loss: 2.1128 - accuracy: 0.1342 - val_loss: 1.7984 - val_accuracy: 0.2358\n",
      "Epoch 2/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 1.5934 - accuracy: 0.2750 - val_loss: 1.4357 - val_accuracy: 0.2981\n",
      "Epoch 3/1000\n",
      "81/81 [==============================] - 4s 49ms/step - loss: 1.4570 - accuracy: 0.2919 - val_loss: 1.4231 - val_accuracy: 0.3000\n",
      "Epoch 4/1000\n",
      "81/81 [==============================] - 2s 27ms/step - loss: 1.5533 - accuracy: 0.2954 - val_loss: 2.3396 - val_accuracy: 0.2173\n",
      "Epoch 5/1000\n",
      "81/81 [==============================] - 2s 23ms/step - loss: 1.9039 - accuracy: 0.2331 - val_loss: 1.8001 - val_accuracy: 0.2267\n",
      "Epoch 6/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 1.7409 - accuracy: 0.2443 - val_loss: 1.7002 - val_accuracy: 0.3039\n",
      "Epoch 7/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 1.6719 - accuracy: 0.2874 - val_loss: 1.6516 - val_accuracy: 0.3114\n",
      "Epoch 8/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 1.5111 - accuracy: 0.3719 - val_loss: 1.4190 - val_accuracy: 0.3537\n",
      "Epoch 9/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 1.2457 - accuracy: 0.4453 - val_loss: 1.2112 - val_accuracy: 0.4497\n",
      "Epoch 10/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 1.2065 - accuracy: 0.4890 - val_loss: 1.2675 - val_accuracy: 0.4885\n",
      "Epoch 11/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 1.2121 - accuracy: 0.4674 - val_loss: 1.1599 - val_accuracy: 0.5384\n",
      "Epoch 12/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 1.0952 - accuracy: 0.5375 - val_loss: 1.3348 - val_accuracy: 0.4735\n",
      "Epoch 13/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 1.0951 - accuracy: 0.5393 - val_loss: 1.0624 - val_accuracy: 0.5195\n",
      "Epoch 14/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 1.0230 - accuracy: 0.5680 - val_loss: 1.0331 - val_accuracy: 0.5496\n",
      "Epoch 15/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.9649 - accuracy: 0.6174 - val_loss: 0.9783 - val_accuracy: 0.6207\n",
      "Epoch 16/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.9345 - accuracy: 0.6326 - val_loss: 0.9440 - val_accuracy: 0.6274\n",
      "Epoch 17/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.9019 - accuracy: 0.6416 - val_loss: 0.9071 - val_accuracy: 0.6427\n",
      "Epoch 18/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.8778 - accuracy: 0.6419 - val_loss: 0.9079 - val_accuracy: 0.6540\n",
      "Epoch 19/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.8496 - accuracy: 0.6619 - val_loss: 0.8455 - val_accuracy: 0.6855\n",
      "Epoch 20/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.7813 - accuracy: 0.7110 - val_loss: 0.7501 - val_accuracy: 0.7195\n",
      "Epoch 21/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 1.5175 - accuracy: 0.4837 - val_loss: 2.0933 - val_accuracy: 0.1769\n",
      "Epoch 22/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 1.8258 - accuracy: 0.2895 - val_loss: 1.7338 - val_accuracy: 0.2662\n",
      "Epoch 23/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 1.6312 - accuracy: 0.3543 - val_loss: 1.5301 - val_accuracy: 0.4431\n",
      "Epoch 24/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 1.3744 - accuracy: 0.5386 - val_loss: 0.9915 - val_accuracy: 0.7479\n",
      "Epoch 25/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.8581 - accuracy: 0.7471 - val_loss: 0.7991 - val_accuracy: 0.7750\n",
      "Epoch 26/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.7527 - accuracy: 0.7746 - val_loss: 0.6974 - val_accuracy: 0.7860\n",
      "Epoch 27/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.6910 - accuracy: 0.7873 - val_loss: 0.6877 - val_accuracy: 0.7883\n",
      "Epoch 28/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.6750 - accuracy: 0.7852 - val_loss: 0.6571 - val_accuracy: 0.7929\n",
      "Epoch 29/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.6491 - accuracy: 0.7925 - val_loss: 0.6339 - val_accuracy: 0.7954\n",
      "Epoch 30/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.6196 - accuracy: 0.7987 - val_loss: 0.6128 - val_accuracy: 0.7993\n",
      "Epoch 31/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.6034 - accuracy: 0.7999 - val_loss: 0.6001 - val_accuracy: 0.8019\n",
      "Epoch 32/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5876 - accuracy: 0.8015 - val_loss: 0.5940 - val_accuracy: 0.7996\n",
      "Epoch 33/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5731 - accuracy: 0.8060 - val_loss: 0.5746 - val_accuracy: 0.8015\n",
      "Epoch 34/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5745 - accuracy: 0.8013 - val_loss: 0.5778 - val_accuracy: 0.8014\n",
      "Epoch 35/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.5528 - accuracy: 0.8055 - val_loss: 0.5571 - val_accuracy: 0.8060\n",
      "Epoch 36/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5420 - accuracy: 0.8080 - val_loss: 0.5472 - val_accuracy: 0.8084\n",
      "Epoch 37/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.5292 - accuracy: 0.8117 - val_loss: 0.5506 - val_accuracy: 0.8065\n",
      "Epoch 38/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5286 - accuracy: 0.8121 - val_loss: 0.5760 - val_accuracy: 0.8027\n",
      "Epoch 39/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5590 - accuracy: 0.8006 - val_loss: 0.5661 - val_accuracy: 0.8012\n",
      "Epoch 40/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.5244 - accuracy: 0.8116 - val_loss: 0.5285 - val_accuracy: 0.8139\n",
      "Epoch 41/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5107 - accuracy: 0.8162 - val_loss: 0.5192 - val_accuracy: 0.8162\n",
      "Epoch 42/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5133 - accuracy: 0.8123 - val_loss: 0.5593 - val_accuracy: 0.8011\n",
      "Epoch 43/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5062 - accuracy: 0.8164 - val_loss: 0.5147 - val_accuracy: 0.8181\n",
      "Epoch 44/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4944 - accuracy: 0.8206 - val_loss: 0.5200 - val_accuracy: 0.8107\n",
      "Epoch 45/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4919 - accuracy: 0.8221 - val_loss: 0.5047 - val_accuracy: 0.8215\n",
      "Epoch 46/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4857 - accuracy: 0.8227 - val_loss: 0.5031 - val_accuracy: 0.8224\n",
      "Epoch 47/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4854 - accuracy: 0.8214 - val_loss: 0.5135 - val_accuracy: 0.8184\n",
      "Epoch 48/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4876 - accuracy: 0.8211 - val_loss: 0.5269 - val_accuracy: 0.8129\n",
      "Epoch 49/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5515 - accuracy: 0.8035 - val_loss: 0.6167 - val_accuracy: 0.7782\n",
      "Epoch 50/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.5067 - accuracy: 0.8178 - val_loss: 0.5026 - val_accuracy: 0.8215\n",
      "Epoch 51/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4847 - accuracy: 0.8221 - val_loss: 0.4863 - val_accuracy: 0.8268\n",
      "Epoch 52/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4736 - accuracy: 0.8272 - val_loss: 0.5166 - val_accuracy: 0.8132\n",
      "Epoch 53/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.4819 - accuracy: 0.8221 - val_loss: 0.6219 - val_accuracy: 0.7864\n",
      "Epoch 54/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4793 - accuracy: 0.8258 - val_loss: 0.4813 - val_accuracy: 0.8232\n",
      "Epoch 55/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4647 - accuracy: 0.8291 - val_loss: 0.4770 - val_accuracy: 0.8264\n",
      "Epoch 56/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4680 - accuracy: 0.8278 - val_loss: 0.5041 - val_accuracy: 0.8293\n",
      "Epoch 57/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.4628 - accuracy: 0.8288 - val_loss: 0.4780 - val_accuracy: 0.8271\n",
      "Epoch 58/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.4568 - accuracy: 0.8329 - val_loss: 0.4861 - val_accuracy: 0.8306\n",
      "Epoch 59/1000\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 0.4593 - accuracy: 0.8314 - val_loss: 0.4787 - val_accuracy: 0.8275\n",
      "Epoch 60/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4578 - accuracy: 0.8305 - val_loss: 0.4854 - val_accuracy: 0.8240\n",
      "Epoch 61/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4576 - accuracy: 0.8311 - val_loss: 0.4748 - val_accuracy: 0.8309\n",
      "Epoch 62/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4525 - accuracy: 0.8337 - val_loss: 0.4720 - val_accuracy: 0.8286\n",
      "Epoch 63/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4518 - accuracy: 0.8345 - val_loss: 0.4683 - val_accuracy: 0.8329\n",
      "Epoch 64/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4576 - accuracy: 0.8319 - val_loss: 0.4801 - val_accuracy: 0.8287\n",
      "Epoch 65/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.8089 - accuracy: 0.7491 - val_loss: 0.6944 - val_accuracy: 0.7912\n",
      "Epoch 66/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5641 - accuracy: 0.8044 - val_loss: 0.5453 - val_accuracy: 0.8088\n",
      "Epoch 67/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.5068 - accuracy: 0.8178 - val_loss: 0.5442 - val_accuracy: 0.8129\n",
      "Epoch 68/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4819 - accuracy: 0.8248 - val_loss: 0.5448 - val_accuracy: 0.8130\n",
      "Epoch 69/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4709 - accuracy: 0.8287 - val_loss: 0.5183 - val_accuracy: 0.8242\n",
      "Epoch 70/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4667 - accuracy: 0.8290 - val_loss: 0.5051 - val_accuracy: 0.8219\n",
      "Epoch 71/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4572 - accuracy: 0.8326 - val_loss: 0.5305 - val_accuracy: 0.8249\n",
      "Epoch 72/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4537 - accuracy: 0.8330 - val_loss: 0.5052 - val_accuracy: 0.8253\n",
      "Epoch 73/1000\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 0.4602 - accuracy: 0.8332 - val_loss: 0.4933 - val_accuracy: 0.8277\n",
      "Epoch 74/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.4648 - accuracy: 0.8298 - val_loss: 0.4913 - val_accuracy: 0.8271\n",
      "Epoch 75/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.4499 - accuracy: 0.8347 - val_loss: 0.4886 - val_accuracy: 0.8268\n",
      "Epoch 76/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4511 - accuracy: 0.8342 - val_loss: 0.4875 - val_accuracy: 0.8262\n",
      "Epoch 77/1000\n",
      "81/81 [==============================] - 2s 23ms/step - loss: 0.4778 - accuracy: 0.8224 - val_loss: 0.4800 - val_accuracy: 0.8272\n",
      "Epoch 78/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4481 - accuracy: 0.8365 - val_loss: 0.4791 - val_accuracy: 0.8254\n",
      "Epoch 79/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4484 - accuracy: 0.8357 - val_loss: 0.4969 - val_accuracy: 0.8234\n",
      "Epoch 80/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.4410 - accuracy: 0.8370 - val_loss: 0.4737 - val_accuracy: 0.8301\n",
      "Epoch 81/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4381 - accuracy: 0.8386 - val_loss: 0.4803 - val_accuracy: 0.8275\n",
      "Epoch 82/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.4397 - accuracy: 0.8378 - val_loss: 0.4812 - val_accuracy: 0.8296\n",
      "Epoch 83/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4500 - accuracy: 0.8341 - val_loss: 0.4870 - val_accuracy: 0.8299\n",
      "Epoch 84/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.4381 - accuracy: 0.8372 - val_loss: 0.4931 - val_accuracy: 0.8285\n",
      "Epoch 85/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.4333 - accuracy: 0.8394 - val_loss: 0.4900 - val_accuracy: 0.8248\n",
      "Epoch 86/1000\n",
      "81/81 [==============================] - 2s 21ms/step - loss: 0.4339 - accuracy: 0.8397 - val_loss: 0.4759 - val_accuracy: 0.8306\n",
      "Epoch 87/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4347 - accuracy: 0.8409 - val_loss: 0.4663 - val_accuracy: 0.8333\n",
      "Epoch 88/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.4334 - accuracy: 0.8402 - val_loss: 0.4591 - val_accuracy: 0.8323\n",
      "Epoch 89/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4289 - accuracy: 0.8421 - val_loss: 0.4615 - val_accuracy: 0.8307\n",
      "Epoch 90/1000\n",
      "81/81 [==============================] - 1s 16ms/step - loss: 0.4796 - accuracy: 0.8241 - val_loss: 0.5016 - val_accuracy: 0.8258\n",
      "Epoch 91/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4459 - accuracy: 0.8363 - val_loss: 0.4596 - val_accuracy: 0.8333\n",
      "Epoch 92/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.5454 - accuracy: 0.8039 - val_loss: 0.4958 - val_accuracy: 0.8197\n",
      "Epoch 93/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4560 - accuracy: 0.8336 - val_loss: 0.4604 - val_accuracy: 0.8337\n",
      "Epoch 94/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4473 - accuracy: 0.8365 - val_loss: 0.4618 - val_accuracy: 0.8365\n",
      "Epoch 95/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4430 - accuracy: 0.8385 - val_loss: 0.4534 - val_accuracy: 0.8373\n",
      "Epoch 96/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4327 - accuracy: 0.8411 - val_loss: 0.4504 - val_accuracy: 0.8386\n",
      "Epoch 97/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4301 - accuracy: 0.8411 - val_loss: 0.4566 - val_accuracy: 0.8353\n",
      "Epoch 98/1000\n",
      "81/81 [==============================] - 2s 23ms/step - loss: 0.4296 - accuracy: 0.8429 - val_loss: 0.4558 - val_accuracy: 0.8328\n",
      "Epoch 99/1000\n",
      "81/81 [==============================] - 3s 32ms/step - loss: 0.4333 - accuracy: 0.8395 - val_loss: 0.4591 - val_accuracy: 0.8351\n",
      "Epoch 100/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4292 - accuracy: 0.8429 - val_loss: 0.4673 - val_accuracy: 0.8322\n",
      "Epoch 101/1000\n",
      "81/81 [==============================] - 2s 21ms/step - loss: 0.4260 - accuracy: 0.8423 - val_loss: 0.4560 - val_accuracy: 0.8326\n",
      "Epoch 102/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4242 - accuracy: 0.8424 - val_loss: 0.4562 - val_accuracy: 0.8352\n",
      "Epoch 103/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4214 - accuracy: 0.8451 - val_loss: 0.4488 - val_accuracy: 0.8348\n",
      "Epoch 104/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4215 - accuracy: 0.8451 - val_loss: 0.4518 - val_accuracy: 0.8365\n",
      "Epoch 105/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4232 - accuracy: 0.8427 - val_loss: 0.4552 - val_accuracy: 0.8349\n",
      "Epoch 106/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4187 - accuracy: 0.8447 - val_loss: 0.4496 - val_accuracy: 0.8367\n",
      "Epoch 107/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4235 - accuracy: 0.8441 - val_loss: 0.4529 - val_accuracy: 0.8369\n",
      "Epoch 108/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.4185 - accuracy: 0.8453 - val_loss: 0.4465 - val_accuracy: 0.8378\n",
      "Epoch 109/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4182 - accuracy: 0.8446 - val_loss: 0.4457 - val_accuracy: 0.8386\n",
      "Epoch 110/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4632 - accuracy: 0.8248 - val_loss: 0.5467 - val_accuracy: 0.8027\n",
      "Epoch 111/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4440 - accuracy: 0.8350 - val_loss: 0.4628 - val_accuracy: 0.8312\n",
      "Epoch 112/1000\n",
      "81/81 [==============================] - 2s 22ms/step - loss: 0.4214 - accuracy: 0.8452 - val_loss: 0.4541 - val_accuracy: 0.8363\n",
      "Epoch 113/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.4176 - accuracy: 0.8447 - val_loss: 0.4587 - val_accuracy: 0.8360\n",
      "Epoch 114/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4145 - accuracy: 0.8463 - val_loss: 0.4614 - val_accuracy: 0.8350\n",
      "Epoch 115/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4157 - accuracy: 0.8468 - val_loss: 0.4581 - val_accuracy: 0.8315\n",
      "Epoch 116/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4128 - accuracy: 0.8464 - val_loss: 0.4588 - val_accuracy: 0.8337\n",
      "Epoch 117/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4154 - accuracy: 0.8475 - val_loss: 0.4518 - val_accuracy: 0.8395\n",
      "Epoch 118/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4121 - accuracy: 0.8474 - val_loss: 0.4683 - val_accuracy: 0.8372\n",
      "Epoch 119/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4140 - accuracy: 0.8460 - val_loss: 0.4755 - val_accuracy: 0.8349\n",
      "Epoch 120/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4140 - accuracy: 0.8463 - val_loss: 0.4606 - val_accuracy: 0.8372\n",
      "Epoch 121/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4103 - accuracy: 0.8484 - val_loss: 0.4685 - val_accuracy: 0.8344\n",
      "Epoch 122/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4135 - accuracy: 0.8457 - val_loss: 0.4506 - val_accuracy: 0.8374\n",
      "Epoch 123/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4083 - accuracy: 0.8487 - val_loss: 0.4493 - val_accuracy: 0.8402\n",
      "Epoch 124/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4210 - accuracy: 0.8446 - val_loss: 0.4547 - val_accuracy: 0.8390\n",
      "Epoch 125/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4890 - accuracy: 0.8249 - val_loss: 0.5692 - val_accuracy: 0.8068\n",
      "Epoch 126/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4358 - accuracy: 0.8372 - val_loss: 0.4726 - val_accuracy: 0.8300\n",
      "Epoch 127/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4163 - accuracy: 0.8445 - val_loss: 0.4660 - val_accuracy: 0.8328\n",
      "Epoch 128/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4118 - accuracy: 0.8482 - val_loss: 0.4686 - val_accuracy: 0.8351\n",
      "Epoch 129/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4091 - accuracy: 0.8479 - val_loss: 0.4644 - val_accuracy: 0.8337\n",
      "Epoch 130/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4073 - accuracy: 0.8482 - val_loss: 0.4540 - val_accuracy: 0.8361\n",
      "Epoch 131/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4110 - accuracy: 0.8467 - val_loss: 0.4773 - val_accuracy: 0.8371\n",
      "Epoch 132/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4069 - accuracy: 0.8487 - val_loss: 0.4671 - val_accuracy: 0.8343\n",
      "Epoch 133/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4053 - accuracy: 0.8497 - val_loss: 0.4625 - val_accuracy: 0.8413\n",
      "Epoch 134/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4028 - accuracy: 0.8498 - val_loss: 0.4605 - val_accuracy: 0.8389\n",
      "Epoch 135/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4039 - accuracy: 0.8495 - val_loss: 0.4850 - val_accuracy: 0.8350\n",
      "Epoch 136/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5657 - accuracy: 0.7909 - val_loss: 0.7450 - val_accuracy: 0.7355\n",
      "Epoch 137/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.5926 - accuracy: 0.7912 - val_loss: 0.4665 - val_accuracy: 0.8329\n",
      "Epoch 138/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4397 - accuracy: 0.8398 - val_loss: 0.4651 - val_accuracy: 0.8326\n",
      "Epoch 139/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4238 - accuracy: 0.8437 - val_loss: 0.4589 - val_accuracy: 0.8381\n",
      "Epoch 140/1000\n",
      "81/81 [==============================] - 2s 22ms/step - loss: 0.4168 - accuracy: 0.8465 - val_loss: 0.4582 - val_accuracy: 0.8377\n",
      "Epoch 141/1000\n",
      "81/81 [==============================] - 2s 24ms/step - loss: 0.4130 - accuracy: 0.8479 - val_loss: 0.4612 - val_accuracy: 0.8373\n",
      "Epoch 142/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4105 - accuracy: 0.8474 - val_loss: 0.4559 - val_accuracy: 0.8348\n",
      "Epoch 143/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4099 - accuracy: 0.8477 - val_loss: 0.4694 - val_accuracy: 0.8345\n",
      "Epoch 144/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4079 - accuracy: 0.8478 - val_loss: 0.4545 - val_accuracy: 0.8380\n",
      "Epoch 145/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4074 - accuracy: 0.8488 - val_loss: 0.4653 - val_accuracy: 0.8353\n",
      "Epoch 146/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4072 - accuracy: 0.8481 - val_loss: 0.4524 - val_accuracy: 0.8390\n",
      "Epoch 147/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4060 - accuracy: 0.8489 - val_loss: 0.4519 - val_accuracy: 0.8389\n",
      "Epoch 148/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4039 - accuracy: 0.8495 - val_loss: 0.4585 - val_accuracy: 0.8365\n",
      "Epoch 149/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4019 - accuracy: 0.8494 - val_loss: 0.4661 - val_accuracy: 0.8338\n",
      "Epoch 150/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4032 - accuracy: 0.8492 - val_loss: 0.4607 - val_accuracy: 0.8341\n",
      "Epoch 151/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4008 - accuracy: 0.8511 - val_loss: 0.4682 - val_accuracy: 0.8379\n",
      "Epoch 152/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4039 - accuracy: 0.8486 - val_loss: 0.4510 - val_accuracy: 0.8418\n",
      "Epoch 153/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4570 - accuracy: 0.8294 - val_loss: 0.4703 - val_accuracy: 0.8302\n",
      "Epoch 154/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4212 - accuracy: 0.8436 - val_loss: 0.4623 - val_accuracy: 0.8337\n",
      "Epoch 155/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4097 - accuracy: 0.8489 - val_loss: 0.4527 - val_accuracy: 0.8357\n",
      "Epoch 156/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4045 - accuracy: 0.8482 - val_loss: 0.4492 - val_accuracy: 0.8404\n",
      "Epoch 157/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4038 - accuracy: 0.8488 - val_loss: 0.4569 - val_accuracy: 0.8378\n",
      "Epoch 158/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3995 - accuracy: 0.8508 - val_loss: 0.4513 - val_accuracy: 0.8384\n",
      "Epoch 159/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4019 - accuracy: 0.8489 - val_loss: 0.4655 - val_accuracy: 0.8359\n",
      "Epoch 160/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3981 - accuracy: 0.8517 - val_loss: 0.4611 - val_accuracy: 0.8378\n",
      "Epoch 161/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4034 - accuracy: 0.8487 - val_loss: 0.4512 - val_accuracy: 0.8385\n",
      "Epoch 162/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4007 - accuracy: 0.8499 - val_loss: 0.4556 - val_accuracy: 0.8394\n",
      "Epoch 163/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.3997 - accuracy: 0.8514 - val_loss: 0.4489 - val_accuracy: 0.8392\n",
      "Epoch 164/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3958 - accuracy: 0.8506 - val_loss: 0.4571 - val_accuracy: 0.8379\n",
      "Epoch 165/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3968 - accuracy: 0.8521 - val_loss: 0.4542 - val_accuracy: 0.8370\n",
      "Epoch 166/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3971 - accuracy: 0.8509 - val_loss: 0.4585 - val_accuracy: 0.8403\n",
      "Epoch 167/1000\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 0.3952 - accuracy: 0.8528 - val_loss: 0.4561 - val_accuracy: 0.8376\n",
      "Epoch 168/1000\n",
      "81/81 [==============================] - 2s 24ms/step - loss: 0.3969 - accuracy: 0.8511 - val_loss: 0.4599 - val_accuracy: 0.8386\n",
      "Epoch 169/1000\n",
      "81/81 [==============================] - 2s 21ms/step - loss: 0.3959 - accuracy: 0.8512 - val_loss: 0.4549 - val_accuracy: 0.8380\n",
      "Epoch 170/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3952 - accuracy: 0.8531 - val_loss: 0.4900 - val_accuracy: 0.8357\n",
      "Epoch 171/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4290 - accuracy: 0.8419 - val_loss: 0.5351 - val_accuracy: 0.8180\n",
      "Epoch 172/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4735 - accuracy: 0.8306 - val_loss: 0.4859 - val_accuracy: 0.8299\n",
      "Epoch 173/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4229 - accuracy: 0.8445 - val_loss: 0.4545 - val_accuracy: 0.8387\n",
      "Epoch 174/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4115 - accuracy: 0.8480 - val_loss: 0.4494 - val_accuracy: 0.8356\n",
      "Epoch 175/1000\n",
      "81/81 [==============================] - 1s 19ms/step - loss: 0.4019 - accuracy: 0.8513 - val_loss: 0.4637 - val_accuracy: 0.8348\n",
      "Epoch 176/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4008 - accuracy: 0.8512 - val_loss: 0.4487 - val_accuracy: 0.8378\n",
      "Epoch 177/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.4071 - accuracy: 0.8500 - val_loss: 0.4490 - val_accuracy: 0.8353\n",
      "Epoch 178/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3996 - accuracy: 0.8515 - val_loss: 0.4597 - val_accuracy: 0.8367\n",
      "Epoch 179/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3979 - accuracy: 0.8525 - val_loss: 0.4472 - val_accuracy: 0.8354\n",
      "Epoch 180/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3937 - accuracy: 0.8529 - val_loss: 0.4605 - val_accuracy: 0.8325\n",
      "Epoch 181/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3976 - accuracy: 0.8521 - val_loss: 0.4544 - val_accuracy: 0.8389\n",
      "Epoch 182/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3952 - accuracy: 0.8533 - val_loss: 0.4391 - val_accuracy: 0.8404\n",
      "Epoch 183/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3924 - accuracy: 0.8540 - val_loss: 0.4520 - val_accuracy: 0.8384\n",
      "Epoch 184/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3952 - accuracy: 0.8527 - val_loss: 0.4552 - val_accuracy: 0.8352\n",
      "Epoch 185/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3939 - accuracy: 0.8526 - val_loss: 0.4878 - val_accuracy: 0.8231\n",
      "Epoch 186/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4158 - accuracy: 0.8452 - val_loss: 0.4698 - val_accuracy: 0.8338\n",
      "Epoch 187/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3929 - accuracy: 0.8531 - val_loss: 0.4621 - val_accuracy: 0.8381\n",
      "Epoch 188/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3889 - accuracy: 0.8551 - val_loss: 0.4598 - val_accuracy: 0.8389\n",
      "Epoch 189/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3897 - accuracy: 0.8545 - val_loss: 0.4603 - val_accuracy: 0.8356\n",
      "Epoch 190/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3891 - accuracy: 0.8549 - val_loss: 0.4465 - val_accuracy: 0.8406\n",
      "Epoch 191/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3913 - accuracy: 0.8531 - val_loss: 0.4559 - val_accuracy: 0.8358\n",
      "Epoch 192/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3974 - accuracy: 0.8521 - val_loss: 0.4529 - val_accuracy: 0.8357\n",
      "Epoch 193/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3894 - accuracy: 0.8545 - val_loss: 0.4670 - val_accuracy: 0.8360\n",
      "Epoch 194/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3890 - accuracy: 0.8547 - val_loss: 0.4765 - val_accuracy: 0.8343\n",
      "Epoch 195/1000\n",
      "81/81 [==============================] - 2s 23ms/step - loss: 0.3887 - accuracy: 0.8547 - val_loss: 0.4475 - val_accuracy: 0.8420\n",
      "Epoch 196/1000\n",
      "81/81 [==============================] - 2s 26ms/step - loss: 0.3895 - accuracy: 0.8542 - val_loss: 0.4749 - val_accuracy: 0.8374\n",
      "Epoch 197/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4751 - accuracy: 0.8275 - val_loss: 0.4982 - val_accuracy: 0.8179\n",
      "Epoch 198/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4864 - accuracy: 0.8187 - val_loss: 0.4544 - val_accuracy: 0.8363\n",
      "Epoch 199/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4083 - accuracy: 0.8496 - val_loss: 0.4745 - val_accuracy: 0.8353\n",
      "Epoch 200/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4003 - accuracy: 0.8513 - val_loss: 0.4527 - val_accuracy: 0.8404\n",
      "Epoch 201/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3914 - accuracy: 0.8539 - val_loss: 0.4550 - val_accuracy: 0.8375\n",
      "Epoch 202/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3883 - accuracy: 0.8565 - val_loss: 0.4518 - val_accuracy: 0.8399\n",
      "Epoch 203/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3852 - accuracy: 0.8565 - val_loss: 0.4647 - val_accuracy: 0.8391\n",
      "Epoch 204/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3851 - accuracy: 0.8565 - val_loss: 0.4554 - val_accuracy: 0.8389\n",
      "Epoch 205/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3839 - accuracy: 0.8570 - val_loss: 0.4834 - val_accuracy: 0.8385\n",
      "Epoch 206/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3837 - accuracy: 0.8576 - val_loss: 0.4727 - val_accuracy: 0.8393\n",
      "Epoch 207/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4498 - accuracy: 0.8394 - val_loss: 0.4636 - val_accuracy: 0.8399\n",
      "Epoch 208/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3994 - accuracy: 0.8511 - val_loss: 0.4597 - val_accuracy: 0.8415\n",
      "Epoch 209/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3888 - accuracy: 0.8555 - val_loss: 0.4600 - val_accuracy: 0.8429\n",
      "Epoch 210/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3839 - accuracy: 0.8564 - val_loss: 0.4825 - val_accuracy: 0.8320\n",
      "Epoch 211/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3860 - accuracy: 0.8575 - val_loss: 0.4485 - val_accuracy: 0.8384\n",
      "Epoch 212/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3850 - accuracy: 0.8557 - val_loss: 0.4715 - val_accuracy: 0.8355\n",
      "Epoch 213/1000\n",
      "81/81 [==============================] - 2s 21ms/step - loss: 0.3849 - accuracy: 0.8559 - val_loss: 0.4690 - val_accuracy: 0.8359\n",
      "Epoch 214/1000\n",
      "81/81 [==============================] - 2s 24ms/step - loss: 0.3841 - accuracy: 0.8572 - val_loss: 0.4563 - val_accuracy: 0.8374\n",
      "Epoch 215/1000\n",
      "81/81 [==============================] - 2s 21ms/step - loss: 0.3813 - accuracy: 0.8572 - val_loss: 0.4669 - val_accuracy: 0.8340\n",
      "Epoch 216/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3831 - accuracy: 0.8563 - val_loss: 0.4680 - val_accuracy: 0.8372\n",
      "Epoch 217/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3834 - accuracy: 0.8574 - val_loss: 0.4629 - val_accuracy: 0.8410\n",
      "Epoch 218/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3790 - accuracy: 0.8567 - val_loss: 0.4829 - val_accuracy: 0.8339\n",
      "Epoch 219/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3834 - accuracy: 0.8567 - val_loss: 0.4697 - val_accuracy: 0.8385\n",
      "Epoch 220/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.4444 - accuracy: 0.8410 - val_loss: 0.4506 - val_accuracy: 0.8405\n",
      "Epoch 221/1000\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 0.3888 - accuracy: 0.8549 - val_loss: 0.4583 - val_accuracy: 0.8377\n",
      "Epoch 222/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.3820 - accuracy: 0.8562 - val_loss: 0.4572 - val_accuracy: 0.8423\n",
      "Epoch 223/1000\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 0.3807 - accuracy: 0.8572 - val_loss: 0.4621 - val_accuracy: 0.8401\n",
      "Epoch 224/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3813 - accuracy: 0.8571 - val_loss: 0.4550 - val_accuracy: 0.8418\n",
      "Epoch 225/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3831 - accuracy: 0.8577 - val_loss: 0.4961 - val_accuracy: 0.8305\n",
      "Epoch 226/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3783 - accuracy: 0.8590 - val_loss: 0.4884 - val_accuracy: 0.8377\n",
      "Epoch 227/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3816 - accuracy: 0.8578 - val_loss: 0.4666 - val_accuracy: 0.8411\n",
      "Epoch 228/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3808 - accuracy: 0.8585 - val_loss: 0.4631 - val_accuracy: 0.8354\n",
      "Epoch 229/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3832 - accuracy: 0.8561 - val_loss: 0.4541 - val_accuracy: 0.8386\n",
      "Epoch 230/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3801 - accuracy: 0.8591 - val_loss: 0.4693 - val_accuracy: 0.8403\n",
      "Epoch 231/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3789 - accuracy: 0.8587 - val_loss: 0.4760 - val_accuracy: 0.8419\n",
      "Epoch 232/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3811 - accuracy: 0.8571 - val_loss: 0.4672 - val_accuracy: 0.8394\n",
      "Epoch 233/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3761 - accuracy: 0.8608 - val_loss: 0.4588 - val_accuracy: 0.8421\n",
      "Epoch 234/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3753 - accuracy: 0.8601 - val_loss: 0.4712 - val_accuracy: 0.8421\n",
      "Epoch 235/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3778 - accuracy: 0.8588 - val_loss: 0.4625 - val_accuracy: 0.8432\n",
      "Epoch 236/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.3780 - accuracy: 0.8587 - val_loss: 0.4734 - val_accuracy: 0.8362\n",
      "Epoch 237/1000\n",
      "81/81 [==============================] - 2s 24ms/step - loss: 0.3743 - accuracy: 0.8607 - val_loss: 0.4572 - val_accuracy: 0.8412\n",
      "Epoch 238/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3753 - accuracy: 0.8603 - val_loss: 0.4820 - val_accuracy: 0.8393\n",
      "Epoch 239/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3768 - accuracy: 0.8601 - val_loss: 0.4750 - val_accuracy: 0.8404\n",
      "Epoch 240/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3754 - accuracy: 0.8604 - val_loss: 0.4775 - val_accuracy: 0.8401\n",
      "Epoch 241/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3741 - accuracy: 0.8607 - val_loss: 0.4650 - val_accuracy: 0.8396\n",
      "Epoch 242/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3733 - accuracy: 0.8599 - val_loss: 0.4687 - val_accuracy: 0.8414\n",
      "Epoch 243/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3814 - accuracy: 0.8587 - val_loss: 0.4815 - val_accuracy: 0.8377\n",
      "Epoch 244/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3880 - accuracy: 0.8559 - val_loss: 0.4813 - val_accuracy: 0.8388\n",
      "Epoch 245/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3754 - accuracy: 0.8595 - val_loss: 0.4853 - val_accuracy: 0.8373\n",
      "Epoch 246/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3783 - accuracy: 0.8583 - val_loss: 0.5013 - val_accuracy: 0.8327\n",
      "Epoch 247/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3835 - accuracy: 0.8563 - val_loss: 0.4800 - val_accuracy: 0.8386\n",
      "Epoch 248/1000\n",
      "81/81 [==============================] - 2s 23ms/step - loss: 0.3782 - accuracy: 0.8593 - val_loss: 0.4911 - val_accuracy: 0.8402\n",
      "Epoch 249/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.3795 - accuracy: 0.8583 - val_loss: 0.4709 - val_accuracy: 0.8407\n",
      "Epoch 250/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3850 - accuracy: 0.8569 - val_loss: 0.4655 - val_accuracy: 0.8374\n",
      "Epoch 251/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3784 - accuracy: 0.8580 - val_loss: 0.4726 - val_accuracy: 0.8436\n",
      "Epoch 252/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3772 - accuracy: 0.8598 - val_loss: 0.4836 - val_accuracy: 0.8381\n",
      "Epoch 253/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3801 - accuracy: 0.8571 - val_loss: 0.4848 - val_accuracy: 0.8367\n",
      "Epoch 254/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3762 - accuracy: 0.8608 - val_loss: 0.4599 - val_accuracy: 0.8375\n",
      "Epoch 255/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3721 - accuracy: 0.8620 - val_loss: 0.4533 - val_accuracy: 0.8442\n",
      "Epoch 256/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.3712 - accuracy: 0.8616 - val_loss: 0.4684 - val_accuracy: 0.8398\n",
      "Epoch 257/1000\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 0.3728 - accuracy: 0.8610 - val_loss: 0.4749 - val_accuracy: 0.8369\n",
      "Epoch 258/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3701 - accuracy: 0.8618 - val_loss: 0.4665 - val_accuracy: 0.8424\n",
      "Epoch 259/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3701 - accuracy: 0.8622 - val_loss: 0.4724 - val_accuracy: 0.8416\n",
      "Epoch 260/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3755 - accuracy: 0.8604 - val_loss: 0.4808 - val_accuracy: 0.8392\n",
      "Epoch 261/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3724 - accuracy: 0.8605 - val_loss: 0.4736 - val_accuracy: 0.8414\n",
      "Epoch 262/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3695 - accuracy: 0.8621 - val_loss: 0.4559 - val_accuracy: 0.8447\n",
      "Epoch 263/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3749 - accuracy: 0.8596 - val_loss: 0.4626 - val_accuracy: 0.8442\n",
      "Epoch 264/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3707 - accuracy: 0.8614 - val_loss: 0.4841 - val_accuracy: 0.8369\n",
      "Epoch 265/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3686 - accuracy: 0.8613 - val_loss: 0.4714 - val_accuracy: 0.8410\n",
      "Epoch 266/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3675 - accuracy: 0.8623 - val_loss: 0.4808 - val_accuracy: 0.8412\n",
      "Epoch 267/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3704 - accuracy: 0.8605 - val_loss: 0.5111 - val_accuracy: 0.8351\n",
      "Epoch 268/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.5771 - accuracy: 0.8018 - val_loss: 0.5430 - val_accuracy: 0.8119\n",
      "Epoch 269/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4655 - accuracy: 0.8296 - val_loss: 0.4798 - val_accuracy: 0.8326\n",
      "Epoch 270/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4309 - accuracy: 0.8407 - val_loss: 0.4734 - val_accuracy: 0.8352\n",
      "Epoch 271/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4080 - accuracy: 0.8494 - val_loss: 0.4618 - val_accuracy: 0.8358\n",
      "Epoch 272/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3947 - accuracy: 0.8534 - val_loss: 0.4568 - val_accuracy: 0.8410\n",
      "Epoch 273/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4000 - accuracy: 0.8507 - val_loss: 0.4497 - val_accuracy: 0.8402\n",
      "Epoch 274/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.3836 - accuracy: 0.8569 - val_loss: 0.4760 - val_accuracy: 0.8374\n",
      "Epoch 275/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.4101 - accuracy: 0.8466 - val_loss: 0.4616 - val_accuracy: 0.8403\n",
      "Epoch 276/1000\n",
      "81/81 [==============================] - 2s 22ms/step - loss: 0.3859 - accuracy: 0.8574 - val_loss: 0.4584 - val_accuracy: 0.8421\n",
      "Epoch 277/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.3783 - accuracy: 0.8585 - val_loss: 0.4539 - val_accuracy: 0.8385\n",
      "Epoch 278/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3764 - accuracy: 0.8589 - val_loss: 0.4564 - val_accuracy: 0.8353\n",
      "Epoch 279/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3745 - accuracy: 0.8606 - val_loss: 0.4621 - val_accuracy: 0.8407\n",
      "Epoch 280/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3717 - accuracy: 0.8609 - val_loss: 0.4585 - val_accuracy: 0.8382\n",
      "Epoch 281/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3761 - accuracy: 0.8596 - val_loss: 0.4517 - val_accuracy: 0.8406\n",
      "Epoch 282/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3725 - accuracy: 0.8608 - val_loss: 0.4602 - val_accuracy: 0.8403\n",
      "Epoch 283/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.3717 - accuracy: 0.8610 - val_loss: 0.4587 - val_accuracy: 0.8422\n",
      "Epoch 284/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3728 - accuracy: 0.8596 - val_loss: 0.4645 - val_accuracy: 0.8375\n",
      "Epoch 285/1000\n",
      "81/81 [==============================] - 1s 17ms/step - loss: 0.3694 - accuracy: 0.8618 - val_loss: 0.4722 - val_accuracy: 0.8392\n",
      "Epoch 286/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3682 - accuracy: 0.8625 - val_loss: 0.4674 - val_accuracy: 0.8416\n",
      "Epoch 287/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3678 - accuracy: 0.8614 - val_loss: 0.4754 - val_accuracy: 0.8412\n",
      "Epoch 288/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3676 - accuracy: 0.8618 - val_loss: 0.4785 - val_accuracy: 0.8416\n",
      "Epoch 289/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3671 - accuracy: 0.8624 - val_loss: 0.4853 - val_accuracy: 0.8402\n",
      "Epoch 290/1000\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 0.3811 - accuracy: 0.8584 - val_loss: 0.4670 - val_accuracy: 0.8349\n",
      "Epoch 291/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3686 - accuracy: 0.8630 - val_loss: 0.4911 - val_accuracy: 0.8357\n",
      "Epoch 292/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3680 - accuracy: 0.8630 - val_loss: 0.4799 - val_accuracy: 0.8376\n",
      "Epoch 293/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3673 - accuracy: 0.8624 - val_loss: 0.4670 - val_accuracy: 0.8424\n",
      "Epoch 294/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3722 - accuracy: 0.8612 - val_loss: 0.4759 - val_accuracy: 0.8415\n",
      "Epoch 295/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3649 - accuracy: 0.8630 - val_loss: 0.4803 - val_accuracy: 0.8399\n",
      "Epoch 296/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3625 - accuracy: 0.8650 - val_loss: 0.4697 - val_accuracy: 0.8445\n",
      "Epoch 297/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3663 - accuracy: 0.8632 - val_loss: 0.5065 - val_accuracy: 0.8365\n",
      "Epoch 298/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.3692 - accuracy: 0.8614 - val_loss: 0.4629 - val_accuracy: 0.8454\n",
      "Epoch 299/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3639 - accuracy: 0.8634 - val_loss: 0.4756 - val_accuracy: 0.8372\n",
      "Epoch 300/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3675 - accuracy: 0.8618 - val_loss: 0.4617 - val_accuracy: 0.8440\n",
      "Epoch 301/1000\n",
      "81/81 [==============================] - 2s 25ms/step - loss: 0.3645 - accuracy: 0.8632 - val_loss: 0.4864 - val_accuracy: 0.8373\n",
      "Epoch 302/1000\n",
      "81/81 [==============================] - 2s 23ms/step - loss: 0.3636 - accuracy: 0.8638 - val_loss: 0.4794 - val_accuracy: 0.8374\n",
      "Epoch 303/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3656 - accuracy: 0.8627 - val_loss: 0.4629 - val_accuracy: 0.8405\n",
      "Epoch 304/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.3619 - accuracy: 0.8644 - val_loss: 0.4819 - val_accuracy: 0.8366\n",
      "Epoch 305/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3683 - accuracy: 0.8632 - val_loss: 0.5032 - val_accuracy: 0.8359\n",
      "Epoch 306/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3641 - accuracy: 0.8629 - val_loss: 0.4684 - val_accuracy: 0.8455\n",
      "Epoch 307/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3639 - accuracy: 0.8636 - val_loss: 0.4776 - val_accuracy: 0.8408\n",
      "Epoch 308/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3655 - accuracy: 0.8626 - val_loss: 0.4718 - val_accuracy: 0.8423\n",
      "Epoch 309/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3658 - accuracy: 0.8629 - val_loss: 0.4766 - val_accuracy: 0.8418\n",
      "Epoch 310/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3600 - accuracy: 0.8661 - val_loss: 0.4779 - val_accuracy: 0.8402\n",
      "Epoch 311/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3616 - accuracy: 0.8654 - val_loss: 0.4820 - val_accuracy: 0.8395\n",
      "Epoch 312/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.5056 - accuracy: 0.8247 - val_loss: 0.4686 - val_accuracy: 0.8387\n",
      "Epoch 313/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.4178 - accuracy: 0.8465 - val_loss: 0.4597 - val_accuracy: 0.8422\n",
      "Epoch 314/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3926 - accuracy: 0.8550 - val_loss: 0.4501 - val_accuracy: 0.8389\n",
      "Epoch 315/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3818 - accuracy: 0.8590 - val_loss: 0.4486 - val_accuracy: 0.8427\n",
      "Epoch 316/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3752 - accuracy: 0.8599 - val_loss: 0.4645 - val_accuracy: 0.8390\n",
      "Epoch 317/1000\n",
      "81/81 [==============================] - 2s 20ms/step - loss: 0.3714 - accuracy: 0.8618 - val_loss: 0.4515 - val_accuracy: 0.8455\n",
      "Epoch 318/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3678 - accuracy: 0.8627 - val_loss: 0.4598 - val_accuracy: 0.8415\n",
      "Epoch 319/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3674 - accuracy: 0.8631 - val_loss: 0.4541 - val_accuracy: 0.8438\n",
      "Epoch 320/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3646 - accuracy: 0.8630 - val_loss: 0.4692 - val_accuracy: 0.8403\n",
      "Epoch 321/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3629 - accuracy: 0.8638 - val_loss: 0.4570 - val_accuracy: 0.8424\n",
      "Epoch 322/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3595 - accuracy: 0.8657 - val_loss: 0.4651 - val_accuracy: 0.8420\n",
      "Epoch 323/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3604 - accuracy: 0.8654 - val_loss: 0.4619 - val_accuracy: 0.8415\n",
      "Epoch 324/1000\n",
      "81/81 [==============================] - 2s 19ms/step - loss: 0.3613 - accuracy: 0.8645 - val_loss: 0.4621 - val_accuracy: 0.8443\n",
      "Epoch 325/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3608 - accuracy: 0.8646 - val_loss: 0.4662 - val_accuracy: 0.8381\n",
      "Epoch 326/1000\n",
      "81/81 [==============================] - 1s 18ms/step - loss: 0.3795 - accuracy: 0.8591 - val_loss: 0.4716 - val_accuracy: 0.8426\n",
      "Epoch 327/1000\n",
      " 8/81 [=>............................] - ETA: 1s - loss: 0.3689 - accuracy: 0.8577"
     ]
    }
   ],
   "source": [
    "history = model_LSTM_2.fit(x_train,y_train, epochs=1000, batch_size=16, validation_split=0.2,callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 38538,
     "status": "ok",
     "timestamp": 1670470311928,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "0Pwz2fkLiWEt",
    "outputId": "f473d501-284e-4e39-c927-809afc893b5b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 0s 22ms/step - loss: 0.4737 - accuracy: 0.8289\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.4736544191837311, 0.8288556933403015]"
      ]
     },
     "execution_count": 162,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_LSTM_2.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670470311929,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "4kEwHgcTThyk"
   },
   "outputs": [],
   "source": [
    "# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5\")\n",
    "# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5\")\n",
    "model_LSTM_2.save(\"./models/lstm_2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1549,
     "status": "ok",
     "timestamp": 1670464132234,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "_lI1n5rWk7DF",
    "outputId": "11fbc446-b78b-4739-c7b0-cdfd12b12134"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13/13 [==============================] - 1s 8ms/step - loss: 0.4526 - accuracy: 0.8438\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.45259910821914673, 0.8438432812690735]"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Testing the saved model\n",
    "# model_load = load_model('/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5')\n",
    "# model_load = load_model('/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5')\n",
    "# model_load = load_model('./models/rnn.h5')\n",
    "model_load.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
