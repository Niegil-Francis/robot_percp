{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "executionInfo": {
     "elapsed": 785,
     "status": "ok",
     "timestamp": 1670472818051,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "yu0OV4sf1nk8"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472819084,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "svhuDSYP1nk-",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import re\n",
    "import os\n",
    "import zipfile\n",
    "import collections\n",
    "import urllib.request\n",
    "from collections import defaultdict\n",
    "%matplotlib inline\n",
    "from IPython.core.display import HTML\n",
    "from collections import defaultdict\n",
    "import time\n",
    "import random\n",
    "import tqdm\n",
    "from itertools import groupby\n",
    "from scipy.spatial.distance import euclidean\n",
    "\n",
    "from fastdtw import fastdtw\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.python import keras\n",
    "from tensorflow.python.keras import backend as K\n",
    "from tensorflow.python.keras.models import Model\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.metrics import accuracy_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472822205,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "vGhXf6lC1nk_",
    "outputId": "478747bb-6f8c-481d-ebb4-82b506528c55"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensorflow version 2.11.0\n",
      "keras version 2.11.0\n",
      "Eager Execution Enabled: True\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "Number of replicas: 1\n",
      "Devices: [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "[LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n",
      "GPU Available:  [PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n",
      "All Physical Devices [PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU'), PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "# Enable/Disable Eager Execution\n",
    "# Reference: https://www.tensorflow.org/guide/eager\n",
    "# TensorFlow's eager execution is an imperative programming environment that evaluates operations immediately, \n",
    "# without building graphs\n",
    "\n",
    "#tf.compat.v1.disable_eager_execution()\n",
    "#tf.compat.v1.enable_eager_execution()\n",
    "\n",
    "print(\"tensorflow version\", tf.__version__)\n",
    "print(\"keras version\", tf.keras.__version__)\n",
    "print(\"Eager Execution Enabled:\", tf.executing_eagerly())\n",
    "\n",
    "# Get the number of replicas \n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "print(\"Number of replicas:\", strategy.num_replicas_in_sync)\n",
    "\n",
    "devices = tf.config.experimental.get_visible_devices()\n",
    "print(\"Devices:\", devices)\n",
    "print(tf.config.experimental.list_logical_devices('GPU'))\n",
    "\n",
    "print(\"GPU Available: \", tf.config.list_physical_devices('GPU'))\n",
    "print(\"All Physical Devices\", tf.config.list_physical_devices())\n",
    "\n",
    "# Better performance with the tf.data API\n",
    "# Reference: https://www.tensorflow.org/guide/data_performance\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EtMgghJO1nlA"
   },
   "source": [
    "## Reading the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "executionInfo": {
     "elapsed": 7156,
     "status": "ok",
     "timestamp": 1670461970917,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "eSg0NnAgXpRg"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# !unzip \"./all_data/sep_1/data.zip\" -d \"./temp_data/sep_1/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472827844,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "tbOPJ2jS1nlB"
   },
   "outputs": [],
   "source": [
    "# Getting the folder names \n",
    "folder_names_1 = glob.glob(\"./temp_data/sep_1/data/*\")\n",
    "folder_names_2 = glob.glob(\"./temp_data/sep_0.7/data/*\")\n",
    "# folder_names = folder_names_1 + folder_names_2\n",
    "folder_names = folder_names_1\n",
    "# folder_names = folder_names_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670472829094,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "JkZ1ScX01nlB"
   },
   "outputs": [],
   "source": [
    "# Getting the data names\n",
    "data_names = []\n",
    "for i in folder_names:\n",
    "    data_names.append(glob.glob(i+\"/*.csv\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ng5z05Q61nlC"
   },
   "source": [
    "## Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {
    "executionInfo": {
     "elapsed": 14851,
     "status": "ok",
     "timestamp": 1670472843943,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "06RUU7IU1nlD"
   },
   "outputs": [],
   "source": [
    "# Datasets to skip \n",
    "skip = []\n",
    "\n",
    "# Labels of the datasets\n",
    "labels = []\n",
    "\n",
    "# Data list \n",
    "data = []\n",
    "\n",
    "\n",
    "# Getting the labels and data for each dataset\n",
    "for i in range(len(data_names)):\n",
    "    if i in skip:\n",
    "        continue\n",
    "    \n",
    "    for j in range(len(data_names[i])):\n",
    "        labels.append([data_names[i][j][data_names[i][j].find(\".csv\")-1]])\n",
    "        \n",
    "        # Cleaning data\n",
    "        df = pd.read_csv(data_names[i][j],skiprows = 1)\n",
    "        df.drop(columns=df.columns[-1], axis=1,  inplace=True)\n",
    "        \n",
    "        data.append(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472843943,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "OhMZiWrx1nlD"
   },
   "outputs": [],
   "source": [
    "# Changing the labels from int to string\n",
    "labels = [int(i)-1 for i in np.reshape(labels,(-1,))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Targets for sep_1\n",
    "target = np.array([[-0.314,1.661,0.45],[0,1.661,0.45],[0.314,1.661,0.45],[-0.314,1.347,0.45],[0,1.347,0.45],[0.314,1.347,0.45],[-0.314,1.033,0.45],[0,1.033,0.45],[0.314,1.033,0.45]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "b3aWbcBR1nlD"
   },
   "source": [
    "## Adding Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {
    "executionInfo": {
     "elapsed": 57502,
     "status": "ok",
     "timestamp": 1670472901442,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "6sJpWHrX1nlE"
   },
   "outputs": [],
   "source": [
    "# Adding the centroid of all the fingers to the data\n",
    "\n",
    "new_data = []\n",
    "\n",
    "for idx_1 in range(len(data)):\n",
    "\n",
    "    \n",
    "    # Grouped columns for centroid\n",
    "    grouped_columns_x = data[idx_1].columns[3::3] \n",
    "    grouped_columns_y = data[idx_1].columns[4::3]\n",
    "    grouped_columns_z = data[idx_1].columns[5::3]\n",
    "    \n",
    "    # Getting the centroid of the finger points\n",
    "    cent_x = np.mean(data[idx_1][grouped_columns_x],axis = 1)\n",
    "    cent_y = np.mean(data[idx_1][grouped_columns_y],axis = 1)\n",
    "    cent_z = np.mean(data[idx_1][grouped_columns_z],axis = 1)\n",
    "    \n",
    "    new_data.append(pd.concat([data[idx_1],cent_x,cent_y,cent_z],axis = 1))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zgaA_2SY0MDc"
   },
   "source": [
    "## Data Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1670472901442,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "MUjsQWtJsKIn"
   },
   "outputs": [],
   "source": [
    "# Pulling only the centroid data \n",
    "cent_data = [i.iloc[:,-3:] for i in new_data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 297
    },
    "executionInfo": {
     "elapsed": 1245,
     "status": "ok",
     "timestamp": 1670472902684,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "cq550A880PAk",
    "outputId": "8c0ba4d0-9ee8-4885-fe2b-e9f624183928"
   },
   "outputs": [
    {
     "data": {
<<<<<<< HEAD
      "image/png": "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",
=======
      "image/png": "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\n",
>>>>>>> 4be9c98eae28bf6b1c7070b4743debe23bef1ded
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lengths = np.array([len(i) for i in cent_data])\n",
    "plt.hist(lengths)\n",
    "plt.xlabel(\"Trajectory length\")\n",
    "plt.ylabel(\"Number of trajectories\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70.61878727634195"
      ]
     },
     "execution_count": 188,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Getting the mean trajectory lengths\n",
    "np.mean(lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "ymWVIli90Uu8"
   },
   "outputs": [],
   "source": [
    "# Removing trajectories with <=5 length\n",
    "idx = np.where(lengths <= 13.)[0]\n",
    "[labels.pop(j-i) for i,j in enumerate(idx)]\n",
    "[cent_data.pop(j-i) for i,j in enumerate(idx)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "9X0N0OYxcyyJ",
    "outputId": "e7d207da-0b10-4219-ad7d-a7ab34848596"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64),)"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking to see if it worked \n",
    "lengths = np.array([len(i) for i in cent_data])\n",
    "np.where(lengths <= 13.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For target point prediction\n",
    "data_3d = []\n",
    "target_3d = []\n",
    "for i in cent_data:\n",
    "    data_3d.append(i.iloc[:-10,:])\n",
    "    temp = []\n",
    "    for j in range(len(i.iloc[:-10,:])):\n",
    "        temp.append(i.iloc[j+1:j+11,:])\n",
    "    target_3d.append(temp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Splitting the data into training and testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902685,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "hfPRW0S7UN4b"
   },
   "outputs": [],
   "source": [
    "# Train test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(cent_data, labels, test_size=0.2, random_state = 7)\n",
    "# x_train_, x_test_, y_train_, y_test_ = train_test_split(data_3d, target_3d, test_size=0.2, random_state = 7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472902687,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "kKLJbGtv1nlE"
   },
   "outputs": [],
   "source": [
    "# Getting the data in the required format for the model\n",
    "# Creating labels for RNN's output \n",
    "y_train = [[dt]*200 for idx,dt in enumerate(y_train)]\n",
    "y_test = [[dt]*200 for idx,dt in enumerate(y_test)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "evCXyI6-1nlE"
   },
   "outputs": [],
   "source": [
    "# Sequence length is based on data analysis\n",
    "# x_train = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_train_, padding='post', dtype='float', maxlen=200, value = -10.))\n",
    "x_train = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_train, padding='post', dtype='float', maxlen=200, value = 0))\n",
    "# y_train = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(y_train_, padding='post', dtype='float', maxlen=200))\n",
    "y_train = tf.convert_to_tensor(y_train)\n",
    "\n",
    "# x_test = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_test_, padding='post', dtype='float', maxlen=200, value = -10.))\n",
    "x_test = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_test, padding='post', dtype='float', maxlen=200, value = 0))\n",
    "# y_test = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(y_test_, padding='post', dtype='float', maxlen=200))\n",
    "y_test = tf.convert_to_tensor(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902688,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "ryFy62Mk1nlF"
   },
   "outputs": [],
   "source": [
    "# One hot encoding the data for training - not required for label_3d\n",
    "y_train = tf.one_hot(y_train, 9, on_value = 1.0, off_value = 0.0)\n",
    "y_test = tf.one_hot(y_test, 9, on_value = 1.0, off_value = 0.0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JJc39yrs1nlE"
   },
   "source": [
    "## Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the DTW model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_dtw(ip_data,op_data):\n",
    "    data_dict_x = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    data_dict_y = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    data_dict_z = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "\n",
    "    time = np.arange(len(ip_data))\n",
    "    for i,j in zip(ip_data,op_data):\n",
    "\n",
    "        time = np.arange(len(i))\n",
    "        \n",
    "        data_dict_x[j].append(np.polyfit(time,i[0],3))\n",
    "        data_dict_y[j].append(np.polyfit(time,i[1],3))\n",
    "        data_dict_z[j].append(np.polyfit(time,i[2],3))\n",
    "\n",
    "    # getting the mean and trend\n",
    "    trend_dict_x = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    trend_dict_y = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    trend_dict_z = {0:[],1:[],2:[],3:[],4:[],5:[],6:[],7:[],8:[]}\n",
    "    time = np.arange(70)\n",
    "    for i in range(9):\n",
    "        trend_dict_x[i] = np.poly1d(np.mean(data_dict_x[i],axis = 0))(time)\n",
    "        trend_dict_y[i] = np.poly1d(np.mean(data_dict_y[i],axis = 0))(time)\n",
    "        trend_dict_z[i] = np.poly1d(np.mean(data_dict_z[i],axis = 0))(time)\n",
    "\n",
    "  \n",
    "    dict_q = []\n",
    "    for i in range(9):\n",
    "        dict_q.append(np.array([trend_dict_x[i],trend_dict_y[i],trend_dict_z[i]]))\n",
    "    return dict_q\n",
    "\n",
    "\n",
    "def model_dtw_pred(ip_data,dic):\n",
    "\n",
    "    \n",
    "    predi = []\n",
    "#     for k in range(0,len(ip_data)):\n",
    "    d = []\n",
    "    for i in range(0,9):\n",
    "        distance, path = fastdtw(dic[i].T, ip_data, dist=euclidean)\n",
    "        d.append(distance)\n",
    "\n",
    "    predi.append(d.index(min(d)))\n",
    "    \n",
    "    return predi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_q = model_dtw(x_train,y_train)\n",
    "with open(\"./models/sep_1/data_driven\", 'wb') as handle:\n",
    "    pickle.dump(dict_q, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "# Load data (deserialize)\n",
    "with open('./models/sep_1/data_driven', 'rb') as handle:\n",
    "    dic = pickle.load(handle)\n",
    "predi = model_dtw_pred(x_test[0],dict_q)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[7]"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472902689,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "LJC8EL0egiGL"
   },
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h = LSTM(ip_reformed)\n",
    "\n",
    "dense = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense(h)\n",
    "\n",
    "model_LSTM = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_LSTM.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM model - labels_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "masking = tf.keras.layers.Masking(mask_value=-10.)\n",
    "masked_op = masking(seq_input)\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(masked_op)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h = LSTM(ip_reformed)\n",
    "\n",
    "dense = tf.keras.layers.Dense(30, activation='linear')\n",
    "dense_out = dense(h)\n",
    "\n",
    "reshaping = tf.keras.layers.Reshape((200,10, 3))\n",
    "output = reshaping(dense_out)\n",
    "\n",
    "model_LSTM_3d = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_LSTM_3d.compile(loss='mse', metrics = ['mae'],optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM+RNN model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1670472905553,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "qsyhNfUNdb9D"
   },
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(seq_input)\n",
    "\n",
    "RNN = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN(ip_reformed)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h_2 = LSTM(h_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(9, activation='softmax')\n",
    "output = dense(h_2)\n",
    "\n",
    "model_RNN_LSTM = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN_LSTM.compile(loss='categorical_crossentropy', metrics = ['accuracy'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the LSTM+RNN model - labels_3d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "hidden_size= 15\n",
    "tf.keras.backend.clear_session()\n",
    "seq_input = tf.keras.Input(shape=x_train.shape[1:], name='input_layer')\n",
    "\n",
    "masking = tf.keras.layers.Masking(mask_value=-10.)\n",
    "masked_op = masking(seq_input)\n",
    "\n",
    "ip_reform = tf.keras.layers.Dense(hidden_size)\n",
    "\n",
    "ip_reformed = ip_reform(masked_op)\n",
    "\n",
    "RNN = tf.keras.layers.SimpleRNN(hidden_size, return_sequences=True)\n",
    "h_1 = RNN(ip_reformed)\n",
    "\n",
    "LSTM = tf.keras.layers.LSTM(hidden_size, return_sequences=True)\n",
    "h_2 = LSTM(h_1)\n",
    "\n",
    "dense = tf.keras.layers.Dense(30, activation='linear')\n",
    "dense_out = dense(h_2)\n",
    "\n",
    "reshaping = tf.keras.layers.Reshape((200,10, 3))\n",
    "output = reshaping(dense_out)\n",
    "\n",
    "model_RNN_LSTM_3d = tf.keras.models.Model(inputs=seq_input, outputs=output)\n",
    "\n",
    "model_RNN_LSTM_3d.compile(loss='mse', metrics = ['mae'], optimizer=Adam(1e-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1670472905553,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "29kaMRnt1nlF",
    "outputId": "96eed065-c571-49cd-fffa-6e4ef9d4d358"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 200, 3)]          0         \n",
      "                                                                 \n",
      " masking (Masking)           (None, 200, 3)            0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200, 15)           60        \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 200, 15)           465       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 15)           1860      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200, 30)           480       \n",
      "                                                                 \n",
      " reshape (Reshape)           (None, 200, 10, 3)        0         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,865\n",
      "Trainable params: 2,865\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_RNN_LSTM_3d.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "executionInfo": {
     "elapsed": 1593,
     "status": "ok",
     "timestamp": 1670472927009,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "7B3g6dUGOOoU"
   },
   "outputs": [],
   "source": [
    "# callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "#     monitor='val_accuracy',\n",
    "#     patience=100,\n",
    "#     restore_best_weights = True\n",
    "# )\n",
    "\n",
    "callbacks = tf.keras.callbacks.EarlyStopping(\n",
    "    monitor='val_mae',\n",
    "    patience=100,\n",
    "    restore_best_weights = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RdnYYPv_1nlF",
    "outputId": "a1bb33a5-8b8c-446d-9016-a14cbc846054",
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-12-13 16:35:11.906640: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:428] Loaded cuDNN version 8101\n",
      "2022-12-13 16:35:14.020076: I tensorflow/compiler/xla/service/service.cc:173] XLA service 0x14a091c54b40 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2022-12-13 16:35:14.020095: I tensorflow/compiler/xla/service/service.cc:181]   StreamExecutor device (0): Tesla V100-PCIE-32GB, Compute Capability 7.0\n",
      "2022-12-13 16:35:14.103729: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:268] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2022-12-13 16:35:14.610576: I tensorflow/compiler/jit/xla_compilation_cache.cc:477] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 34s 149ms/step - loss: 0.0109 - mae: 0.0405 - val_loss: 0.0021 - val_mae: 0.0182\n",
      "Epoch 2/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 0.0014 - mae: 0.0148 - val_loss: 9.0127e-04 - val_mae: 0.0121\n",
      "Epoch 3/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.3876e-04 - mae: 0.0100 - val_loss: 7.9560e-04 - val_mae: 0.0119\n",
      "Epoch 4/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.3815e-04 - mae: 0.0091 - val_loss: 5.1718e-04 - val_mae: 0.0089\n",
      "Epoch 5/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 3.3984e-04 - mae: 0.0071 - val_loss: 2.5057e-04 - val_mae: 0.0058\n",
      "Epoch 6/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 2.4240e-04 - mae: 0.0058 - val_loss: 3.7125e-04 - val_mae: 0.0076\n",
      "Epoch 7/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 2.4036e-04 - mae: 0.0057 - val_loss: 2.9518e-04 - val_mae: 0.0066\n",
      "Epoch 8/1000\n",
      "116/116 [==============================] - 16s 138ms/step - loss: 2.2973e-04 - mae: 0.0056 - val_loss: 2.1140e-04 - val_mae: 0.0050\n",
      "Epoch 9/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 2.1275e-04 - mae: 0.0054 - val_loss: 2.5746e-04 - val_mae: 0.0058\n",
      "Epoch 10/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 2.2137e-04 - mae: 0.0055 - val_loss: 2.6234e-04 - val_mae: 0.0061\n",
      "Epoch 11/1000\n",
      "116/116 [==============================] - 15s 132ms/step - loss: 2.2524e-04 - mae: 0.0057 - val_loss: 2.2886e-04 - val_mae: 0.0054\n",
      "Epoch 12/1000\n",
      "116/116 [==============================] - 16s 135ms/step - loss: 2.1259e-04 - mae: 0.0054 - val_loss: 2.3523e-04 - val_mae: 0.0056\n",
      "Epoch 13/1000\n",
      "116/116 [==============================] - 16s 137ms/step - loss: 2.1863e-04 - mae: 0.0056 - val_loss: 2.3231e-04 - val_mae: 0.0058\n",
      "Epoch 14/1000\n",
      "116/116 [==============================] - 16s 138ms/step - loss: 2.0749e-04 - mae: 0.0055 - val_loss: 2.3547e-04 - val_mae: 0.0058\n",
      "Epoch 15/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 1.9315e-04 - mae: 0.0052 - val_loss: 2.3251e-04 - val_mae: 0.0059\n",
      "Epoch 16/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 2.2158e-04 - mae: 0.0058 - val_loss: 3.2447e-04 - val_mae: 0.0082\n",
      "Epoch 17/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 2.0510e-04 - mae: 0.0054 - val_loss: 1.9539e-04 - val_mae: 0.0050\n",
      "Epoch 18/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.8087e-04 - mae: 0.0050 - val_loss: 1.8611e-04 - val_mae: 0.0050\n",
      "Epoch 19/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 2.0454e-04 - mae: 0.0055 - val_loss: 2.4169e-04 - val_mae: 0.0065\n",
      "Epoch 20/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 2.3520e-04 - mae: 0.0061 - val_loss: 2.1508e-04 - val_mae: 0.0055\n",
      "Epoch 21/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.9685e-04 - mae: 0.0055 - val_loss: 1.8574e-04 - val_mae: 0.0049\n",
      "Epoch 22/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 1.8268e-04 - mae: 0.0052 - val_loss: 1.9306e-04 - val_mae: 0.0053\n",
      "Epoch 23/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.7663e-04 - mae: 0.0050 - val_loss: 1.7536e-04 - val_mae: 0.0047\n",
      "Epoch 24/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 1.6423e-04 - mae: 0.0048 - val_loss: 1.7106e-04 - val_mae: 0.0048\n",
      "Epoch 25/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.6532e-04 - mae: 0.0048 - val_loss: 1.6487e-04 - val_mae: 0.0045\n",
      "Epoch 26/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.6102e-04 - mae: 0.0048 - val_loss: 1.7933e-04 - val_mae: 0.0051\n",
      "Epoch 27/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.8027e-04 - mae: 0.0052 - val_loss: 1.6522e-04 - val_mae: 0.0045\n",
      "Epoch 28/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.5161e-04 - mae: 0.0046 - val_loss: 1.6904e-04 - val_mae: 0.0047\n",
      "Epoch 29/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.6381e-04 - mae: 0.0050 - val_loss: 1.8683e-04 - val_mae: 0.0055\n",
      "Epoch 30/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.6783e-04 - mae: 0.0051 - val_loss: 1.8895e-04 - val_mae: 0.0051\n",
      "Epoch 31/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.6812e-04 - mae: 0.0051 - val_loss: 1.7076e-04 - val_mae: 0.0053\n",
      "Epoch 32/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 1.5477e-04 - mae: 0.0049 - val_loss: 1.7758e-04 - val_mae: 0.0057\n",
      "Epoch 33/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.5530e-04 - mae: 0.0051 - val_loss: 2.5091e-04 - val_mae: 0.0071\n",
      "Epoch 34/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 1.5556e-04 - mae: 0.0050 - val_loss: 2.0296e-04 - val_mae: 0.0066\n",
      "Epoch 35/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 1.3013e-04 - mae: 0.0044 - val_loss: 1.6148e-04 - val_mae: 0.0045\n",
      "Epoch 36/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 1.4532e-04 - mae: 0.0048 - val_loss: 1.2773e-04 - val_mae: 0.0040\n",
      "Epoch 37/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.3465e-04 - mae: 0.0046 - val_loss: 1.8769e-04 - val_mae: 0.0056\n",
      "Epoch 38/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.2977e-04 - mae: 0.0045 - val_loss: 1.6856e-04 - val_mae: 0.0054\n",
      "Epoch 39/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.2616e-04 - mae: 0.0043 - val_loss: 1.2191e-04 - val_mae: 0.0038\n",
      "Epoch 40/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 1.3013e-04 - mae: 0.0044 - val_loss: 2.1867e-04 - val_mae: 0.0070\n",
      "Epoch 41/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.3100e-04 - mae: 0.0045 - val_loss: 1.2874e-04 - val_mae: 0.0044\n",
      "Epoch 42/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.2824e-04 - mae: 0.0045 - val_loss: 1.2069e-04 - val_mae: 0.0041\n",
      "Epoch 43/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.1294e-04 - mae: 0.0041 - val_loss: 1.3843e-04 - val_mae: 0.0047\n",
      "Epoch 44/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 1.1907e-04 - mae: 0.0042 - val_loss: 2.0052e-04 - val_mae: 0.0055\n",
      "Epoch 45/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 1.2231e-04 - mae: 0.0044 - val_loss: 1.4533e-04 - val_mae: 0.0050\n",
      "Epoch 46/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 1.0901e-04 - mae: 0.0041 - val_loss: 1.1566e-04 - val_mae: 0.0040\n",
      "Epoch 47/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 1.0791e-04 - mae: 0.0040 - val_loss: 1.1435e-04 - val_mae: 0.0038\n",
      "Epoch 48/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.0649e-04 - mae: 0.0040 - val_loss: 1.4358e-04 - val_mae: 0.0046\n",
      "Epoch 49/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 1.1126e-04 - mae: 0.0041 - val_loss: 1.0613e-04 - val_mae: 0.0037\n",
      "Epoch 50/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 9.1794e-05 - mae: 0.0037 - val_loss: 1.1627e-04 - val_mae: 0.0043\n",
      "Epoch 51/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.0369e-05 - mae: 0.0036 - val_loss: 1.2046e-04 - val_mae: 0.0043\n",
      "Epoch 52/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.4732e-05 - mae: 0.0038 - val_loss: 1.0782e-04 - val_mae: 0.0041\n",
      "Epoch 53/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 9.1811e-05 - mae: 0.0038 - val_loss: 1.0530e-04 - val_mae: 0.0038\n",
      "Epoch 54/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.0454e-05 - mae: 0.0037 - val_loss: 1.1607e-04 - val_mae: 0.0043\n",
      "Epoch 55/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 9.4180e-05 - mae: 0.0037 - val_loss: 1.0110e-04 - val_mae: 0.0038\n",
      "Epoch 56/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 8.0517e-05 - mae: 0.0034 - val_loss: 9.8325e-05 - val_mae: 0.0035\n",
      "Epoch 57/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 8.6761e-05 - mae: 0.0036 - val_loss: 8.9184e-05 - val_mae: 0.0036\n",
      "Epoch 58/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 7.7914e-05 - mae: 0.0033 - val_loss: 8.6915e-05 - val_mae: 0.0036\n",
      "Epoch 59/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 8.9431e-05 - mae: 0.0038 - val_loss: 9.0322e-05 - val_mae: 0.0037\n",
      "Epoch 60/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.0297e-05 - mae: 0.0037 - val_loss: 8.9438e-05 - val_mae: 0.0036\n",
      "Epoch 61/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 9.3034e-05 - mae: 0.0038 - val_loss: 1.1009e-04 - val_mae: 0.0043\n",
      "Epoch 62/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 7.2515e-05 - mae: 0.0032 - val_loss: 8.0797e-05 - val_mae: 0.0031\n",
      "Epoch 63/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 7.5458e-05 - mae: 0.0033 - val_loss: 8.6755e-05 - val_mae: 0.0034\n",
      "Epoch 64/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 7.5651e-05 - mae: 0.0033 - val_loss: 7.8274e-05 - val_mae: 0.0032\n",
      "Epoch 65/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 7.1675e-05 - mae: 0.0032 - val_loss: 8.5493e-05 - val_mae: 0.0034\n",
      "Epoch 66/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 7.5099e-05 - mae: 0.0033 - val_loss: 1.0427e-04 - val_mae: 0.0044\n",
      "Epoch 67/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 8.4721e-05 - mae: 0.0038 - val_loss: 7.5888e-05 - val_mae: 0.0032\n",
      "Epoch 68/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.7472e-05 - mae: 0.0030 - val_loss: 8.4022e-05 - val_mae: 0.0035\n",
      "Epoch 69/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.4877e-05 - mae: 0.0030 - val_loss: 8.3727e-05 - val_mae: 0.0033\n",
      "Epoch 70/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 7.4439e-05 - mae: 0.0034 - val_loss: 8.0386e-05 - val_mae: 0.0034\n",
      "Epoch 71/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 7.3756e-05 - mae: 0.0033 - val_loss: 9.2154e-05 - val_mae: 0.0040\n",
      "Epoch 72/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 7.1240e-05 - mae: 0.0033 - val_loss: 8.2839e-05 - val_mae: 0.0035\n",
      "Epoch 73/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 7.2526e-05 - mae: 0.0033 - val_loss: 7.8068e-05 - val_mae: 0.0034\n",
      "Epoch 74/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 7.6906e-05 - mae: 0.0035 - val_loss: 8.6142e-05 - val_mae: 0.0034\n",
      "Epoch 75/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 6.6470e-05 - mae: 0.0031 - val_loss: 8.4138e-05 - val_mae: 0.0035\n",
      "Epoch 76/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.3981e-05 - mae: 0.0030 - val_loss: 7.4597e-05 - val_mae: 0.0033\n",
      "Epoch 77/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.5187e-05 - mae: 0.0031 - val_loss: 6.9407e-05 - val_mae: 0.0031\n",
      "Epoch 78/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 6.6682e-05 - mae: 0.0031 - val_loss: 7.7087e-05 - val_mae: 0.0031\n",
      "Epoch 79/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.5263e-05 - mae: 0.0031 - val_loss: 8.2621e-05 - val_mae: 0.0037\n",
      "Epoch 80/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.9184e-05 - mae: 0.0028 - val_loss: 7.8754e-05 - val_mae: 0.0035\n",
      "Epoch 81/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.1700e-05 - mae: 0.0030 - val_loss: 8.1309e-05 - val_mae: 0.0036\n",
      "Epoch 82/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 6.7724e-05 - mae: 0.0032 - val_loss: 8.0564e-05 - val_mae: 0.0034\n",
      "Epoch 83/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.2991e-05 - mae: 0.0030 - val_loss: 7.9642e-05 - val_mae: 0.0040\n",
      "Epoch 84/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 6.0646e-05 - mae: 0.0030 - val_loss: 9.9392e-05 - val_mae: 0.0041\n",
      "Epoch 85/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.0760e-05 - mae: 0.0029 - val_loss: 7.1592e-05 - val_mae: 0.0030\n",
      "Epoch 86/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.5965e-05 - mae: 0.0032 - val_loss: 7.4124e-05 - val_mae: 0.0029\n",
      "Epoch 87/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.1680e-05 - mae: 0.0030 - val_loss: 7.4816e-05 - val_mae: 0.0033\n",
      "Epoch 88/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.0405e-05 - mae: 0.0030 - val_loss: 7.3106e-05 - val_mae: 0.0030\n",
      "Epoch 89/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 5.9257e-05 - mae: 0.0029 - val_loss: 6.2100e-05 - val_mae: 0.0026\n",
      "Epoch 90/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 6.0077e-05 - mae: 0.0030 - val_loss: 6.7376e-05 - val_mae: 0.0028\n",
      "Epoch 91/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.0411e-05 - mae: 0.0030 - val_loss: 6.6792e-05 - val_mae: 0.0030\n",
      "Epoch 92/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.8697e-05 - mae: 0.0029 - val_loss: 7.1107e-05 - val_mae: 0.0031\n",
      "Epoch 93/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.1454e-05 - mae: 0.0031 - val_loss: 7.0483e-05 - val_mae: 0.0033\n",
      "Epoch 94/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.8629e-05 - mae: 0.0029 - val_loss: 6.7643e-05 - val_mae: 0.0031\n",
      "Epoch 95/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 6.0778e-05 - mae: 0.0030 - val_loss: 8.2647e-05 - val_mae: 0.0036\n",
      "Epoch 96/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.8483e-05 - mae: 0.0030 - val_loss: 6.8450e-05 - val_mae: 0.0029\n",
      "Epoch 97/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.8544e-05 - mae: 0.0030 - val_loss: 6.3602e-05 - val_mae: 0.0028\n",
      "Epoch 98/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.0529e-05 - mae: 0.0029 - val_loss: 6.2841e-05 - val_mae: 0.0027\n",
      "Epoch 99/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 6.0189e-05 - mae: 0.0031 - val_loss: 7.5825e-05 - val_mae: 0.0033\n",
      "Epoch 100/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.5962e-05 - mae: 0.0029 - val_loss: 7.5002e-05 - val_mae: 0.0032\n",
      "Epoch 101/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.9426e-05 - mae: 0.0030 - val_loss: 9.5606e-05 - val_mae: 0.0038\n",
      "Epoch 102/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.1980e-05 - mae: 0.0026 - val_loss: 6.1063e-05 - val_mae: 0.0026\n",
      "Epoch 103/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 6.0263e-05 - mae: 0.0030 - val_loss: 6.4070e-05 - val_mae: 0.0028\n",
      "Epoch 104/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.7479e-05 - mae: 0.0029 - val_loss: 8.4327e-05 - val_mae: 0.0036\n",
      "Epoch 105/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.6060e-05 - mae: 0.0029 - val_loss: 6.5855e-05 - val_mae: 0.0031\n",
      "Epoch 106/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 5.1738e-05 - mae: 0.0027 - val_loss: 5.8581e-05 - val_mae: 0.0027\n",
      "Epoch 107/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.4935e-05 - mae: 0.0029 - val_loss: 7.1839e-05 - val_mae: 0.0033\n",
      "Epoch 108/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.9250e-05 - mae: 0.0030 - val_loss: 5.9636e-05 - val_mae: 0.0026\n",
      "Epoch 109/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.9998e-05 - mae: 0.0026 - val_loss: 6.9199e-05 - val_mae: 0.0031\n",
      "Epoch 110/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.3236e-05 - mae: 0.0028 - val_loss: 5.9437e-05 - val_mae: 0.0025\n",
      "Epoch 111/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.7911e-05 - mae: 0.0030 - val_loss: 7.8435e-05 - val_mae: 0.0034\n",
      "Epoch 112/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.9607e-05 - mae: 0.0026 - val_loss: 6.6859e-05 - val_mae: 0.0034\n",
      "Epoch 113/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116/116 [==============================] - 16s 142ms/step - loss: 5.7049e-05 - mae: 0.0030 - val_loss: 7.0060e-05 - val_mae: 0.0032\n",
      "Epoch 114/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 5.1417e-05 - mae: 0.0027 - val_loss: 7.0800e-05 - val_mae: 0.0033\n",
      "Epoch 115/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 6.0992e-05 - mae: 0.0030 - val_loss: 1.4356e-04 - val_mae: 0.0051\n",
      "Epoch 116/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.4520e-05 - mae: 0.0032 - val_loss: 6.5206e-05 - val_mae: 0.0031\n",
      "Epoch 117/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.9702e-05 - mae: 0.0026 - val_loss: 6.1064e-05 - val_mae: 0.0027\n",
      "Epoch 118/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.2330e-05 - mae: 0.0028 - val_loss: 6.4438e-05 - val_mae: 0.0031\n",
      "Epoch 119/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.1707e-05 - mae: 0.0027 - val_loss: 5.6812e-05 - val_mae: 0.0028\n",
      "Epoch 120/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.9381e-05 - mae: 0.0031 - val_loss: 8.6419e-05 - val_mae: 0.0039\n",
      "Epoch 121/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.3433e-05 - mae: 0.0028 - val_loss: 7.2319e-05 - val_mae: 0.0034\n",
      "Epoch 122/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.3199e-05 - mae: 0.0028 - val_loss: 7.3382e-05 - val_mae: 0.0034\n",
      "Epoch 123/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.2251e-05 - mae: 0.0027 - val_loss: 6.1858e-05 - val_mae: 0.0027\n",
      "Epoch 124/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.1323e-05 - mae: 0.0027 - val_loss: 1.2841e-04 - val_mae: 0.0051\n",
      "Epoch 125/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 7.4479e-05 - mae: 0.0036 - val_loss: 7.7339e-05 - val_mae: 0.0035\n",
      "Epoch 126/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.0419e-05 - mae: 0.0026 - val_loss: 6.9191e-05 - val_mae: 0.0034\n",
      "Epoch 127/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.7373e-05 - mae: 0.0025 - val_loss: 5.8092e-05 - val_mae: 0.0026\n",
      "Epoch 128/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.7065e-05 - mae: 0.0025 - val_loss: 5.5284e-05 - val_mae: 0.0025\n",
      "Epoch 129/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.9722e-05 - mae: 0.0027 - val_loss: 5.8031e-05 - val_mae: 0.0025\n",
      "Epoch 130/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.9445e-05 - mae: 0.0026 - val_loss: 5.4547e-05 - val_mae: 0.0024\n",
      "Epoch 131/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.6717e-05 - mae: 0.0025 - val_loss: 5.9883e-05 - val_mae: 0.0027\n",
      "Epoch 132/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.8257e-05 - mae: 0.0026 - val_loss: 6.5699e-05 - val_mae: 0.0031\n",
      "Epoch 133/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.8600e-05 - mae: 0.0026 - val_loss: 7.0707e-05 - val_mae: 0.0032\n",
      "Epoch 134/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.0303e-05 - mae: 0.0027 - val_loss: 6.5965e-05 - val_mae: 0.0033\n",
      "Epoch 135/1000\n",
      "116/116 [==============================] - 16s 138ms/step - loss: 5.5459e-05 - mae: 0.0029 - val_loss: 7.2868e-05 - val_mae: 0.0035\n",
      "Epoch 136/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.3368e-05 - mae: 0.0029 - val_loss: 6.7793e-05 - val_mae: 0.0034\n",
      "Epoch 137/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.0207e-05 - mae: 0.0027 - val_loss: 7.0868e-05 - val_mae: 0.0033\n",
      "Epoch 138/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.4600e-05 - mae: 0.0029 - val_loss: 5.9740e-05 - val_mae: 0.0028\n",
      "Epoch 139/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.1002e-05 - mae: 0.0028 - val_loss: 7.5197e-05 - val_mae: 0.0035\n",
      "Epoch 140/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.9308e-05 - mae: 0.0027 - val_loss: 5.8505e-05 - val_mae: 0.0028\n",
      "Epoch 141/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.7863e-05 - mae: 0.0026 - val_loss: 5.9674e-05 - val_mae: 0.0026\n",
      "Epoch 142/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.7541e-05 - mae: 0.0026 - val_loss: 5.6215e-05 - val_mae: 0.0024\n",
      "Epoch 143/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.0217e-05 - mae: 0.0027 - val_loss: 5.9753e-05 - val_mae: 0.0029\n",
      "Epoch 144/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 3.8101e-04 - mae: 0.0072 - val_loss: 3.0268e-04 - val_mae: 0.0078\n",
      "Epoch 145/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 1.9157e-04 - mae: 0.0058 - val_loss: 1.8662e-04 - val_mae: 0.0051\n",
      "Epoch 146/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 1.4656e-04 - mae: 0.0049 - val_loss: 1.5354e-04 - val_mae: 0.0047\n",
      "Epoch 147/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 1.1785e-04 - mae: 0.0044 - val_loss: 1.1718e-04 - val_mae: 0.0042\n",
      "Epoch 148/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 8.9971e-05 - mae: 0.0037 - val_loss: 1.0322e-04 - val_mae: 0.0042\n",
      "Epoch 149/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 8.0611e-05 - mae: 0.0035 - val_loss: 1.0813e-04 - val_mae: 0.0041\n",
      "Epoch 150/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 8.0304e-05 - mae: 0.0036 - val_loss: 9.2830e-05 - val_mae: 0.0038\n",
      "Epoch 151/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 7.2473e-05 - mae: 0.0033 - val_loss: 8.3242e-05 - val_mae: 0.0031\n",
      "Epoch 152/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.6995e-05 - mae: 0.0030 - val_loss: 7.6303e-05 - val_mae: 0.0031\n",
      "Epoch 153/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 6.7343e-05 - mae: 0.0031 - val_loss: 7.6836e-05 - val_mae: 0.0030\n",
      "Epoch 154/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 6.5958e-05 - mae: 0.0030 - val_loss: 8.6145e-05 - val_mae: 0.0037\n",
      "Epoch 155/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.5210e-05 - mae: 0.0030 - val_loss: 7.4963e-05 - val_mae: 0.0031\n",
      "Epoch 156/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 6.4464e-05 - mae: 0.0030 - val_loss: 7.5039e-05 - val_mae: 0.0033\n",
      "Epoch 157/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.5965e-05 - mae: 0.0031 - val_loss: 7.0846e-05 - val_mae: 0.0029\n",
      "Epoch 158/1000\n",
      "116/116 [==============================] - 16s 139ms/step - loss: 6.4126e-05 - mae: 0.0031 - val_loss: 9.5813e-05 - val_mae: 0.0038\n",
      "Epoch 159/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.6930e-05 - mae: 0.0032 - val_loss: 8.6672e-05 - val_mae: 0.0038\n",
      "Epoch 160/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 6.3028e-05 - mae: 0.0030 - val_loss: 7.7258e-05 - val_mae: 0.0032\n",
      "Epoch 161/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 6.2369e-05 - mae: 0.0031 - val_loss: 1.1914e-04 - val_mae: 0.0051\n",
      "Epoch 162/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 6.6798e-05 - mae: 0.0033 - val_loss: 7.3566e-05 - val_mae: 0.0031\n",
      "Epoch 163/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.8966e-05 - mae: 0.0029 - val_loss: 8.0460e-05 - val_mae: 0.0036\n",
      "Epoch 164/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 6.0611e-05 - mae: 0.0030 - val_loss: 6.8069e-05 - val_mae: 0.0029\n",
      "Epoch 165/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.7751e-05 - mae: 0.0028 - val_loss: 6.7860e-05 - val_mae: 0.0028\n",
      "Epoch 166/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.4485e-05 - mae: 0.0033 - val_loss: 7.0992e-05 - val_mae: 0.0034\n",
      "Epoch 167/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.5252e-05 - mae: 0.0032 - val_loss: 1.0251e-04 - val_mae: 0.0051\n",
      "Epoch 168/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 6.4975e-05 - mae: 0.0032 - val_loss: 6.9394e-05 - val_mae: 0.0029\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 169/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.8084e-05 - mae: 0.0030 - val_loss: 6.5414e-05 - val_mae: 0.0029\n",
      "Epoch 170/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.3914e-05 - mae: 0.0027 - val_loss: 7.1059e-05 - val_mae: 0.0030\n",
      "Epoch 171/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 6.0457e-05 - mae: 0.0031 - val_loss: 6.1493e-05 - val_mae: 0.0026\n",
      "Epoch 172/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.7303e-05 - mae: 0.0029 - val_loss: 6.6400e-05 - val_mae: 0.0030\n",
      "Epoch 173/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.6105e-05 - mae: 0.0029 - val_loss: 8.6536e-05 - val_mae: 0.0038\n",
      "Epoch 174/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 6.1712e-05 - mae: 0.0032 - val_loss: 6.6812e-05 - val_mae: 0.0030\n",
      "Epoch 175/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.6297e-05 - mae: 0.0030 - val_loss: 7.0278e-05 - val_mae: 0.0030\n",
      "Epoch 176/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.3183e-05 - mae: 0.0027 - val_loss: 6.1144e-05 - val_mae: 0.0025\n",
      "Epoch 177/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.5632e-05 - mae: 0.0028 - val_loss: 6.3003e-05 - val_mae: 0.0027\n",
      "Epoch 178/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.8739e-05 - mae: 0.0031 - val_loss: 6.9809e-05 - val_mae: 0.0033\n",
      "Epoch 179/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 5.4533e-05 - mae: 0.0029 - val_loss: 6.1467e-05 - val_mae: 0.0028\n",
      "Epoch 180/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.3731e-05 - mae: 0.0029 - val_loss: 6.1724e-05 - val_mae: 0.0029\n",
      "Epoch 181/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.0569e-05 - mae: 0.0027 - val_loss: 6.1623e-05 - val_mae: 0.0031\n",
      "Epoch 182/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.5517e-05 - mae: 0.0029 - val_loss: 6.2585e-05 - val_mae: 0.0029\n",
      "Epoch 183/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.6398e-05 - mae: 0.0030 - val_loss: 5.6990e-05 - val_mae: 0.0025\n",
      "Epoch 184/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.8951e-05 - mae: 0.0026 - val_loss: 6.0412e-05 - val_mae: 0.0028\n",
      "Epoch 185/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.0377e-05 - mae: 0.0027 - val_loss: 7.9214e-05 - val_mae: 0.0039\n",
      "Epoch 186/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.4526e-05 - mae: 0.0029 - val_loss: 6.9457e-05 - val_mae: 0.0035\n",
      "Epoch 187/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 5.1262e-05 - mae: 0.0027 - val_loss: 6.0020e-05 - val_mae: 0.0028\n",
      "Epoch 188/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.4338e-05 - mae: 0.0030 - val_loss: 5.8997e-05 - val_mae: 0.0026\n",
      "Epoch 189/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 7.3239e-05 - mae: 0.0036 - val_loss: 1.0778e-04 - val_mae: 0.0050\n",
      "Epoch 190/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.7582e-05 - mae: 0.0030 - val_loss: 6.0681e-05 - val_mae: 0.0029\n",
      "Epoch 191/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.0917e-05 - mae: 0.0028 - val_loss: 5.7424e-05 - val_mae: 0.0025\n",
      "Epoch 192/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.9189e-05 - mae: 0.0026 - val_loss: 6.4233e-05 - val_mae: 0.0030\n",
      "Epoch 193/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.1719e-05 - mae: 0.0028 - val_loss: 1.1264e-04 - val_mae: 0.0047\n",
      "Epoch 194/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 5.6303e-05 - mae: 0.0030 - val_loss: 5.8591e-05 - val_mae: 0.0026\n",
      "Epoch 195/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.5255e-05 - mae: 0.0029 - val_loss: 5.9445e-05 - val_mae: 0.0025\n",
      "Epoch 196/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.8549e-05 - mae: 0.0026 - val_loss: 5.7503e-05 - val_mae: 0.0025\n",
      "Epoch 197/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.2658e-05 - mae: 0.0029 - val_loss: 6.8137e-05 - val_mae: 0.0033\n",
      "Epoch 198/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.8169e-05 - mae: 0.0026 - val_loss: 6.0710e-05 - val_mae: 0.0031\n",
      "Epoch 199/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.2920e-05 - mae: 0.0029 - val_loss: 9.9699e-05 - val_mae: 0.0047\n",
      "Epoch 200/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.4043e-05 - mae: 0.0030 - val_loss: 6.8122e-05 - val_mae: 0.0033\n",
      "Epoch 201/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.2696e-05 - mae: 0.0029 - val_loss: 6.1443e-05 - val_mae: 0.0031\n",
      "Epoch 202/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.9603e-05 - mae: 0.0031 - val_loss: 6.1093e-05 - val_mae: 0.0027\n",
      "Epoch 203/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.9667e-05 - mae: 0.0027 - val_loss: 6.0888e-05 - val_mae: 0.0030\n",
      "Epoch 204/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.7346e-05 - mae: 0.0030 - val_loss: 6.4559e-05 - val_mae: 0.0033\n",
      "Epoch 205/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.2308e-05 - mae: 0.0029 - val_loss: 6.9429e-05 - val_mae: 0.0034\n",
      "Epoch 206/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.2128e-05 - mae: 0.0028 - val_loss: 5.7767e-05 - val_mae: 0.0028\n",
      "Epoch 207/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.1578e-05 - mae: 0.0028 - val_loss: 6.8328e-05 - val_mae: 0.0034\n",
      "Epoch 208/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.1967e-05 - mae: 0.0028 - val_loss: 5.6604e-05 - val_mae: 0.0027\n",
      "Epoch 209/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.9992e-05 - mae: 0.0028 - val_loss: 5.9032e-05 - val_mae: 0.0027\n",
      "Epoch 210/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 5.0858e-05 - mae: 0.0028 - val_loss: 5.6729e-05 - val_mae: 0.0028\n",
      "Epoch 211/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.6976e-05 - mae: 0.0026 - val_loss: 7.7636e-05 - val_mae: 0.0037\n",
      "Epoch 212/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.3971e-05 - mae: 0.0029 - val_loss: 5.7308e-05 - val_mae: 0.0029\n",
      "Epoch 213/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.7984e-05 - mae: 0.0026 - val_loss: 7.3754e-05 - val_mae: 0.0033\n",
      "Epoch 214/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.8885e-05 - mae: 0.0026 - val_loss: 5.9536e-05 - val_mae: 0.0028\n",
      "Epoch 215/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.4145e-05 - mae: 0.0029 - val_loss: 6.7055e-05 - val_mae: 0.0032\n",
      "Epoch 216/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 5.0940e-05 - mae: 0.0028 - val_loss: 6.7092e-05 - val_mae: 0.0032\n",
      "Epoch 217/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.0807e-05 - mae: 0.0028 - val_loss: 6.4997e-05 - val_mae: 0.0035\n",
      "Epoch 218/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.9276e-05 - mae: 0.0027 - val_loss: 5.6482e-05 - val_mae: 0.0026\n",
      "Epoch 219/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.5732e-05 - mae: 0.0025 - val_loss: 6.0058e-05 - val_mae: 0.0028\n",
      "Epoch 220/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.7756e-05 - mae: 0.0026 - val_loss: 5.8106e-05 - val_mae: 0.0027\n",
      "Epoch 221/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.3454e-05 - mae: 0.0029 - val_loss: 6.2834e-05 - val_mae: 0.0031\n",
      "Epoch 222/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.1811e-05 - mae: 0.0029 - val_loss: 5.8181e-05 - val_mae: 0.0028\n",
      "Epoch 223/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.7350e-05 - mae: 0.0029 - val_loss: 5.1174e-05 - val_mae: 0.0022\n",
      "Epoch 224/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.2385e-05 - mae: 0.0028 - val_loss: 5.1400e-05 - val_mae: 0.0023\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 225/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.0023e-05 - mae: 0.0027 - val_loss: 5.3405e-05 - val_mae: 0.0022\n",
      "Epoch 226/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.6332e-05 - mae: 0.0025 - val_loss: 6.4839e-05 - val_mae: 0.0030\n",
      "Epoch 227/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.8126e-05 - mae: 0.0030 - val_loss: 5.7315e-05 - val_mae: 0.0027\n",
      "Epoch 228/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.7968e-05 - mae: 0.0026 - val_loss: 6.4354e-05 - val_mae: 0.0031\n",
      "Epoch 229/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.8291e-05 - mae: 0.0027 - val_loss: 5.5527e-05 - val_mae: 0.0027\n",
      "Epoch 230/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.6498e-05 - mae: 0.0026 - val_loss: 5.5868e-05 - val_mae: 0.0026\n",
      "Epoch 231/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.8781e-05 - mae: 0.0027 - val_loss: 5.6542e-05 - val_mae: 0.0027\n",
      "Epoch 232/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.3277e-05 - mae: 0.0029 - val_loss: 6.5426e-05 - val_mae: 0.0031\n",
      "Epoch 233/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 5.0420e-05 - mae: 0.0028 - val_loss: 7.0656e-05 - val_mae: 0.0032\n",
      "Epoch 234/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.3327e-05 - mae: 0.0029 - val_loss: 8.4492e-05 - val_mae: 0.0039\n",
      "Epoch 235/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 5.1793e-05 - mae: 0.0028 - val_loss: 6.3084e-05 - val_mae: 0.0031\n",
      "Epoch 236/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5626e-05 - mae: 0.0025 - val_loss: 6.1277e-05 - val_mae: 0.0029\n",
      "Epoch 237/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.8951e-05 - mae: 0.0027 - val_loss: 6.2721e-05 - val_mae: 0.0035\n",
      "Epoch 238/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.9548e-05 - mae: 0.0027 - val_loss: 8.1340e-05 - val_mae: 0.0037\n",
      "Epoch 239/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.9676e-05 - mae: 0.0027 - val_loss: 5.8275e-05 - val_mae: 0.0030\n",
      "Epoch 240/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.5536e-05 - mae: 0.0025 - val_loss: 6.3051e-05 - val_mae: 0.0031\n",
      "Epoch 241/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.8082e-05 - mae: 0.0026 - val_loss: 5.9891e-05 - val_mae: 0.0028\n",
      "Epoch 242/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 5.7972e-05 - mae: 0.0031 - val_loss: 6.4363e-05 - val_mae: 0.0030\n",
      "Epoch 243/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.0003e-05 - mae: 0.0028 - val_loss: 5.6740e-05 - val_mae: 0.0028\n",
      "Epoch 244/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5176e-05 - mae: 0.0025 - val_loss: 5.4399e-05 - val_mae: 0.0025\n",
      "Epoch 245/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.8801e-05 - mae: 0.0026 - val_loss: 8.4310e-05 - val_mae: 0.0041\n",
      "Epoch 246/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 5.4919e-05 - mae: 0.0029 - val_loss: 6.3334e-05 - val_mae: 0.0032\n",
      "Epoch 247/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.8976e-05 - mae: 0.0027 - val_loss: 6.0461e-05 - val_mae: 0.0032\n",
      "Epoch 248/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.5576e-05 - mae: 0.0025 - val_loss: 7.2264e-05 - val_mae: 0.0033\n",
      "Epoch 249/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 5.1910e-05 - mae: 0.0029 - val_loss: 6.8018e-05 - val_mae: 0.0030\n",
      "Epoch 250/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.8756e-05 - mae: 0.0026 - val_loss: 5.6745e-05 - val_mae: 0.0026\n",
      "Epoch 251/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5355e-05 - mae: 0.0025 - val_loss: 5.8104e-05 - val_mae: 0.0029\n",
      "Epoch 252/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.6229e-05 - mae: 0.0025 - val_loss: 5.9266e-05 - val_mae: 0.0029\n",
      "Epoch 253/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 5.2161e-05 - mae: 0.0028 - val_loss: 6.7536e-05 - val_mae: 0.0032\n",
      "Epoch 254/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5514e-05 - mae: 0.0025 - val_loss: 5.3890e-05 - val_mae: 0.0025\n",
      "Epoch 255/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 5.3430e-05 - mae: 0.0029 - val_loss: 5.7910e-05 - val_mae: 0.0026\n",
      "Epoch 256/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.6312e-05 - mae: 0.0026 - val_loss: 5.5119e-05 - val_mae: 0.0027\n",
      "Epoch 257/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.9702e-05 - mae: 0.0028 - val_loss: 5.6051e-05 - val_mae: 0.0028\n",
      "Epoch 258/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.8328e-05 - mae: 0.0027 - val_loss: 4.9094e-05 - val_mae: 0.0021\n",
      "Epoch 259/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5429e-05 - mae: 0.0025 - val_loss: 5.1673e-05 - val_mae: 0.0023\n",
      "Epoch 260/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.9453e-05 - mae: 0.0027 - val_loss: 6.4938e-05 - val_mae: 0.0034\n",
      "Epoch 261/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.9849e-05 - mae: 0.0027 - val_loss: 5.2073e-05 - val_mae: 0.0024\n",
      "Epoch 262/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.6319e-05 - mae: 0.0025 - val_loss: 5.4689e-05 - val_mae: 0.0029\n",
      "Epoch 263/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4483e-05 - mae: 0.0024 - val_loss: 5.2797e-05 - val_mae: 0.0025\n",
      "Epoch 264/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.6121e-05 - mae: 0.0026 - val_loss: 5.4369e-05 - val_mae: 0.0027\n",
      "Epoch 265/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.5841e-05 - mae: 0.0026 - val_loss: 5.2174e-05 - val_mae: 0.0024\n",
      "Epoch 266/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.6689e-05 - mae: 0.0026 - val_loss: 5.2991e-05 - val_mae: 0.0026\n",
      "Epoch 267/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.5056e-05 - mae: 0.0025 - val_loss: 5.3792e-05 - val_mae: 0.0025\n",
      "Epoch 268/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.8002e-05 - mae: 0.0027 - val_loss: 5.8548e-05 - val_mae: 0.0029\n",
      "Epoch 269/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 5.1909e-05 - mae: 0.0028 - val_loss: 5.9694e-05 - val_mae: 0.0027\n",
      "Epoch 270/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.5106e-05 - mae: 0.0025 - val_loss: 5.4139e-05 - val_mae: 0.0027\n",
      "Epoch 271/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.2802e-05 - mae: 0.0023 - val_loss: 5.6650e-05 - val_mae: 0.0028\n",
      "Epoch 272/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.9851e-05 - mae: 0.0027 - val_loss: 7.3328e-05 - val_mae: 0.0038\n",
      "Epoch 273/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5906e-05 - mae: 0.0026 - val_loss: 5.5208e-05 - val_mae: 0.0027\n",
      "Epoch 274/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.4705e-05 - mae: 0.0025 - val_loss: 5.1308e-05 - val_mae: 0.0025\n",
      "Epoch 275/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.3050e-05 - mae: 0.0024 - val_loss: 5.2562e-05 - val_mae: 0.0025\n",
      "Epoch 276/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4985e-05 - mae: 0.0025 - val_loss: 5.2027e-05 - val_mae: 0.0024\n",
      "Epoch 277/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.7318e-05 - mae: 0.0026 - val_loss: 6.7441e-05 - val_mae: 0.0036\n",
      "Epoch 278/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.6642e-05 - mae: 0.0026 - val_loss: 5.8551e-05 - val_mae: 0.0028\n",
      "Epoch 279/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5529e-05 - mae: 0.0025 - val_loss: 6.0273e-05 - val_mae: 0.0028\n",
      "Epoch 280/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 5.3787e-05 - mae: 0.0030 - val_loss: 5.3670e-05 - val_mae: 0.0026\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 281/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2367e-05 - mae: 0.0023 - val_loss: 5.2948e-05 - val_mae: 0.0027\n",
      "Epoch 282/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.2936e-05 - mae: 0.0024 - val_loss: 6.8119e-05 - val_mae: 0.0034\n",
      "Epoch 283/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.6307e-05 - mae: 0.0026 - val_loss: 6.8442e-05 - val_mae: 0.0033\n",
      "Epoch 284/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.4131e-05 - mae: 0.0025 - val_loss: 5.3847e-05 - val_mae: 0.0025\n",
      "Epoch 285/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.7642e-05 - mae: 0.0027 - val_loss: 6.6877e-05 - val_mae: 0.0032\n",
      "Epoch 286/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.5975e-05 - mae: 0.0026 - val_loss: 5.2608e-05 - val_mae: 0.0024\n",
      "Epoch 287/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.4287e-05 - mae: 0.0024 - val_loss: 5.1128e-05 - val_mae: 0.0024\n",
      "Epoch 288/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.2943e-05 - mae: 0.0024 - val_loss: 5.1037e-05 - val_mae: 0.0023\n",
      "Epoch 289/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.5859e-05 - mae: 0.0026 - val_loss: 6.6040e-05 - val_mae: 0.0029\n",
      "Epoch 290/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.6667e-05 - mae: 0.0026 - val_loss: 5.2003e-05 - val_mae: 0.0024\n",
      "Epoch 291/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.8068e-05 - mae: 0.0027 - val_loss: 4.9703e-05 - val_mae: 0.0023\n",
      "Epoch 292/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.2859e-05 - mae: 0.0024 - val_loss: 5.0276e-05 - val_mae: 0.0023\n",
      "Epoch 293/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.2119e-05 - mae: 0.0023 - val_loss: 5.3557e-05 - val_mae: 0.0026\n",
      "Epoch 294/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5411e-05 - mae: 0.0026 - val_loss: 5.3222e-05 - val_mae: 0.0025\n",
      "Epoch 295/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.9277e-05 - mae: 0.0026 - val_loss: 5.6764e-05 - val_mae: 0.0027\n",
      "Epoch 296/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.5172e-05 - mae: 0.0025 - val_loss: 5.1063e-05 - val_mae: 0.0024\n",
      "Epoch 297/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.5222e-05 - mae: 0.0025 - val_loss: 5.6528e-05 - val_mae: 0.0027\n",
      "Epoch 298/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 6.1659e-05 - mae: 0.0030 - val_loss: 6.1591e-05 - val_mae: 0.0034\n",
      "Epoch 299/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.6017e-05 - mae: 0.0026 - val_loss: 5.5453e-05 - val_mae: 0.0026\n",
      "Epoch 300/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5940e-05 - mae: 0.0025 - val_loss: 5.3702e-05 - val_mae: 0.0027\n",
      "Epoch 301/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.4109e-05 - mae: 0.0025 - val_loss: 5.1036e-05 - val_mae: 0.0024\n",
      "Epoch 302/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.7221e-05 - mae: 0.0027 - val_loss: 7.1337e-05 - val_mae: 0.0038\n",
      "Epoch 303/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.5124e-05 - mae: 0.0025 - val_loss: 5.2820e-05 - val_mae: 0.0023\n",
      "Epoch 304/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.3594e-05 - mae: 0.0024 - val_loss: 5.7202e-05 - val_mae: 0.0027\n",
      "Epoch 305/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.4968e-05 - mae: 0.0025 - val_loss: 6.3628e-05 - val_mae: 0.0031\n",
      "Epoch 306/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.7043e-05 - mae: 0.0026 - val_loss: 6.5693e-05 - val_mae: 0.0036\n",
      "Epoch 307/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.5580e-05 - mae: 0.0026 - val_loss: 7.2775e-05 - val_mae: 0.0034\n",
      "Epoch 308/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.8966e-05 - mae: 0.0027 - val_loss: 4.8934e-05 - val_mae: 0.0021\n",
      "Epoch 309/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.3414e-05 - mae: 0.0024 - val_loss: 5.2226e-05 - val_mae: 0.0026\n",
      "Epoch 310/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4220e-05 - mae: 0.0025 - val_loss: 5.2259e-05 - val_mae: 0.0024\n",
      "Epoch 311/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.4215e-05 - mae: 0.0025 - val_loss: 6.0776e-05 - val_mae: 0.0031\n",
      "Epoch 312/1000\n",
      "116/116 [==============================] - 17s 148ms/step - loss: 4.4271e-05 - mae: 0.0025 - val_loss: 5.5540e-05 - val_mae: 0.0029\n",
      "Epoch 313/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2448e-05 - mae: 0.0024 - val_loss: 5.4300e-05 - val_mae: 0.0024\n",
      "Epoch 314/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.3970e-05 - mae: 0.0025 - val_loss: 4.7616e-05 - val_mae: 0.0023\n",
      "Epoch 315/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.2284e-05 - mae: 0.0024 - val_loss: 6.4322e-05 - val_mae: 0.0030\n",
      "Epoch 316/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.6045e-05 - mae: 0.0026 - val_loss: 5.0227e-05 - val_mae: 0.0023\n",
      "Epoch 317/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.4114e-05 - mae: 0.0025 - val_loss: 6.1319e-05 - val_mae: 0.0033\n",
      "Epoch 318/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.4525e-05 - mae: 0.0026 - val_loss: 6.2862e-05 - val_mae: 0.0033\n",
      "Epoch 319/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.3838e-05 - mae: 0.0025 - val_loss: 5.6144e-05 - val_mae: 0.0028\n",
      "Epoch 320/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.2977e-05 - mae: 0.0024 - val_loss: 6.8502e-05 - val_mae: 0.0035\n",
      "Epoch 321/1000\n",
      "116/116 [==============================] - 16s 141ms/step - loss: 4.6847e-05 - mae: 0.0026 - val_loss: 5.2361e-05 - val_mae: 0.0025\n",
      "Epoch 322/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.3875e-05 - mae: 0.0024 - val_loss: 5.6385e-05 - val_mae: 0.0027\n",
      "Epoch 323/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.8002e-05 - mae: 0.0028 - val_loss: 5.3806e-05 - val_mae: 0.0026\n",
      "Epoch 324/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.4899e-05 - mae: 0.0025 - val_loss: 5.0682e-05 - val_mae: 0.0024\n",
      "Epoch 325/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.3738e-05 - mae: 0.0024 - val_loss: 6.6552e-05 - val_mae: 0.0034\n",
      "Epoch 326/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.5471e-05 - mae: 0.0025 - val_loss: 4.8057e-05 - val_mae: 0.0022\n",
      "Epoch 327/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.9064e-05 - mae: 0.0028 - val_loss: 5.2201e-05 - val_mae: 0.0024\n",
      "Epoch 328/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.3812e-05 - mae: 0.0024 - val_loss: 5.4535e-05 - val_mae: 0.0026\n",
      "Epoch 329/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.4797e-05 - mae: 0.0025 - val_loss: 5.2403e-05 - val_mae: 0.0027\n",
      "Epoch 330/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.3461e-05 - mae: 0.0024 - val_loss: 5.4648e-05 - val_mae: 0.0027\n",
      "Epoch 331/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.4008e-05 - mae: 0.0025 - val_loss: 5.3278e-05 - val_mae: 0.0026\n",
      "Epoch 332/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2934e-05 - mae: 0.0025 - val_loss: 7.3185e-05 - val_mae: 0.0040\n",
      "Epoch 333/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2335e-05 - mae: 0.0024 - val_loss: 5.2561e-05 - val_mae: 0.0025\n",
      "Epoch 334/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.4407e-05 - mae: 0.0026 - val_loss: 5.0274e-05 - val_mae: 0.0026\n",
      "Epoch 335/1000\n",
      "116/116 [==============================] - 16s 142ms/step - loss: 4.0789e-05 - mae: 0.0023 - val_loss: 4.9752e-05 - val_mae: 0.0023\n",
      "Epoch 336/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.1710e-05 - mae: 0.0024 - val_loss: 5.9224e-05 - val_mae: 0.0030\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 337/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.3794e-05 - mae: 0.0025 - val_loss: 4.8674e-05 - val_mae: 0.0023\n",
      "Epoch 338/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.1735e-05 - mae: 0.0024 - val_loss: 5.8282e-05 - val_mae: 0.0030\n",
      "Epoch 339/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.1614e-05 - mae: 0.0024 - val_loss: 4.9245e-05 - val_mae: 0.0023\n",
      "Epoch 340/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 3.9317e-05 - mae: 0.0022 - val_loss: 4.6532e-05 - val_mae: 0.0022\n",
      "Epoch 341/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.2143e-05 - mae: 0.0024 - val_loss: 5.0435e-05 - val_mae: 0.0026\n",
      "Epoch 342/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2211e-05 - mae: 0.0024 - val_loss: 5.2228e-05 - val_mae: 0.0024\n",
      "Epoch 343/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.3060e-05 - mae: 0.0025 - val_loss: 5.1086e-05 - val_mae: 0.0026\n",
      "Epoch 344/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.3293e-05 - mae: 0.0025 - val_loss: 4.8459e-05 - val_mae: 0.0024\n",
      "Epoch 345/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4173e-05 - mae: 0.0026 - val_loss: 6.5095e-05 - val_mae: 0.0033\n",
      "Epoch 346/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.5334e-05 - mae: 0.0027 - val_loss: 6.6330e-05 - val_mae: 0.0035\n",
      "Epoch 347/1000\n",
      "116/116 [==============================] - 16s 140ms/step - loss: 4.5200e-05 - mae: 0.0026 - val_loss: 4.8225e-05 - val_mae: 0.0023\n",
      "Epoch 348/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.1985e-05 - mae: 0.0024 - val_loss: 4.8228e-05 - val_mae: 0.0023\n",
      "Epoch 349/1000\n",
      "116/116 [==============================] - 17s 142ms/step - loss: 4.0164e-05 - mae: 0.0023 - val_loss: 4.8835e-05 - val_mae: 0.0024\n",
      "Epoch 350/1000\n",
      "116/116 [==============================] - 17s 145ms/step - loss: 4.2064e-05 - mae: 0.0024 - val_loss: 5.0977e-05 - val_mae: 0.0027\n",
      "Epoch 351/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.2216e-05 - mae: 0.0024 - val_loss: 5.0123e-05 - val_mae: 0.0024\n",
      "Epoch 352/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.7564e-05 - mae: 0.0027 - val_loss: 6.4020e-05 - val_mae: 0.0036\n",
      "Epoch 353/1000\n",
      "116/116 [==============================] - 17s 146ms/step - loss: 4.4337e-05 - mae: 0.0026 - val_loss: 4.7903e-05 - val_mae: 0.0023\n",
      "Epoch 354/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 4.0478e-05 - mae: 0.0023 - val_loss: 5.2032e-05 - val_mae: 0.0027\n",
      "Epoch 355/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.1351e-05 - mae: 0.0024 - val_loss: 5.0839e-05 - val_mae: 0.0024\n",
      "Epoch 356/1000\n",
      "116/116 [==============================] - 17s 147ms/step - loss: 4.6027e-05 - mae: 0.0026 - val_loss: 5.2442e-05 - val_mae: 0.0026\n",
      "Epoch 357/1000\n",
      "116/116 [==============================] - 17s 143ms/step - loss: 4.3171e-05 - mae: 0.0025 - val_loss: 5.8487e-05 - val_mae: 0.0034\n",
      "Epoch 358/1000\n",
      "116/116 [==============================] - 17s 144ms/step - loss: 3.9944e-05 - mae: 0.0023 - val_loss: 4.9493e-05 - val_mae: 0.0023\n"
     ]
    }
   ],
   "source": [
    "history = model_RNN_LSTM_3d.fit(x_train,y_train, epochs=1000, batch_size=16, validation_split=0.2,callbacks = [callbacks])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1670470311929,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "4kEwHgcTThyk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'model_RNN_LSTM_3d' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[21], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5\")\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;66;03m# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5\")\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mmodel_RNN_LSTM_3d\u001b[49m\u001b[38;5;241m.\u001b[39msave(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./models/sep_1/lstm.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'model_RNN_LSTM_3d' is not defined"
     ]
    }
   ],
   "source": [
    "# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5\")\n",
    "# model_LSTM.save(\"/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5\")\n",
    "model_RNN_LSTM_3d.save(\"./models/traj_point/lstm_rnn.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the saved models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1549,
     "status": "ok",
     "timestamp": 1670464132234,
     "user": {
      "displayName": "Niegil Francis Muttath Joseph",
      "userId": "14540288352466598089"
     },
     "user_tz": 300
    },
    "id": "_lI1n5rWk7DF",
    "outputId": "11fbc446-b78b-4739-c7b0-cdfd12b12134"
   },
   "outputs": [],
   "source": [
    "# classification models\n",
    "# model_load = load_model('/content/drive/MyDrive/Robot perception /Modeling/models/lstm_data_trim.h5')\n",
    "# model_load = load_model('/content/drive/MyDrive/Robot perception /Modeling/models/lstm.h5')\n",
    "model_load = load_model('./models/sep_0.7/lstm_rnn.h5')\n",
    "\n",
    "\n",
    "# 3d models\n",
    "# model_load = load_model('./models/traj_point/lstm_rnn.h5')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 200, 3)]          0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 200, 15)           60        \n",
      "                                                                 \n",
      " simple_rnn (SimpleRNN)      (None, 200, 15)           465       \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 200, 15)           1860      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 200, 9)            144       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,529\n",
      "Trainable params: 2,529\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model_load.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 18ms/step - loss: 0.2631 - accuracy: 0.9007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.26308029890060425, 0.900730311870575]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 18ms/step - loss: 0.2674 - accuracy: 0.8985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.267398864030838, 0.898490846157074]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_load.evaluate(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the lengths of x_test\n",
    "# lengths = np.array([len(i) for i in x_test_])\n",
    "# Removing trajectories with <=12 length\n",
    "# idx = np.where(lengths <= 12)[0]\n",
    "# [y_test_.pop(j-i) for i,j in enumerate(idx)]\n",
    "# [x_test_.pop(j-i) for i,j in enumerate(idx)];\n",
    "# Checking\n",
    "# np.where(lengths <= 12)[0]\n",
    "\n",
    "# dict_l = defaultdict(list)\n",
    "\n",
    "# for i in tqdm.tqdm(range(max(lengths)-9)):\n",
    "#     idx = np.where(lengths >= i+12)[0]\n",
    "#     x_ = [x_test_[l].values.tolist()[:i+2] for l in idx]\n",
    "#     y_ = [y_test_[l].values.tolist()[i+2:i+12] for l in idx]\n",
    "#     if len(idx) == 1:\n",
    "#             break\n",
    "#     for k in range(10):\n",
    "\n",
    "#         temp = tf.convert_to_tensor(tf.keras.preprocessing.sequence.pad_sequences(x_, padding='post', dtype='float', maxlen=200, value = -10))\n",
    "\n",
    "#         preds = model_load.predict(temp, verbose = 0)\n",
    "#         preds = preds[:,-1,:]\n",
    "#         [x_[j].append(list(preds[j])) for j in range(len(idx))]\n",
    "#     print(np.array(x_[j])[i+2:] - np.array(y_[j]))\n",
    "#     print(np.array(x_[j]))\n",
    "#     print(np.array(y_[j]))\n",
    "#     helo\n",
    "#     [dict_l[i+2].append(np.mean(np.linalg.norm(),axis =0)) for j in range(len(x_))]\n",
    "# [np.mean(dict_l[i]) for i in dict_l.keys()]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8 (tags/v3.10.8:aaaf517, Oct 11 2022, 16:50:30) [MSC v.1933 64 bit (AMD64)]"
  },
  "vscode": {
   "interpreter": {
    "hash": "26de051ba29f2982a8de78e945f0abaf191376122a1563185a90213a26c5da77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
